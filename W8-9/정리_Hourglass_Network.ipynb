{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"정리_Hourglass_Network.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMZCxNdlcW96WrLsjW/N4Qg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Hourglass module"],"metadata":{"id":"9YzkcjqTGswN"}},{"cell_type":"code","execution_count":13,"metadata":{"id":"DgpWOCFJj9IE","executionInfo":{"status":"ok","timestamp":1649572481202,"user_tz":-540,"elapsed":323,"user":{"displayName":"Jaehoon Kim","userId":"03064955329912050209"}}},"outputs":[],"source":["import torch\n","import numpy as np\n","import random\n","\n","torch.manual_seed(0)\n","torch.cuda.manual_seed(0)\n","np.random.seed(0)\n","random.seed(0)\n","\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class ResidualBlock(nn.Module):\n","    def __init__(self, num_channels=256):\n","        super(ResidualBlock, self).__init__()\n","\n","        self.bn1 = nn.BatchNorm2d(num_channels)\n","        self.conv1 = nn.Conv2d(num_channels, num_channels//2, kernel_size=1, bias=True)\n","\n","        self.bn2 = nn.BatchNorm2d(num_channels//2)\n","        self.conv2 = nn.Conv2d(num_channels//2, num_channels//2, kernel_size=3, stride=1, padding=1, bias=True)\n","\n","        self.bn3 = nn.BatchNorm2d(num_channels//2)\n","        self.conv3 = nn.Conv2d(num_channels//2, num_channels, kernel_size=1, bias=True)\n","\n","        self.relu = nn.ReLU(inplace=True)\n","\n","    def forward(self, x):\n","        residual = x\n","\n","        out = self.bn1(x)\n","        out = self.relu(out)\n","        out = self.conv1(out)\n","\n","        out = self.bn2(out)\n","        out = self.relu(out)\n","        out = self.conv2(out)\n","\n","        out = self.bn3(out)\n","        out = self.relu(out)\n","        out = self.conv3(out)\n","\n","        out += residual\n","\n","        return out"],"metadata":{"id":"iAxN4XS8lOU4","executionInfo":{"status":"ok","timestamp":1649572481469,"user_tz":-540,"elapsed":5,"user":{"displayName":"Jaehoon Kim","userId":"03064955329912050209"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["class Hourglass(nn.Module):\n","    def __init__(self, block, num_channels=256):\n","        super(Hourglass, self).__init__()\n","\n","        self.downconv_1 = block(num_channels)\n","        self.pool_1 = nn.MaxPool2d(kernel_size=2)\n","        self.downconv_2 = block(num_channels)\n","        self.pool_2 = nn.MaxPool2d(kernel_size=2)\n","        self.downconv_3 = block(num_channels)\n","        self.pool_3 = nn.MaxPool2d(kernel_size=2)\n","        self.downconv_4 = block(num_channels)\n","        self.pool_4 = nn.MaxPool2d(kernel_size=2)\n","\n","        self.midconv_1 = block(num_channels)\n","        self.midconv_2 = block(num_channels)\n","        self.midconv_3 = block(num_channels)\n","        \n","        self.skipconv_1 = block(num_channels)\n","        self.skipconv_2 = block(num_channels)\n","        self.skipconv_3 = block(num_channels)\n","        self.skipconv_4 = block(num_channels)\n","\n","        self.upconv_1 = block(num_channels)\n","        self.upconv_2 = block(num_channels)\n","        self.upconv_3 = block(num_channels)\n","        self.upconv_4 = block(num_channels)\n","\n","    def forward(self, x):\n","\n","        x1 = self.downconv_1(x)\n","        x  = self.pool_1(x1)\n","        x2 = self.downconv_2(x)\n","        x  = self.pool_2(x2)\n","        x3 = self.downconv_3(x)\n","        x  = self.pool_3(x3)\n","        x4 = self.downconv_4(x)\n","        x  = self.pool_4(x4)\n","\n","        x = self.midconv_1(x)\n","        x = self.midconv_2(x)\n","        x = self.midconv_3(x)\n","\n","        x4 = self.skipconv_1(x4)\n","        x = F.upsample(x, scale_factor=2)\n","        x = x + x4\n","        x = self.upconv_1(x)\n","\n","        x3 = self.skipconv_1(x3)\n","        x = F.upsample(x, scale_factor=2)\n","        x = x + x3\n","        x = self.upconv_2(x)\n","\n","        x2 = self.skipconv_1(x2)\n","        x = F.upsample(x, scale_factor=2)\n","        x = x + x2\n","        x = self.upconv_3(x)\n","\n","        x1 = self.skipconv_1(x1)\n","        x = F.upsample(x, scale_factor=2)\n","        x = x + x1\n","        x = self.upconv_4(x)\n","\n","        return x"],"metadata":{"id":"LHLRtLBeB7ii","executionInfo":{"status":"ok","timestamp":1649572481469,"user_tz":-540,"elapsed":4,"user":{"displayName":"Jaehoon Kim","userId":"03064955329912050209"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["hg = Hourglass(ResidualBlock)\n","\n","from torchsummary import summary\n","summary(hg, input_size=(256,64,64), device='cpu')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SdYdfTOHF6YE","executionInfo":{"status":"ok","timestamp":1649572482328,"user_tz":-540,"elapsed":863,"user":{"displayName":"Jaehoon Kim","userId":"03064955329912050209"}},"outputId":"5611c3c0-0ee4-44c2-bcbf-e661b975b75d"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","       BatchNorm2d-1          [-1, 256, 64, 64]             512\n","              ReLU-2          [-1, 256, 64, 64]               0\n","            Conv2d-3          [-1, 128, 64, 64]          32,896\n","       BatchNorm2d-4          [-1, 128, 64, 64]             256\n","              ReLU-5          [-1, 128, 64, 64]               0\n","            Conv2d-6          [-1, 128, 64, 64]         147,584\n","       BatchNorm2d-7          [-1, 128, 64, 64]             256\n","              ReLU-8          [-1, 128, 64, 64]               0\n","            Conv2d-9          [-1, 256, 64, 64]          33,024\n","    ResidualBlock-10          [-1, 256, 64, 64]               0\n","        MaxPool2d-11          [-1, 256, 32, 32]               0\n","      BatchNorm2d-12          [-1, 256, 32, 32]             512\n","             ReLU-13          [-1, 256, 32, 32]               0\n","           Conv2d-14          [-1, 128, 32, 32]          32,896\n","      BatchNorm2d-15          [-1, 128, 32, 32]             256\n","             ReLU-16          [-1, 128, 32, 32]               0\n","           Conv2d-17          [-1, 128, 32, 32]         147,584\n","      BatchNorm2d-18          [-1, 128, 32, 32]             256\n","             ReLU-19          [-1, 128, 32, 32]               0\n","           Conv2d-20          [-1, 256, 32, 32]          33,024\n","    ResidualBlock-21          [-1, 256, 32, 32]               0\n","        MaxPool2d-22          [-1, 256, 16, 16]               0\n","      BatchNorm2d-23          [-1, 256, 16, 16]             512\n","             ReLU-24          [-1, 256, 16, 16]               0\n","           Conv2d-25          [-1, 128, 16, 16]          32,896\n","      BatchNorm2d-26          [-1, 128, 16, 16]             256\n","             ReLU-27          [-1, 128, 16, 16]               0\n","           Conv2d-28          [-1, 128, 16, 16]         147,584\n","      BatchNorm2d-29          [-1, 128, 16, 16]             256\n","             ReLU-30          [-1, 128, 16, 16]               0\n","           Conv2d-31          [-1, 256, 16, 16]          33,024\n","    ResidualBlock-32          [-1, 256, 16, 16]               0\n","        MaxPool2d-33            [-1, 256, 8, 8]               0\n","      BatchNorm2d-34            [-1, 256, 8, 8]             512\n","             ReLU-35            [-1, 256, 8, 8]               0\n","           Conv2d-36            [-1, 128, 8, 8]          32,896\n","      BatchNorm2d-37            [-1, 128, 8, 8]             256\n","             ReLU-38            [-1, 128, 8, 8]               0\n","           Conv2d-39            [-1, 128, 8, 8]         147,584\n","      BatchNorm2d-40            [-1, 128, 8, 8]             256\n","             ReLU-41            [-1, 128, 8, 8]               0\n","           Conv2d-42            [-1, 256, 8, 8]          33,024\n","    ResidualBlock-43            [-1, 256, 8, 8]               0\n","        MaxPool2d-44            [-1, 256, 4, 4]               0\n","      BatchNorm2d-45            [-1, 256, 4, 4]             512\n","             ReLU-46            [-1, 256, 4, 4]               0\n","           Conv2d-47            [-1, 128, 4, 4]          32,896\n","      BatchNorm2d-48            [-1, 128, 4, 4]             256\n","             ReLU-49            [-1, 128, 4, 4]               0\n","           Conv2d-50            [-1, 128, 4, 4]         147,584\n","      BatchNorm2d-51            [-1, 128, 4, 4]             256\n","             ReLU-52            [-1, 128, 4, 4]               0\n","           Conv2d-53            [-1, 256, 4, 4]          33,024\n","    ResidualBlock-54            [-1, 256, 4, 4]               0\n","      BatchNorm2d-55            [-1, 256, 4, 4]             512\n","             ReLU-56            [-1, 256, 4, 4]               0\n","           Conv2d-57            [-1, 128, 4, 4]          32,896\n","      BatchNorm2d-58            [-1, 128, 4, 4]             256\n","             ReLU-59            [-1, 128, 4, 4]               0\n","           Conv2d-60            [-1, 128, 4, 4]         147,584\n","      BatchNorm2d-61            [-1, 128, 4, 4]             256\n","             ReLU-62            [-1, 128, 4, 4]               0\n","           Conv2d-63            [-1, 256, 4, 4]          33,024\n","    ResidualBlock-64            [-1, 256, 4, 4]               0\n","      BatchNorm2d-65            [-1, 256, 4, 4]             512\n","             ReLU-66            [-1, 256, 4, 4]               0\n","           Conv2d-67            [-1, 128, 4, 4]          32,896\n","      BatchNorm2d-68            [-1, 128, 4, 4]             256\n","             ReLU-69            [-1, 128, 4, 4]               0\n","           Conv2d-70            [-1, 128, 4, 4]         147,584\n","      BatchNorm2d-71            [-1, 128, 4, 4]             256\n","             ReLU-72            [-1, 128, 4, 4]               0\n","           Conv2d-73            [-1, 256, 4, 4]          33,024\n","    ResidualBlock-74            [-1, 256, 4, 4]               0\n","      BatchNorm2d-75            [-1, 256, 8, 8]             512\n","             ReLU-76            [-1, 256, 8, 8]               0\n","           Conv2d-77            [-1, 128, 8, 8]          32,896\n","      BatchNorm2d-78            [-1, 128, 8, 8]             256\n","             ReLU-79            [-1, 128, 8, 8]               0\n","           Conv2d-80            [-1, 128, 8, 8]         147,584\n","      BatchNorm2d-81            [-1, 128, 8, 8]             256\n","             ReLU-82            [-1, 128, 8, 8]               0\n","           Conv2d-83            [-1, 256, 8, 8]          33,024\n","    ResidualBlock-84            [-1, 256, 8, 8]               0\n","      BatchNorm2d-85            [-1, 256, 8, 8]             512\n","             ReLU-86            [-1, 256, 8, 8]               0\n","           Conv2d-87            [-1, 128, 8, 8]          32,896\n","      BatchNorm2d-88            [-1, 128, 8, 8]             256\n","             ReLU-89            [-1, 128, 8, 8]               0\n","           Conv2d-90            [-1, 128, 8, 8]         147,584\n","      BatchNorm2d-91            [-1, 128, 8, 8]             256\n","             ReLU-92            [-1, 128, 8, 8]               0\n","           Conv2d-93            [-1, 256, 8, 8]          33,024\n","    ResidualBlock-94            [-1, 256, 8, 8]               0\n","      BatchNorm2d-95          [-1, 256, 16, 16]             512\n","             ReLU-96          [-1, 256, 16, 16]               0\n","           Conv2d-97          [-1, 128, 16, 16]          32,896\n","      BatchNorm2d-98          [-1, 128, 16, 16]             256\n","             ReLU-99          [-1, 128, 16, 16]               0\n","          Conv2d-100          [-1, 128, 16, 16]         147,584\n","     BatchNorm2d-101          [-1, 128, 16, 16]             256\n","            ReLU-102          [-1, 128, 16, 16]               0\n","          Conv2d-103          [-1, 256, 16, 16]          33,024\n","   ResidualBlock-104          [-1, 256, 16, 16]               0\n","     BatchNorm2d-105          [-1, 256, 16, 16]             512\n","            ReLU-106          [-1, 256, 16, 16]               0\n","          Conv2d-107          [-1, 128, 16, 16]          32,896\n","     BatchNorm2d-108          [-1, 128, 16, 16]             256\n","            ReLU-109          [-1, 128, 16, 16]               0\n","          Conv2d-110          [-1, 128, 16, 16]         147,584\n","     BatchNorm2d-111          [-1, 128, 16, 16]             256\n","            ReLU-112          [-1, 128, 16, 16]               0\n","          Conv2d-113          [-1, 256, 16, 16]          33,024\n","   ResidualBlock-114          [-1, 256, 16, 16]               0\n","     BatchNorm2d-115          [-1, 256, 32, 32]             512\n","            ReLU-116          [-1, 256, 32, 32]               0\n","          Conv2d-117          [-1, 128, 32, 32]          32,896\n","     BatchNorm2d-118          [-1, 128, 32, 32]             256\n","            ReLU-119          [-1, 128, 32, 32]               0\n","          Conv2d-120          [-1, 128, 32, 32]         147,584\n","     BatchNorm2d-121          [-1, 128, 32, 32]             256\n","            ReLU-122          [-1, 128, 32, 32]               0\n","          Conv2d-123          [-1, 256, 32, 32]          33,024\n","   ResidualBlock-124          [-1, 256, 32, 32]               0\n","     BatchNorm2d-125          [-1, 256, 32, 32]             512\n","            ReLU-126          [-1, 256, 32, 32]               0\n","          Conv2d-127          [-1, 128, 32, 32]          32,896\n","     BatchNorm2d-128          [-1, 128, 32, 32]             256\n","            ReLU-129          [-1, 128, 32, 32]               0\n","          Conv2d-130          [-1, 128, 32, 32]         147,584\n","     BatchNorm2d-131          [-1, 128, 32, 32]             256\n","            ReLU-132          [-1, 128, 32, 32]               0\n","          Conv2d-133          [-1, 256, 32, 32]          33,024\n","   ResidualBlock-134          [-1, 256, 32, 32]               0\n","     BatchNorm2d-135          [-1, 256, 64, 64]             512\n","            ReLU-136          [-1, 256, 64, 64]               0\n","          Conv2d-137          [-1, 128, 64, 64]          32,896\n","     BatchNorm2d-138          [-1, 128, 64, 64]             256\n","            ReLU-139          [-1, 128, 64, 64]               0\n","          Conv2d-140          [-1, 128, 64, 64]         147,584\n","     BatchNorm2d-141          [-1, 128, 64, 64]             256\n","            ReLU-142          [-1, 128, 64, 64]               0\n","          Conv2d-143          [-1, 256, 64, 64]          33,024\n","   ResidualBlock-144          [-1, 256, 64, 64]               0\n","     BatchNorm2d-145          [-1, 256, 64, 64]             512\n","            ReLU-146          [-1, 256, 64, 64]               0\n","          Conv2d-147          [-1, 128, 64, 64]          32,896\n","     BatchNorm2d-148          [-1, 128, 64, 64]             256\n","            ReLU-149          [-1, 128, 64, 64]               0\n","          Conv2d-150          [-1, 128, 64, 64]         147,584\n","     BatchNorm2d-151          [-1, 128, 64, 64]             256\n","            ReLU-152          [-1, 128, 64, 64]               0\n","          Conv2d-153          [-1, 256, 64, 64]          33,024\n","   ResidualBlock-154          [-1, 256, 64, 64]               0\n","================================================================\n","Total params: 3,217,920\n","Trainable params: 3,217,920\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 4.00\n","Forward/backward pass size (MB): 226.44\n","Params size (MB): 12.28\n","Estimated Total Size (MB): 242.71\n","----------------------------------------------------------------\n"]}]},{"cell_type":"markdown","source":["# Stacked hourglass network"],"metadata":{"id":"aZd7LdmBGwB5"}},{"cell_type":"code","source":["__all__ = ['HourglassNet', 'hg']\n","\n","class Bottleneck(nn.Module):\n","    expansion = 2\n","\n","    def __init__(self, inplanes, planes, stride=1, downsample=None):\n","        super(Bottleneck, self).__init__()\n","\n","        self.bn1 = nn.BatchNorm2d(inplanes)\n","        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=True)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=True)\n","        self.bn3 = nn.BatchNorm2d(planes)\n","        self.conv3 = nn.Conv2d(planes, planes*2, kernel_size=1, bias=True)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","    def forward(self, x):\n","        residual = x\n","\n","        out = self.bn1(x)\n","        out = self.relu(out)\n","        out = self.conv1(out)\n","\n","        out = self.bn2(out)\n","        out = self.relu(out)\n","        out = self.conv2(out)\n","\n","        out = self.bn3(out)\n","        out = self.relu(out)\n","        out = self.conv3(out)\n","\n","        if self.downsample is not None:\n","            residual = self.downsample(x)\n","\n","        out += residual\n","\n","        return out\n","\n","\n","class Hourglass(nn.Module):\n","    def __init__(self, block, num_blocks, planes, depth):\n","        super(Hourglass, self).__init__()\n","        self.depth = depth\n","        self.block = block\n","        self.hg = self._make_hour_glass(block, num_blocks, planes, depth)\n","\n","    def _make_residual(self, block, num_blocks, planes):\n","        layers = []\n","        for i in range(0, num_blocks):\n","            layers.append(block(planes*block.expansion, planes))\n","        return nn.Sequential(*layers)\n","\n","    def _make_hour_glass(self, block, num_blocks, planes, depth):\n","        hg = []\n","        for i in range(depth):\n","            res = []\n","            for j in range(3):\n","                res.append(self._make_residual(block, num_blocks, planes))\n","            if i == 0:\n","                res.append(self._make_residual(block, num_blocks, planes))\n","            hg.append(nn.ModuleList(res))\n","        return nn.ModuleList(hg)\n","\n","    def _hour_glass_forward(self, n, x):\n","        up1 = self.hg[n-1][0](x)\n","        low1 = F.max_pool2d(x, 2, stride=2)\n","        low1 = self.hg[n-1][1](low1)\n","\n","        if n > 1:\n","            low2 = self._hour_glass_forward(n-1, low1)\n","        else:\n","            low2 = self.hg[n-1][3](low1)\n","        low3 = self.hg[n-1][2](low2)\n","        up2 = F.interpolate(low3, scale_factor=2)\n","        out = up1 + up2\n","        return out\n","\n","    def forward(self, x):\n","        return self._hour_glass_forward(self.depth, x)\n","\n","\n","class HourglassNet(nn.Module):\n","    def __init__(self, block, num_stacks=2, num_blocks=4, num_classes=16):\n","        super(HourglassNet, self).__init__()\n","\n","        self.inplanes = 64\n","        self.num_feats = 128\n","        self.num_stacks = num_stacks\n","        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3, bias=True)\n","        self.bn1 = nn.BatchNorm2d(self.inplanes)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.layer1 = self._make_residual(block, self.inplanes, 1)\n","        self.layer2 = self._make_residual(block, self.inplanes, 1)\n","        self.layer3 = self._make_residual(block, self.num_feats, 1)\n","        self.maxpool = nn.MaxPool2d(2, stride=2)\n","\n","        ch = self.num_feats*block.expansion\n","        hg, res, fc, score, fc_, score_ = [], [], [], [], [], []\n","        for i in range(num_stacks):\n","            # Hourglass\n","            hg.append(Hourglass(block, num_blocks, self.num_feats, 4))\n","            # _make_residual\n","            res.append(self._make_residual(block, self.num_feats, num_blocks))\n","            # _make_fc\n","            fc.append(self._make_fc(ch, ch))\n","            score.append(nn.Conv2d(ch, num_classes, kernel_size=1, bias=True))\n","            if i < num_stacks-1:\n","                fc_.append(nn.Conv2d(ch, ch, kernel_size=1, bias=True))\n","                score_.append(nn.Conv2d(num_classes, ch, kernel_size=1, bias=True))\n","        self.hg = nn.ModuleList(hg)\n","        self.res = nn.ModuleList(res)\n","        self.fc = nn.ModuleList(fc)\n","        self.score = nn.ModuleList(score)\n","        self.fc_ = nn.ModuleList(fc_)\n","        self.score_ = nn.ModuleList(score_)\n","\n","    def _make_residual(self, block, planes, blocks, stride=1):\n","        downsample = None\n","        if stride != 1 or self.inplanes != planes*block.expansion:\n","            downsample = nn.Sequential(nn.Conv2d(self.inplanes, planes*block.expansion, kernel_size=1, stride=stride, bias=True))\n","\n","        layers = []\n","        layers.append(block(self.inplanes, planes, stride, downsample))\n","        self.inplanes = planes*block.expansion\n","        for i in range(1, blocks):\n","            layers.append(block(self.inplanes, planes))\n","\n","        return nn.Sequential(*layers)\n","\n","    def _make_fc(self, inplanes, outplanes):\n","        bn = nn.BatchNorm2d(inplanes)\n","        conv = nn.Conv2d(inplanes, outplanes, kernel_size=1, bias=True)\n","        return nn.Sequential(conv, bn, self.relu)\n","\n","    def forward(self, x):\n","        out = []\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","\n","        x = self.layer1(x)\n","        x = self.maxpool(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","\n","        for i in range(self.num_stacks):\n","            y = self.hg[i](x)\n","            y = self.res[i](y)\n","            y = self.fc[i](y)\n","            score = self.score[i](y)\n","            out.append(score)\n","            if i < self.num_stacks-1:\n","                fc_ = self.fc_[i](y)\n","                score_ = self.score_[i](score)\n","                x = x + fc_ + score_\n","\n","        return out"],"metadata":{"id":"j167YHyHGbWu","executionInfo":{"status":"ok","timestamp":1649572482745,"user_tz":-540,"elapsed":418,"user":{"displayName":"Jaehoon Kim","userId":"03064955329912050209"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["model = HourglassNet(Bottleneck, num_stacks=1, num_blocks=2, num_classes=22)\n","\n","summary(model, input_size=(3,64,64), device='cpu')"],"metadata":{"id":"MqvYNrCmHuME","executionInfo":{"status":"ok","timestamp":1649572483055,"user_tz":-540,"elapsed":312,"user":{"displayName":"Jaehoon Kim","userId":"03064955329912050209"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a0be22f5-4258-4380-9ef3-293c5d55f1e8"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 64, 32, 32]           9,472\n","       BatchNorm2d-2           [-1, 64, 32, 32]             128\n","              ReLU-3           [-1, 64, 32, 32]               0\n","              ReLU-4           [-1, 64, 32, 32]               0\n","       BatchNorm2d-5           [-1, 64, 32, 32]             128\n","              ReLU-6           [-1, 64, 32, 32]               0\n","            Conv2d-7           [-1, 64, 32, 32]           4,160\n","       BatchNorm2d-8           [-1, 64, 32, 32]             128\n","              ReLU-9           [-1, 64, 32, 32]               0\n","           Conv2d-10           [-1, 64, 32, 32]          36,928\n","      BatchNorm2d-11           [-1, 64, 32, 32]             128\n","             ReLU-12           [-1, 64, 32, 32]               0\n","           Conv2d-13          [-1, 128, 32, 32]           8,320\n","           Conv2d-14          [-1, 128, 32, 32]           8,320\n","       Bottleneck-15          [-1, 128, 32, 32]               0\n","        MaxPool2d-16          [-1, 128, 16, 16]               0\n","      BatchNorm2d-17          [-1, 128, 16, 16]             256\n","             ReLU-18          [-1, 128, 16, 16]               0\n","           Conv2d-19          [-1, 128, 16, 16]          16,512\n","      BatchNorm2d-20          [-1, 128, 16, 16]             256\n","             ReLU-21          [-1, 128, 16, 16]               0\n","           Conv2d-22          [-1, 128, 16, 16]         147,584\n","      BatchNorm2d-23          [-1, 128, 16, 16]             256\n","             ReLU-24          [-1, 128, 16, 16]               0\n","           Conv2d-25          [-1, 256, 16, 16]          33,024\n","           Conv2d-26          [-1, 256, 16, 16]          33,024\n","       Bottleneck-27          [-1, 256, 16, 16]               0\n","      BatchNorm2d-28          [-1, 256, 16, 16]             512\n","             ReLU-29          [-1, 256, 16, 16]               0\n","           Conv2d-30          [-1, 128, 16, 16]          32,896\n","      BatchNorm2d-31          [-1, 128, 16, 16]             256\n","             ReLU-32          [-1, 128, 16, 16]               0\n","           Conv2d-33          [-1, 128, 16, 16]         147,584\n","      BatchNorm2d-34          [-1, 128, 16, 16]             256\n","             ReLU-35          [-1, 128, 16, 16]               0\n","           Conv2d-36          [-1, 256, 16, 16]          33,024\n","       Bottleneck-37          [-1, 256, 16, 16]               0\n","      BatchNorm2d-38          [-1, 256, 16, 16]             512\n","             ReLU-39          [-1, 256, 16, 16]               0\n","           Conv2d-40          [-1, 128, 16, 16]          32,896\n","      BatchNorm2d-41          [-1, 128, 16, 16]             256\n","             ReLU-42          [-1, 128, 16, 16]               0\n","           Conv2d-43          [-1, 128, 16, 16]         147,584\n","      BatchNorm2d-44          [-1, 128, 16, 16]             256\n","             ReLU-45          [-1, 128, 16, 16]               0\n","           Conv2d-46          [-1, 256, 16, 16]          33,024\n","       Bottleneck-47          [-1, 256, 16, 16]               0\n","      BatchNorm2d-48          [-1, 256, 16, 16]             512\n","             ReLU-49          [-1, 256, 16, 16]               0\n","           Conv2d-50          [-1, 128, 16, 16]          32,896\n","      BatchNorm2d-51          [-1, 128, 16, 16]             256\n","             ReLU-52          [-1, 128, 16, 16]               0\n","           Conv2d-53          [-1, 128, 16, 16]         147,584\n","      BatchNorm2d-54          [-1, 128, 16, 16]             256\n","             ReLU-55          [-1, 128, 16, 16]               0\n","           Conv2d-56          [-1, 256, 16, 16]          33,024\n","       Bottleneck-57          [-1, 256, 16, 16]               0\n","      BatchNorm2d-58            [-1, 256, 8, 8]             512\n","             ReLU-59            [-1, 256, 8, 8]               0\n","           Conv2d-60            [-1, 128, 8, 8]          32,896\n","      BatchNorm2d-61            [-1, 128, 8, 8]             256\n","             ReLU-62            [-1, 128, 8, 8]               0\n","           Conv2d-63            [-1, 128, 8, 8]         147,584\n","      BatchNorm2d-64            [-1, 128, 8, 8]             256\n","             ReLU-65            [-1, 128, 8, 8]               0\n","           Conv2d-66            [-1, 256, 8, 8]          33,024\n","       Bottleneck-67            [-1, 256, 8, 8]               0\n","      BatchNorm2d-68            [-1, 256, 8, 8]             512\n","             ReLU-69            [-1, 256, 8, 8]               0\n","           Conv2d-70            [-1, 128, 8, 8]          32,896\n","      BatchNorm2d-71            [-1, 128, 8, 8]             256\n","             ReLU-72            [-1, 128, 8, 8]               0\n","           Conv2d-73            [-1, 128, 8, 8]         147,584\n","      BatchNorm2d-74            [-1, 128, 8, 8]             256\n","             ReLU-75            [-1, 128, 8, 8]               0\n","           Conv2d-76            [-1, 256, 8, 8]          33,024\n","       Bottleneck-77            [-1, 256, 8, 8]               0\n","      BatchNorm2d-78            [-1, 256, 8, 8]             512\n","             ReLU-79            [-1, 256, 8, 8]               0\n","           Conv2d-80            [-1, 128, 8, 8]          32,896\n","      BatchNorm2d-81            [-1, 128, 8, 8]             256\n","             ReLU-82            [-1, 128, 8, 8]               0\n","           Conv2d-83            [-1, 128, 8, 8]         147,584\n","      BatchNorm2d-84            [-1, 128, 8, 8]             256\n","             ReLU-85            [-1, 128, 8, 8]               0\n","           Conv2d-86            [-1, 256, 8, 8]          33,024\n","       Bottleneck-87            [-1, 256, 8, 8]               0\n","      BatchNorm2d-88            [-1, 256, 8, 8]             512\n","             ReLU-89            [-1, 256, 8, 8]               0\n","           Conv2d-90            [-1, 128, 8, 8]          32,896\n","      BatchNorm2d-91            [-1, 128, 8, 8]             256\n","             ReLU-92            [-1, 128, 8, 8]               0\n","           Conv2d-93            [-1, 128, 8, 8]         147,584\n","      BatchNorm2d-94            [-1, 128, 8, 8]             256\n","             ReLU-95            [-1, 128, 8, 8]               0\n","           Conv2d-96            [-1, 256, 8, 8]          33,024\n","       Bottleneck-97            [-1, 256, 8, 8]               0\n","      BatchNorm2d-98            [-1, 256, 4, 4]             512\n","             ReLU-99            [-1, 256, 4, 4]               0\n","          Conv2d-100            [-1, 128, 4, 4]          32,896\n","     BatchNorm2d-101            [-1, 128, 4, 4]             256\n","            ReLU-102            [-1, 128, 4, 4]               0\n","          Conv2d-103            [-1, 128, 4, 4]         147,584\n","     BatchNorm2d-104            [-1, 128, 4, 4]             256\n","            ReLU-105            [-1, 128, 4, 4]               0\n","          Conv2d-106            [-1, 256, 4, 4]          33,024\n","      Bottleneck-107            [-1, 256, 4, 4]               0\n","     BatchNorm2d-108            [-1, 256, 4, 4]             512\n","            ReLU-109            [-1, 256, 4, 4]               0\n","          Conv2d-110            [-1, 128, 4, 4]          32,896\n","     BatchNorm2d-111            [-1, 128, 4, 4]             256\n","            ReLU-112            [-1, 128, 4, 4]               0\n","          Conv2d-113            [-1, 128, 4, 4]         147,584\n","     BatchNorm2d-114            [-1, 128, 4, 4]             256\n","            ReLU-115            [-1, 128, 4, 4]               0\n","          Conv2d-116            [-1, 256, 4, 4]          33,024\n","      Bottleneck-117            [-1, 256, 4, 4]               0\n","     BatchNorm2d-118            [-1, 256, 4, 4]             512\n","            ReLU-119            [-1, 256, 4, 4]               0\n","          Conv2d-120            [-1, 128, 4, 4]          32,896\n","     BatchNorm2d-121            [-1, 128, 4, 4]             256\n","            ReLU-122            [-1, 128, 4, 4]               0\n","          Conv2d-123            [-1, 128, 4, 4]         147,584\n","     BatchNorm2d-124            [-1, 128, 4, 4]             256\n","            ReLU-125            [-1, 128, 4, 4]               0\n","          Conv2d-126            [-1, 256, 4, 4]          33,024\n","      Bottleneck-127            [-1, 256, 4, 4]               0\n","     BatchNorm2d-128            [-1, 256, 4, 4]             512\n","            ReLU-129            [-1, 256, 4, 4]               0\n","          Conv2d-130            [-1, 128, 4, 4]          32,896\n","     BatchNorm2d-131            [-1, 128, 4, 4]             256\n","            ReLU-132            [-1, 128, 4, 4]               0\n","          Conv2d-133            [-1, 128, 4, 4]         147,584\n","     BatchNorm2d-134            [-1, 128, 4, 4]             256\n","            ReLU-135            [-1, 128, 4, 4]               0\n","          Conv2d-136            [-1, 256, 4, 4]          33,024\n","      Bottleneck-137            [-1, 256, 4, 4]               0\n","     BatchNorm2d-138            [-1, 256, 2, 2]             512\n","            ReLU-139            [-1, 256, 2, 2]               0\n","          Conv2d-140            [-1, 128, 2, 2]          32,896\n","     BatchNorm2d-141            [-1, 128, 2, 2]             256\n","            ReLU-142            [-1, 128, 2, 2]               0\n","          Conv2d-143            [-1, 128, 2, 2]         147,584\n","     BatchNorm2d-144            [-1, 128, 2, 2]             256\n","            ReLU-145            [-1, 128, 2, 2]               0\n","          Conv2d-146            [-1, 256, 2, 2]          33,024\n","      Bottleneck-147            [-1, 256, 2, 2]               0\n","     BatchNorm2d-148            [-1, 256, 2, 2]             512\n","            ReLU-149            [-1, 256, 2, 2]               0\n","          Conv2d-150            [-1, 128, 2, 2]          32,896\n","     BatchNorm2d-151            [-1, 128, 2, 2]             256\n","            ReLU-152            [-1, 128, 2, 2]               0\n","          Conv2d-153            [-1, 128, 2, 2]         147,584\n","     BatchNorm2d-154            [-1, 128, 2, 2]             256\n","            ReLU-155            [-1, 128, 2, 2]               0\n","          Conv2d-156            [-1, 256, 2, 2]          33,024\n","      Bottleneck-157            [-1, 256, 2, 2]               0\n","     BatchNorm2d-158            [-1, 256, 2, 2]             512\n","            ReLU-159            [-1, 256, 2, 2]               0\n","          Conv2d-160            [-1, 128, 2, 2]          32,896\n","     BatchNorm2d-161            [-1, 128, 2, 2]             256\n","            ReLU-162            [-1, 128, 2, 2]               0\n","          Conv2d-163            [-1, 128, 2, 2]         147,584\n","     BatchNorm2d-164            [-1, 128, 2, 2]             256\n","            ReLU-165            [-1, 128, 2, 2]               0\n","          Conv2d-166            [-1, 256, 2, 2]          33,024\n","      Bottleneck-167            [-1, 256, 2, 2]               0\n","     BatchNorm2d-168            [-1, 256, 2, 2]             512\n","            ReLU-169            [-1, 256, 2, 2]               0\n","          Conv2d-170            [-1, 128, 2, 2]          32,896\n","     BatchNorm2d-171            [-1, 128, 2, 2]             256\n","            ReLU-172            [-1, 128, 2, 2]               0\n","          Conv2d-173            [-1, 128, 2, 2]         147,584\n","     BatchNorm2d-174            [-1, 128, 2, 2]             256\n","            ReLU-175            [-1, 128, 2, 2]               0\n","          Conv2d-176            [-1, 256, 2, 2]          33,024\n","      Bottleneck-177            [-1, 256, 2, 2]               0\n","     BatchNorm2d-178            [-1, 256, 1, 1]             512\n","            ReLU-179            [-1, 256, 1, 1]               0\n","          Conv2d-180            [-1, 128, 1, 1]          32,896\n","     BatchNorm2d-181            [-1, 128, 1, 1]             256\n","            ReLU-182            [-1, 128, 1, 1]               0\n","          Conv2d-183            [-1, 128, 1, 1]         147,584\n","     BatchNorm2d-184            [-1, 128, 1, 1]             256\n","            ReLU-185            [-1, 128, 1, 1]               0\n","          Conv2d-186            [-1, 256, 1, 1]          33,024\n","      Bottleneck-187            [-1, 256, 1, 1]               0\n","     BatchNorm2d-188            [-1, 256, 1, 1]             512\n","            ReLU-189            [-1, 256, 1, 1]               0\n","          Conv2d-190            [-1, 128, 1, 1]          32,896\n","     BatchNorm2d-191            [-1, 128, 1, 1]             256\n","            ReLU-192            [-1, 128, 1, 1]               0\n","          Conv2d-193            [-1, 128, 1, 1]         147,584\n","     BatchNorm2d-194            [-1, 128, 1, 1]             256\n","            ReLU-195            [-1, 128, 1, 1]               0\n","          Conv2d-196            [-1, 256, 1, 1]          33,024\n","      Bottleneck-197            [-1, 256, 1, 1]               0\n","     BatchNorm2d-198            [-1, 256, 1, 1]             512\n","            ReLU-199            [-1, 256, 1, 1]               0\n","          Conv2d-200            [-1, 128, 1, 1]          32,896\n","     BatchNorm2d-201            [-1, 128, 1, 1]             256\n","            ReLU-202            [-1, 128, 1, 1]               0\n","          Conv2d-203            [-1, 128, 1, 1]         147,584\n","     BatchNorm2d-204            [-1, 128, 1, 1]             256\n","            ReLU-205            [-1, 128, 1, 1]               0\n","          Conv2d-206            [-1, 256, 1, 1]          33,024\n","      Bottleneck-207            [-1, 256, 1, 1]               0\n","     BatchNorm2d-208            [-1, 256, 1, 1]             512\n","            ReLU-209            [-1, 256, 1, 1]               0\n","          Conv2d-210            [-1, 128, 1, 1]          32,896\n","     BatchNorm2d-211            [-1, 128, 1, 1]             256\n","            ReLU-212            [-1, 128, 1, 1]               0\n","          Conv2d-213            [-1, 128, 1, 1]         147,584\n","     BatchNorm2d-214            [-1, 128, 1, 1]             256\n","            ReLU-215            [-1, 128, 1, 1]               0\n","          Conv2d-216            [-1, 256, 1, 1]          33,024\n","      Bottleneck-217            [-1, 256, 1, 1]               0\n","     BatchNorm2d-218            [-1, 256, 1, 1]             512\n","            ReLU-219            [-1, 256, 1, 1]               0\n","          Conv2d-220            [-1, 128, 1, 1]          32,896\n","     BatchNorm2d-221            [-1, 128, 1, 1]             256\n","            ReLU-222            [-1, 128, 1, 1]               0\n","          Conv2d-223            [-1, 128, 1, 1]         147,584\n","     BatchNorm2d-224            [-1, 128, 1, 1]             256\n","            ReLU-225            [-1, 128, 1, 1]               0\n","          Conv2d-226            [-1, 256, 1, 1]          33,024\n","      Bottleneck-227            [-1, 256, 1, 1]               0\n","     BatchNorm2d-228            [-1, 256, 1, 1]             512\n","            ReLU-229            [-1, 256, 1, 1]               0\n","          Conv2d-230            [-1, 128, 1, 1]          32,896\n","     BatchNorm2d-231            [-1, 128, 1, 1]             256\n","            ReLU-232            [-1, 128, 1, 1]               0\n","          Conv2d-233            [-1, 128, 1, 1]         147,584\n","     BatchNorm2d-234            [-1, 128, 1, 1]             256\n","            ReLU-235            [-1, 128, 1, 1]               0\n","          Conv2d-236            [-1, 256, 1, 1]          33,024\n","      Bottleneck-237            [-1, 256, 1, 1]               0\n","     BatchNorm2d-238            [-1, 256, 2, 2]             512\n","            ReLU-239            [-1, 256, 2, 2]               0\n","          Conv2d-240            [-1, 128, 2, 2]          32,896\n","     BatchNorm2d-241            [-1, 128, 2, 2]             256\n","            ReLU-242            [-1, 128, 2, 2]               0\n","          Conv2d-243            [-1, 128, 2, 2]         147,584\n","     BatchNorm2d-244            [-1, 128, 2, 2]             256\n","            ReLU-245            [-1, 128, 2, 2]               0\n","          Conv2d-246            [-1, 256, 2, 2]          33,024\n","      Bottleneck-247            [-1, 256, 2, 2]               0\n","     BatchNorm2d-248            [-1, 256, 2, 2]             512\n","            ReLU-249            [-1, 256, 2, 2]               0\n","          Conv2d-250            [-1, 128, 2, 2]          32,896\n","     BatchNorm2d-251            [-1, 128, 2, 2]             256\n","            ReLU-252            [-1, 128, 2, 2]               0\n","          Conv2d-253            [-1, 128, 2, 2]         147,584\n","     BatchNorm2d-254            [-1, 128, 2, 2]             256\n","            ReLU-255            [-1, 128, 2, 2]               0\n","          Conv2d-256            [-1, 256, 2, 2]          33,024\n","      Bottleneck-257            [-1, 256, 2, 2]               0\n","     BatchNorm2d-258            [-1, 256, 4, 4]             512\n","            ReLU-259            [-1, 256, 4, 4]               0\n","          Conv2d-260            [-1, 128, 4, 4]          32,896\n","     BatchNorm2d-261            [-1, 128, 4, 4]             256\n","            ReLU-262            [-1, 128, 4, 4]               0\n","          Conv2d-263            [-1, 128, 4, 4]         147,584\n","     BatchNorm2d-264            [-1, 128, 4, 4]             256\n","            ReLU-265            [-1, 128, 4, 4]               0\n","          Conv2d-266            [-1, 256, 4, 4]          33,024\n","      Bottleneck-267            [-1, 256, 4, 4]               0\n","     BatchNorm2d-268            [-1, 256, 4, 4]             512\n","            ReLU-269            [-1, 256, 4, 4]               0\n","          Conv2d-270            [-1, 128, 4, 4]          32,896\n","     BatchNorm2d-271            [-1, 128, 4, 4]             256\n","            ReLU-272            [-1, 128, 4, 4]               0\n","          Conv2d-273            [-1, 128, 4, 4]         147,584\n","     BatchNorm2d-274            [-1, 128, 4, 4]             256\n","            ReLU-275            [-1, 128, 4, 4]               0\n","          Conv2d-276            [-1, 256, 4, 4]          33,024\n","      Bottleneck-277            [-1, 256, 4, 4]               0\n","     BatchNorm2d-278            [-1, 256, 8, 8]             512\n","            ReLU-279            [-1, 256, 8, 8]               0\n","          Conv2d-280            [-1, 128, 8, 8]          32,896\n","     BatchNorm2d-281            [-1, 128, 8, 8]             256\n","            ReLU-282            [-1, 128, 8, 8]               0\n","          Conv2d-283            [-1, 128, 8, 8]         147,584\n","     BatchNorm2d-284            [-1, 128, 8, 8]             256\n","            ReLU-285            [-1, 128, 8, 8]               0\n","          Conv2d-286            [-1, 256, 8, 8]          33,024\n","      Bottleneck-287            [-1, 256, 8, 8]               0\n","     BatchNorm2d-288            [-1, 256, 8, 8]             512\n","            ReLU-289            [-1, 256, 8, 8]               0\n","          Conv2d-290            [-1, 128, 8, 8]          32,896\n","     BatchNorm2d-291            [-1, 128, 8, 8]             256\n","            ReLU-292            [-1, 128, 8, 8]               0\n","          Conv2d-293            [-1, 128, 8, 8]         147,584\n","     BatchNorm2d-294            [-1, 128, 8, 8]             256\n","            ReLU-295            [-1, 128, 8, 8]               0\n","          Conv2d-296            [-1, 256, 8, 8]          33,024\n","      Bottleneck-297            [-1, 256, 8, 8]               0\n","       Hourglass-298          [-1, 256, 16, 16]               0\n","     BatchNorm2d-299          [-1, 256, 16, 16]             512\n","            ReLU-300          [-1, 256, 16, 16]               0\n","          Conv2d-301          [-1, 128, 16, 16]          32,896\n","     BatchNorm2d-302          [-1, 128, 16, 16]             256\n","            ReLU-303          [-1, 128, 16, 16]               0\n","          Conv2d-304          [-1, 128, 16, 16]         147,584\n","     BatchNorm2d-305          [-1, 128, 16, 16]             256\n","            ReLU-306          [-1, 128, 16, 16]               0\n","          Conv2d-307          [-1, 256, 16, 16]          33,024\n","      Bottleneck-308          [-1, 256, 16, 16]               0\n","     BatchNorm2d-309          [-1, 256, 16, 16]             512\n","            ReLU-310          [-1, 256, 16, 16]               0\n","          Conv2d-311          [-1, 128, 16, 16]          32,896\n","     BatchNorm2d-312          [-1, 128, 16, 16]             256\n","            ReLU-313          [-1, 128, 16, 16]               0\n","          Conv2d-314          [-1, 128, 16, 16]         147,584\n","     BatchNorm2d-315          [-1, 128, 16, 16]             256\n","            ReLU-316          [-1, 128, 16, 16]               0\n","          Conv2d-317          [-1, 256, 16, 16]          33,024\n","      Bottleneck-318          [-1, 256, 16, 16]               0\n","          Conv2d-319          [-1, 256, 16, 16]          65,792\n","     BatchNorm2d-320          [-1, 256, 16, 16]             512\n","            ReLU-321          [-1, 256, 16, 16]               0\n","            ReLU-322          [-1, 256, 16, 16]               0\n","          Conv2d-323           [-1, 22, 16, 16]           5,654\n","================================================================\n","Total params: 6,591,894\n","Trainable params: 6,591,894\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.05\n","Forward/backward pass size (MB): 39.77\n","Params size (MB): 25.15\n","Estimated Total Size (MB): 64.96\n","----------------------------------------------------------------\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"_yXVDKXkHzs4","executionInfo":{"status":"ok","timestamp":1649572483055,"user_tz":-540,"elapsed":3,"user":{"displayName":"Jaehoon Kim","userId":"03064955329912050209"}}},"execution_count":18,"outputs":[]}]}