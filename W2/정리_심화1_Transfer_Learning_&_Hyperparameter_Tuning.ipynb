{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0dcdbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from tqdm.notebook import tqdm\n",
    "# 반복문의 진행상황을 보여줌\n",
    "# wrap any iterable with tqdm(iterable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf56409",
   "metadata": {},
   "source": [
    "### mnist_resnet18 (untrained model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f987cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST를 학습할 ResNet18 model (pretrained=False)\n",
    "\n",
    "mnist_resnet18 = torchvision.models.resnet18(pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42830e0e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52c5959f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "# input channel dimension\n",
    "print(mnist_resnet18.conv1.weight.shape[1])\n",
    "# output channel dimension (prediction classes)\n",
    "print(mnist_resnet18.fc.weight.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba06289",
   "metadata": {},
   "source": [
    "### Modifying mnist_resnet18\n",
    "\n",
    "fully-connected layer channel: 1000 -> 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "806e2945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "MNIST_CLASS_NUM = 10\n",
    "\n",
    "# fully-connected layer의 out_features를 1000에서 10으로 바꿈\n",
    "mnist_resnet18.fc = torch.nn.Linear(in_features=512, out_features=MNIST_CLASS_NUM, bias=True)\n",
    "# 새로 바뀐 fc layer를 xavier uniform으로 initialization\n",
    "torch.nn.init.xavier_uniform_(mnist_resnet18.fc.weight)\n",
    "stdv = 1. / math.sqrt(mnist_resnet18.fc.weight.size(1))\n",
    "mnist_resnet18.fc.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "# input channel dimension\n",
    "print(mnist_resnet18.conv1.weight.shape[1])\n",
    "# output channel dimension (prediction classes)\n",
    "print(mnist_resnet18.fc.weight.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5037b2",
   "metadata": {},
   "source": [
    "### MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1693fa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = torchvision.datasets.MNIST(root='./mnist', train=True, download=True)\n",
    "mnist_test = torchvision.datasets.MNIST(root='./mnist', train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "309be629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "IMAGE_INDEX = 2\n",
    "plt.imshow(mnist_train[IMAGE_INDEX][0])\n",
    "\n",
    "print(mnist_train[IMAGE_INDEX][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d6a351",
   "metadata": {},
   "source": [
    "### MNIST dataset transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b32dd293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'PIL.Image.Image'>\n",
      "(28, 28)\n",
      "<class 'torch.Tensor'>\n",
      "(3, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# torchvision.datasets.mnist의 데이터타입은 PIL Image.\n",
    "# torch.Tensor로 변경해줘야.\n",
    "print(type(mnist_train[0][0]))\n",
    "# 데이터는 channel이 1개 (grayscale).\n",
    "# 모델은 3개.\n",
    "print(np.array(mnist_train[0][0]).shape)\n",
    "\n",
    "# grayscale의 1채널 영상을 3채널로 확장함.\n",
    "# PIL Image를 torch.Tensor로 변경함.\n",
    "common_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Grayscale(num_output_channels=3),\n",
    "    torchvision.transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# transform 적용\n",
    "mnist_train_transformed = torchvision.datasets.MNIST(root='./mnist', train=True, download=True, transform=common_transform)\n",
    "mnist_test_transformed = torchvision.datasets.MNIST(root='./mnist', train=False, download=True, transform=common_transform)\n",
    "\n",
    "print(type(mnist_train_transformed[0][0]))\n",
    "print(np.array(mnist_train_transformed[0][0]).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f4ff83",
   "metadata": {},
   "source": [
    "### dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbfabc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "# should be num_workers=2, but it gives warning\n",
    "# num_workers=0 kills parallel computing, but gets rid of the warning\n",
    "mnist_train_dataloader = torch.utils.data.DataLoader(mnist_train_transformed, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "mnist_test_dataloader = torch.utils.data.DataLoader(mnist_test_transformed, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "dataloaders = {'train': mnist_train_dataloader, \n",
    "               'test': mnist_test_dataloader}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42927240",
   "metadata": {},
   "source": [
    "### device, lr, loss_fn, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "901f176b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "mnist_resnet18.to(device)\n",
    "\n",
    "LEARNING_RATE = 0.0001\n",
    "\n",
    "NUM_EPOCH = 5\n",
    "\n",
    "# loss function is cross-entropy loss\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer 결정함. 모델의 파라미터와 lr 지정해줘야.\n",
    "optimizer = torch.optim.Adam(mnist_resnet18.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3823fa6a",
   "metadata": {},
   "source": [
    "### Train and test \n",
    "\n",
    "`model.train()`\n",
    "`model.eval()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6bfb330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d2804c50ad84fbc860249d7b8ff7329",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Phase: train, Average Loss: 0.190, Average Accuracy: 0.941\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a2e08dcaf464c15853c2dcadd31654e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Phase: test, Average Loss: 0.069, Average Accuracy: 0.978\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b774ec3ce0741c8bc0735f3646a7682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Phase: train, Average Loss: 0.057, Average Accuracy: 0.982\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2ef29a7174b404c92f3b89ad7876566",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Phase: test, Average Loss: 0.060, Average Accuracy: 0.981\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b63bdcbf31324253acf70c03cce0c5ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Phase: train, Average Loss: 0.040, Average Accuracy: 0.987\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb07de26b4084b39adeb3f23966e8971",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Phase: test, Average Loss: 0.051, Average Accuracy: 0.984\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f416daaaffa4748a608069012273040",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Phase: train, Average Loss: 0.034, Average Accuracy: 0.989\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a658210ac4e44879f6443a7f6a29b84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Phase: test, Average Loss: 0.043, Average Accuracy: 0.986\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e14151df8fe74902a74102dd6e7da12e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Phase: train, Average Loss: 0.028, Average Accuracy: 0.991\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcb5f5c6b86d4b44b847ab7d3226067d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Phase: test, Average Loss: 0.041, Average Accuracy: 0.987\n",
      "Best Accuracy: 0.9873999953269958, Best Loss: 0.04104293988384306\n"
     ]
    }
   ],
   "source": [
    "best_test_accuracy = 0.\n",
    "best_test_loss = 9999.\n",
    "\n",
    "for epoch in range(NUM_EPOCH):\n",
    "    for phase in ['train', 'test']:\n",
    "        \n",
    "        running_loss = 0.\n",
    "        running_acc = 0.\n",
    "        \n",
    "        if phase=='train':\n",
    "            mnist_resnet18.train()\n",
    "        elif phase=='test':\n",
    "            mnist_resnet18.eval()\n",
    "            \n",
    "        for ind, (images, labels) in enumerate(tqdm(dataloaders[phase])):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # initialize gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # train 모드일 시에는 gradient를 계산하고, \n",
    "            # 아닐 때는 gradient를 계산하지 않아 연산량 최소화\n",
    "            with torch.set_grad_enabled(phase=='train'):\n",
    "                \n",
    "                # yhat\n",
    "                logits = mnist_resnet18(images)\n",
    "                \n",
    "                # 모델에서 linear 값으로 나오는 예측 값 ([0.9,1.2, 3.2,0.1,-0.1,...])을 \n",
    "                # 최대 output index를 찾아 예측 레이블([2])로 변경함\n",
    "                # ???\n",
    "                _, preds = torch.max(logits, 1)\n",
    "                \n",
    "                loss = loss_fn(logits, labels)\n",
    "                \n",
    "                if phase=='train':\n",
    "                    loss.backward() # gradient 계산\n",
    "                    optimizer.step() # parameter update\n",
    "            \n",
    "            # 한 batch에서의 loss값 저장\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            # 한 batch에서의 accuracy값 저장\n",
    "            running_acc += torch.sum(preds == labels.data)\n",
    "            \n",
    "        epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "        epoch_acc = running_acc / len(dataloaders[phase].dataset)\n",
    "        \n",
    "        print(f'Epoch: {epoch}, Phase: {phase}, Average Loss: {epoch_loss:.3f}, Average Accuracy: {epoch_acc:.3f}')\n",
    "        \n",
    "        if phase=='test' and best_test_accuracy < epoch_acc:\n",
    "            best_test_accuracy = epoch_acc\n",
    "        if phase=='test' and best_test_loss > epoch_loss:\n",
    "            best_test_loss = epoch_loss\n",
    "            \n",
    "print(f'Best Accuracy: {best_test_accuracy}, Best Loss: {best_test_loss}')\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a0ebca",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91897f1",
   "metadata": {},
   "source": [
    "### fashion_resnet18 (pretrained model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7579aa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fashion-MNIST를 학습할 ResNet18 model (pretrained=True)\n",
    "\n",
    "fashion_resnet18 = torchvision.models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df4d548c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fashion_resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "349169e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "# input channel dimension\n",
    "print(fashion_resnet18.conv1.weight.shape[1])\n",
    "# output channel dimension (prediction classes)\n",
    "print(fashion_resnet18.fc.weight.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eee5efb",
   "metadata": {},
   "source": [
    "### Modifying fashion_resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c286b0d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "FASHION_INPUT_NUM = 1\n",
    "FASHION_CLASS_NUM = 10\n",
    "\n",
    "# Modifying the model\n",
    "fashion_resnet18.conv1 = torch.nn.Conv2d(FASHION_INPUT_NUM, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "fashion_resnet18.fc = torch.nn.Linear(in_features=512, out_features=FASHION_CLASS_NUM, bias=True)\n",
    "# Initializing parameters with xavier uniform\n",
    "torch.nn.init.xavier_uniform_(fashion_resnet18.fc.weight)\n",
    "stdv = 1. / math.sqrt(fashion_resnet18.fc.weight.size(1))\n",
    "fashion_resnet18.fc.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "print(fashion_resnet18.conv1.weight.shape[1])\n",
    "print(fashion_resnet18.fc.weight.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121542e4",
   "metadata": {},
   "source": [
    "### Fashion-MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8aa7ad9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_train = torchvision.datasets.FashionMNIST(root='./fashion', train=True, download=True)\n",
    "fashion_test = torchvision.datasets.FashionMNIST(root='./fashion', train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97352390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "IMAGE_INDEX = 2 \n",
    "plt.imshow(fashion_train[IMAGE_INDEX][0])\n",
    "\n",
    "print(fashion_train[IMAGE_INDEX][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfc5c89",
   "metadata": {},
   "source": [
    "### Fashion-MNIST dataset transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34162011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'PIL.Image.Image'>\n",
      "(28, 28)\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print(type(fashion_train[0][0]))\n",
    "print(np.array(fashion_train[0][0]).shape)\n",
    "\n",
    "common_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor()\n",
    "])\n",
    "\n",
    "fashion_train_transformed = torchvision.datasets.FashionMNIST(root='./fashion', train=True, download=True, transform=common_transform)\n",
    "fashion_test_transformed = torchvision.datasets.FashionMNIST(root='./fashion', train=False, download=True, transform=common_transform)\n",
    "\n",
    "print(type(fashion_train_transformed[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6588fc1d",
   "metadata": {},
   "source": [
    "### dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69d70ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "fashion_train_dataloader = torch.utils.data.DataLoader(fashion_train_transformed, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "fashion_test_dataloader = torch.utils.data.DataLoader(fashion_test_transformed, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "dataloaders = {\"train\" : fashion_train_dataloader, \n",
    "               \"test\" : fashion_test_dataloader}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136cb868",
   "metadata": {},
   "source": [
    "### device, lr, loss_fn, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8550cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n",
    "print(device)\n",
    "fashion_resnet18.to(device)\n",
    "\n",
    "LEARNING_RATE = 0.0001 \n",
    "\n",
    "NUM_EPOCH = 5\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss() \n",
    "\n",
    "optimizer = torch.optim.Adam(fashion_resnet18.parameters(), lr=LEARNING_RATE) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e09aee",
   "metadata": {},
   "source": [
    "### Train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3adb87a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "218af24dfcfc4a15bc114bc999770d3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Phase: train, Average Loss: 0.589, Average Accuracy: 0.790\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdf815e5ffaf42e79a2a5f7baaadc2e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Phase: test, Average Loss: 0.426, Average Accuracy: 0.839\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "009cb9fc5566482d9c3df57d262fba99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Phase: train, Average Loss: 0.373, Average Accuracy: 0.862\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "751777a18a8942679e422da5b500b2e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Phase: test, Average Loss: 0.348, Average Accuracy: 0.873\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c085019d8eb4f45a51fb79cf994afbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Phase: train, Average Loss: 0.316, Average Accuracy: 0.883\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b423dd55c684bb0aaa7fbda33f2ef11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Phase: test, Average Loss: 0.322, Average Accuracy: 0.885\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f6ed8e38a104d5d8ba19a4673d5994a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Phase: train, Average Loss: 0.276, Average Accuracy: 0.898\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba36d701caa547d8bd2fe7c2e7c0639b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Phase: test, Average Loss: 0.304, Average Accuracy: 0.892\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dd6a338fc3a49ddbe11567edc4e1490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Phase: train, Average Loss: 0.248, Average Accuracy: 0.908\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "904b7def473a49bb8f846b5e72a7f838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Phase: test, Average Loss: 0.307, Average Accuracy: 0.890\n",
      "Best Accuracy: 0.8917999863624573, Best Loss: 0.30445397114753725\n"
     ]
    }
   ],
   "source": [
    "best_test_accuracy = 0.\n",
    "best_test_loss = 9999.\n",
    "\n",
    "for epoch in range(NUM_EPOCH):\n",
    "    for phase in ['train', 'test']:\n",
    "        \n",
    "        running_loss = 0.\n",
    "        running_acc = 0.\n",
    "        \n",
    "        if phase=='train':\n",
    "            fashion_resnet18.train()\n",
    "        elif phase=='test':\n",
    "            fashion_resnet18.eval()\n",
    "            \n",
    "        for ind, (images, labels) in enumerate(tqdm(dataloaders[phase])):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # initialize gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # train 모드일 시에는 gradient를 계산하고, \n",
    "            # 아닐 때는 gradient를 계산하지 않아 연산량 최소화\n",
    "            with torch.set_grad_enabled(phase=='train'):\n",
    "                \n",
    "                # yhat\n",
    "                logits = fashion_resnet18(images)\n",
    "                \n",
    "                # 모델에서 linear 값으로 나오는 예측 값 ([0.9,1.2, 3.2,0.1,-0.1,...])을 \n",
    "                # 최대 output index를 찾아 예측 레이블([2])로 변경함\n",
    "                # ???\n",
    "                _, preds = torch.max(logits, 1)\n",
    "                \n",
    "                loss = loss_fn(logits, labels)\n",
    "                \n",
    "                if phase=='train':\n",
    "                    loss.backward() # gradient 계산\n",
    "                    optimizer.step() # parameter update\n",
    "            \n",
    "            # 한 batch에서의 loss값 저장\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            # 한 batch에서의 accuracy값 저장\n",
    "            running_acc += torch.sum(preds == labels.data)\n",
    "            \n",
    "        epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "        epoch_acc = running_acc / len(dataloaders[phase].dataset)\n",
    "        \n",
    "        print(f'Epoch: {epoch}, Phase: {phase}, Average Loss: {epoch_loss:.3f}, Average Accuracy: {epoch_acc:.3f}')\n",
    "        \n",
    "        if phase=='test' and best_test_accuracy < epoch_acc:\n",
    "            best_test_accuracy = epoch_acc\n",
    "        if phase=='test' and best_test_loss > epoch_loss:\n",
    "            best_test_loss = epoch_loss\n",
    "            \n",
    "print(f'Best Accuracy: {best_test_accuracy}, Best Loss: {best_test_loss}')\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3aeb89",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acf6a3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
