{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b61b533",
   "metadata": {},
   "source": [
    "# PyTorch Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a11e94a",
   "metadata": {},
   "source": [
    "### torch.Tensor vs. torch.tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce701ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.Tensor \n",
    "# is a class.\n",
    "# if input data is torch.Tensor, shares the memory space.\n",
    "# if input data is list or numpy, copies the data.\n",
    "# transforms input data into 32-bit floating point data type.\n",
    "# also refers to the torch.Tensor data type??\n",
    "\n",
    "# torch.tensor \n",
    "# is a function.\n",
    "# always copies input data.\n",
    "# infers input data's data type, unless specified by dtype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38b6de43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.]) tensor([1.])\n",
      "tensor([2.]) tensor([2.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# torch.Tensor - torch.Tensor input\n",
    "orig_data = torch.Tensor([1])\n",
    "\n",
    "new_data = torch.Tensor(orig_data)\n",
    "print(orig_data, new_data)\n",
    "\n",
    "orig_data[0] = 2\n",
    "print(orig_data, new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2391c0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] tensor([1.])\n",
      "[2] tensor([1.])\n"
     ]
    }
   ],
   "source": [
    "# torch.Tensor - list, numpy input\n",
    "orig_data = [1]\n",
    "\n",
    "new_data = torch.Tensor(orig_data)\n",
    "print(orig_data, new_data)\n",
    "\n",
    "orig_data[0] = 2\n",
    "print(orig_data, new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bfb1c01c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.]) tensor([1.])\n",
      "tensor([2.]) tensor([1.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lh/13z6kjx97lsd31q5h0712_mm0000gn/T/ipykernel_20286/2575792912.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  new_data = torch.tensor(orig_data)\n"
     ]
    }
   ],
   "source": [
    "# torch.tensor - torch.Tensor input\n",
    "\n",
    "orig_data = torch.tensor([1])\n",
    "# orig_data = torch.Tensor([1]) # ì²˜ìŒ declare í• ë• ë­ ì“°ì§€? ë…¸ìƒê´€?\n",
    "new_data = torch.tensor(orig_data)\n",
    "print(orig_data, new_data)\n",
    "\n",
    "orig_data[0] = 2\n",
    "print(orig_data, new_data)\n",
    "\n",
    "# ì›Œë‹ ë‚´ìš©ì€ ëŒ€ì¶© if you want to avoid a copy, use these functions ì¸ë“¯."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bfea7264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.Tensor([1])\n",
    "type(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2b535c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.Tensor([1])\n",
    "type(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc03a34",
   "metadata": {},
   "source": [
    "### index_select\n",
    "### axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e538a6f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.],\n",
      "        [3.]])\n",
      "tensor([1., 3.])\n"
     ]
    }
   ],
   "source": [
    "# index_select\n",
    "\n",
    "import torch\n",
    "\n",
    "A = torch.Tensor([[1, 2],\n",
    "                  [3, 4]])\n",
    "\n",
    "# TODO : [1, 3]ì„ ë§Œë“œì„¸ìš”!\n",
    "\n",
    "index = torch.tensor([0]) # must use int type for index\n",
    "output = torch.index_select(A, 1, index)\n",
    "print(output)\n",
    "\n",
    "output = output.reshape(-1)\n",
    "# output = output.view(-1) # tfì—ì„  reshapeì¸ë° ê± reshape ì“°ë©´ ì•ˆë¨?\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1cb64bfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 3.])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = A[:, 0] # ì´ê±¸ë¡œë„ ê°€ëŠ¥\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "898c1e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# axis test\n",
    "\n",
    "output = torch.index_select(A, 0, index)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ae6d4027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2],\n",
       "         [3, 4]],\n",
       "\n",
       "        [[5, 6],\n",
       "         [7, 8]]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# axis test - 3D\n",
    "\n",
    "A = torch.arange(1, 9)\n",
    "A = A.reshape(2, 2, 2)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5c456d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = torch.index_select(A, 0, index)\n",
    "output\n",
    "\n",
    "# check the axis orientation - from [1] to [5]\n",
    "# this is the 'most complicated' axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c8b3a9ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2]],\n",
       "\n",
       "        [[5, 6]]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = torch.index_select(A, 1, index)\n",
    "output\n",
    "\n",
    "# check the axis orientation - from [1] to [3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b1243112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1],\n",
       "         [3]],\n",
       "\n",
       "        [[5],\n",
       "         [7]]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = torch.index_select(A, 2, index)\n",
    "output\n",
    "\n",
    "# check the axis orientation - from [1] to [2]\n",
    "# this is the 'simplest' axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e5cc8344",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 2])\n",
      "tensor([[[ 1,  2],\n",
      "         [ 3,  4],\n",
      "         [ 5,  6]],\n",
      "\n",
      "        [[ 7,  8],\n",
      "         [ 9, 10],\n",
      "         [11, 12]],\n",
      "\n",
      "        [[13, 14],\n",
      "         [15, 16],\n",
      "         [17, 18]],\n",
      "\n",
      "        [[19, 20],\n",
      "         [21, 22],\n",
      "         [23, 24]]])\n"
     ]
    }
   ],
   "source": [
    "A = torch.arange(1, 25)\n",
    "A = A.reshape(4, 3, 2)\n",
    "print(A.shape)\n",
    "print(A)\n",
    "\n",
    "# axis 0: 4\n",
    "# axis 1: 3\n",
    "# axis 2: 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690a932a",
   "metadata": {},
   "source": [
    "### gather\n",
    "### view, reshape\n",
    "### expand, repeat\n",
    "### unsqueeze, squeeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "da412d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.],\n",
      "        [4.]])\n",
      "tensor([1., 4.])\n"
     ]
    }
   ],
   "source": [
    "# 2D gather\n",
    "\n",
    "A = torch.Tensor([[1, 2],\n",
    "                  [3, 4]])\n",
    "\n",
    "index = torch.tensor([[0],\n",
    "                      [1]])\n",
    "output = torch.gather(A, 1, index)\n",
    "print(output)\n",
    "\n",
    "output = output.reshape(-1)\n",
    "print(output)\n",
    "\n",
    "# 'from [1] to [3]' axis ì˜ ë°©í–¥ìœ¼ë¡œ ì²«ë²ˆì§¸ ë¼ì¸ì—ì„œ index 0, \n",
    "# 1ë²ˆì§¸ ë¼ì¸ì—ì„œ index 1ì— í•´ë‹¹í•˜ëŠ” ê°’ë“¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a1557c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.],\n",
      "         [4.]],\n",
      "\n",
      "        [[5.],\n",
      "         [8.]]])\n",
      "tensor([[1., 4.],\n",
      "        [5., 8.]])\n"
     ]
    }
   ],
   "source": [
    "# 3D gather\n",
    "\n",
    "A = torch.Tensor([[[1, 2],\n",
    "                   [3, 4]],\n",
    "                  \n",
    "                  [[5, 6],\n",
    "                   [7, 8]]])\n",
    "\n",
    "index = torch.tensor([[[0],\n",
    "                       [1]],\n",
    "                      [[0],\n",
    "                       [1]]])\n",
    "output = torch.gather(A, 2, index)\n",
    "print(output)\n",
    "# axisê°€ 2ì„. The simplest axis. 'from [1] to [2]' axis.\n",
    "# ì´ 4ê°œì˜ ë¼ì¸ì— ëŒ€í•´ index 0, 1, 0, 1ì— í•´ë‹¹í•˜ëŠ” ê°’ì„ gather.\n",
    "\n",
    "output = output.reshape(2, 2)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "7433de9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2, 3],\n",
      "         [4, 5, 6]]])\n",
      "gather_index:\n",
      "tensor([[[0],\n",
      "         [1]]])\n",
      "tensor([[1, 5]])\n"
     ]
    }
   ],
   "source": [
    "# 3D gather - arbitrary size\n",
    "\n",
    "# TODO : ì„ì˜ì˜ í¬ê¸°ì˜ 3D tensorì—ì„œ ëŒ€ê°ì„  ìš”ì†Œ ê°€ì ¸ì™€ 2Dë¡œ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜ë¥¼ ë§Œë“œì„¸ìš”! \n",
    "def get_diag_element_3D(A):\n",
    "    \n",
    "    C, H, W = A.shape\n",
    "    diag_size = min(H, W) \n",
    "    # C axis (channel axis = 0-axis = depth axis) is fixed.\n",
    "    # H-W planeì— diagonal lineì„ ê·¸ë¦¬ëŠ” ê²ƒ.\n",
    "    \n",
    "    # gather_index = torch.arange(diag_size).view(diag_size, -1).expand(C, diag_size, 1)\n",
    "    gather_index = torch.arange(diag_size).reshape(diag_size, 1).expand(C, diag_size, 1)\n",
    "    # view vs. reshape: reshape doesn't impose any contiguity constraints,\n",
    "    # but also doesn't gunarantee data sharing. \n",
    "    print('gather_index:')\n",
    "    print(gather_index)\n",
    "    \n",
    "    output = torch.gather(A, 2, gather_index)\n",
    "    output = output.view(C, diag_size)\n",
    "\n",
    "    return output\n",
    "\n",
    "C = 1\n",
    "H = 2\n",
    "W = 3\n",
    "\n",
    "A = torch.tensor([i for i in range(1, C*H*W + 1)])\n",
    "A = A.reshape(C, H, W)\n",
    "print(A)\n",
    "\n",
    "A = get_diag_element_3D(A)\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "1b6d6210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gather_index:\n",
      "tensor([[[0]]])\n",
      "ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\n"
     ]
    }
   ],
   "source": [
    "# ì•„ë˜ ì½”ë“œëŠ” ìˆ˜ì •í•˜ì‹¤ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤!\n",
    "A = torch.tensor([[[1]]])\n",
    "\n",
    "if torch.all(get_diag_element_3D(A) == torch.Tensor([[1]])):\n",
    "    print(\"ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\")\n",
    "else:\n",
    "    print(\"ğŸ¦† ë‹¤ì‹œ ë„ì „í•´ë´ìš”!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "2d4e2751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gather_index:\n",
      "tensor([[[0],\n",
      "         [1]],\n",
      "\n",
      "        [[0],\n",
      "         [1]]])\n",
      "ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\n"
     ]
    }
   ],
   "source": [
    "# ì•„ë˜ ì½”ë“œëŠ” ìˆ˜ì •í•˜ì‹¤ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤!\n",
    "A = torch.Tensor([[[1, 2],\n",
    "                   [3, 4]],\n",
    "                  [[5, 6],\n",
    "                   [7, 8]]])\n",
    "\n",
    "if torch.all(get_diag_element_3D(A) == torch.Tensor([[1, 4],\n",
    "                                                     [5, 8]])):\n",
    "    print(\"ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\")\n",
    "else:\n",
    "    print(\"ğŸ¦† ë‹¤ì‹œ ë„ì „í•´ë´ìš”!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "a11f91fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gather_index:\n",
      "tensor([[[0],\n",
      "         [1]]])\n",
      "ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\n"
     ]
    }
   ],
   "source": [
    "# ì•„ë˜ ì½”ë“œëŠ” ìˆ˜ì •í•˜ì‹¤ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤!\n",
    "A = torch.Tensor([[[1, 2, 3],\n",
    "                   [4, 5, 6]]])\n",
    "\n",
    "if torch.all(get_diag_element_3D(A) == torch.Tensor([[1, 5]])):\n",
    "    print(\"ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\")\n",
    "else:\n",
    "    print(\"ğŸ¦† ë‹¤ì‹œ ë„ì „í•´ë´ìš”!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "62d981c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gather_index:\n",
      "tensor([[[0],\n",
      "         [1],\n",
      "         [2]],\n",
      "\n",
      "        [[0],\n",
      "         [1],\n",
      "         [2]]])\n",
      "ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\n"
     ]
    }
   ],
   "source": [
    "# ì•„ë˜ ì½”ë“œëŠ” ìˆ˜ì •í•˜ì‹¤ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤!\n",
    "A = torch.tensor([[[ 1,  2,  3,  4,  5],\n",
    "                   [ 6,  7,  8,  9, 10],\n",
    "                   [11, 12, 13, 14, 15]],\n",
    "          \n",
    "                  [[16, 17, 18, 19, 20],\n",
    "                   [21, 22, 23, 24, 25],\n",
    "                   [26, 27, 28, 29, 30]]])\n",
    "\n",
    "if torch.all(get_diag_element_3D(A) == torch.Tensor([[ 1,  7, 13],\n",
    "                                                     [16, 22, 28]])):\n",
    "    print(\"ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\")\n",
    "else:\n",
    "    print(\"ğŸ¦† ë‹¤ì‹œ ë„ì „í•´ë´ìš”!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "136771bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gather_index:\n",
      "tensor([[[0],\n",
      "         [1],\n",
      "         [2]],\n",
      "\n",
      "        [[0],\n",
      "         [1],\n",
      "         [2]],\n",
      "\n",
      "        [[0],\n",
      "         [1],\n",
      "         [2]]])\n",
      "ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\n"
     ]
    }
   ],
   "source": [
    "# ì•„ë˜ ì½”ë“œëŠ” ìˆ˜ì •í•˜ì‹¤ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤!\n",
    "A = torch.tensor([[[ 1,  2,  3],\n",
    "                   [ 4,  5,  6],\n",
    "                   [ 7,  8,  9],\n",
    "                   [10, 11, 12],\n",
    "                   [13, 14, 15]],\n",
    "        \n",
    "                  [[16, 17, 18],\n",
    "                   [19, 20, 21],\n",
    "                   [22, 23, 24],\n",
    "                   [25, 26, 27],\n",
    "                   [28, 29, 30]],\n",
    "        \n",
    "                  [[31, 32, 33],\n",
    "                   [34, 35, 36],\n",
    "                   [37, 38, 39],\n",
    "                   [40, 41, 42],\n",
    "                   [43, 44, 45]]])\n",
    "\n",
    "if torch.all(get_diag_element_3D(A) == torch.Tensor([[ 1,  5,  9],\n",
    "                                                     [16, 20, 24],\n",
    "                                                     [31, 35, 39]])):\n",
    "    print(\"ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\")\n",
    "else:\n",
    "    print(\"ğŸ¦† ë‹¤ì‹œ ë„ì „í•´ë´ìš”!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "e6b8c01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 2])\n",
      "torch.Size([2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "A = torch.arange(1, 9)\n",
    "A = A.reshape(2, 2, 2)\n",
    "print(A.size())\n",
    "print(A.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "a4f68200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1])\n",
      "tensor([[0],\n",
      "        [1]])\n",
      "tensor([[[0],\n",
      "         [1]]])\n"
     ]
    }
   ],
   "source": [
    "# gather_index analysis\n",
    "\n",
    "C = 1\n",
    "H = 2\n",
    "W = 3\n",
    "\n",
    "diag_size = min(H, W) \n",
    "    \n",
    "# A = torch.tensor([i for i in range(1, C*H*W + 1)])\n",
    "# A = A.reshape(C, H, W)\n",
    "\n",
    "gather_index = torch.arange(diag_size)\n",
    "print(gather_index)\n",
    "\n",
    "gather_index = torch.arange(diag_size).reshape(diag_size, 1)\n",
    "print(gather_index)\n",
    "\n",
    "gather_index = torch.arange(diag_size).reshape(diag_size, 1).expand(C, diag_size, 1)\n",
    "print(gather_index)\n",
    "\n",
    "# output = torch.gather(A, 2, gather_index)    \n",
    "# output = output.view(C, diag_size)\n",
    "\n",
    "# print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "e4c73252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1],\n",
      "        [2]])\n",
      "tensor([[1, 1, 1],\n",
      "        [2, 2, 2]])\n",
      "tensor([[1, 1, 1, 1],\n",
      "        [2, 2, 2, 2]])\n",
      "tensor([[1, 1, 1],\n",
      "        [2, 2, 2],\n",
      "        [1, 1, 1],\n",
      "        [2, 2, 2]])\n"
     ]
    }
   ],
   "source": [
    "# expand vs. repeat\n",
    "\n",
    "t = torch.arange(1, 3)\n",
    "t = t.reshape(2, 1)\n",
    "print(t)\n",
    "\n",
    "# expand\n",
    "print(t.expand(2, 3)) # expand as a specified shape.\n",
    "print(t.expand(-1, 4)) # -1: do not change this axis.\n",
    "\n",
    "# repeat\n",
    "print(t.repeat(2, 3)) # repeat as many times as."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "8d79a365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1]],\n",
      "\n",
      "        [[2]],\n",
      "\n",
      "        [[3]]])\n",
      "tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# squeeze vs. unsqueeze\n",
    "\n",
    "t = torch.arange(1, 4)\n",
    "t = t.reshape(3, 1, 1)\n",
    "print(t)\n",
    "t = t.squeeze() # í¬ê¸°ê°€ 1ì¸ ì°¨ì›ì„ ì œê±°\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "53f63473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3])\n",
      "tensor([1, 2, 3])\n",
      "torch.Size([1, 3])\n",
      "tensor([[1, 2, 3]])\n",
      "torch.Size([1, 1, 3])\n",
      "tensor([[[1, 2, 3]]])\n"
     ]
    }
   ],
   "source": [
    "t = torch.arange(1, 4)\n",
    "print(t.shape)\n",
    "print(t)\n",
    "\n",
    "t = t.unsqueeze(0) # 0-axis is always the 'most complicated' axis\n",
    "print(t.shape)\n",
    "print(t)\n",
    "\n",
    "t = t.unsqueeze(0)\n",
    "print(t.shape)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44be424c",
   "metadata": {},
   "source": [
    "# nn.Module í´ë˜ìŠ¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "3b5ae253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get two numbers and add them together\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class Add(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, x1, x2):\n",
    "        output = torch.add(x1, x2)\n",
    "        \n",
    "        return output\n",
    "\n",
    "x1 = torch.tensor([1])\n",
    "x2 = torch.tensor([2])\n",
    "\n",
    "add = Add()\n",
    "\n",
    "output = add(x1, x2)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e71f0d7",
   "metadata": {},
   "source": [
    "### Module, nn.ModuleList, nn.ModuleDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "b8196c6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sequential\n",
    "# variable pre-run assignment in __init__()\n",
    "\n",
    "class Add(nn.Module):\n",
    "    def __init__(self, value): # value is initiated before run\n",
    "        super().__init__()\n",
    "        self.value = value # self.value\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x + self.value\n",
    "\n",
    "calculator = nn.Sequential(Add(3), # collection of modules\n",
    "                           Add(2),\n",
    "                           Add(5))\n",
    "\n",
    "x = torch.tensor([1])\n",
    "\n",
    "output = calculator(x)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "82f7857a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ModuleList\n",
    "\n",
    "class Add(nn.Module):\n",
    "    def __init__(self, value):\n",
    "        super().__init__()\n",
    "        self.value = value\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x + self.value\n",
    "\n",
    "class Calculator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # nn.ModuleList()\n",
    "        self.add_list = nn.ModuleList([Add(2), Add(3), Add(5)])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.add_list[1](x)\n",
    "        x = self.add_list[0](x)\n",
    "        x = self.add_list[2](x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "x = torch.tensor([1])\n",
    "\n",
    "calculator = Calculator()\n",
    "output = calculator(x)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "d4cc1f02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ModuleDict\n",
    "\n",
    "class Add(nn.Module):\n",
    "    def __init__(self, value):\n",
    "        super().__init__()\n",
    "        self.value = value\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x + self.value\n",
    "\n",
    "class Calculator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.add_dict = nn.ModuleDict({'add2': Add(2),\n",
    "                                       'add3': Add(3),\n",
    "                                       'add5': Add(5)})\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.add_dict['add3'](x)\n",
    "        x = self.add_dict['add2'](x)\n",
    "        x = self.add_dict['add5'](x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "x = torch.tensor([1])\n",
    "\n",
    "calculator = Calculator()\n",
    "output = calculator(x)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "27a862bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Function A Initialized\n",
      "        Function B Initialized\n",
      "    Layer AB Initialized\n",
      "        Function C Initialized\n",
      "        Function D Initialized\n",
      "    Layer CD Initialized\n",
      "Model ABCD Initialized\n",
      "\n",
      "Model ABCD started\n",
      "    Layer AB started\n",
      "        Function A started\n",
      "        Function A done\n",
      "        Function B started\n",
      "        Function B done\n",
      "    Layer AB done\n",
      "    Layer CD started\n",
      "        Function C started\n",
      "        Function C done\n",
      "        Function D started\n",
      "        Function D done\n",
      "    Layer CD done\n",
      "Model ABCD done\n",
      "\n",
      "ğŸ‰ğŸ‰ğŸ‰ ëª¨ë“  ë”¥ëŸ¬ë‹ ëª¨ë¸ì€ ì´ì²˜ëŸ¼ Moduleë“¤ì´ ìŒ“ì´ê³  ìŒ“ì—¬ì„œ ë§Œë“¤ì–´ì§‘ë‹ˆë‹¤! ğŸ‰ğŸ‰ğŸ‰\n",
      "ğŸ‰ğŸ‰ğŸ‰ íë¦„ì„ ëŠê»´ë³´ì‹œê³  ì´ íë¦„ì´ ì´í•´ê°€ ë˜ì‹  ë¶„ì€ ë‹¤ìŒìœ¼ë¡œ ê°€ì‹œë©´ ë©ë‹ˆë‹¤! ğŸ‰ğŸ‰\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "# Function\n",
    "class Function_A(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        print(f\"        Function A Initialized\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(f\"        Function A started\")\n",
    "        print(f\"        Function A done\")\n",
    "\n",
    "class Function_B(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        print(f\"        Function B Initialized\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(f\"        Function B started\")\n",
    "        print(f\"        Function B done\")\n",
    "\n",
    "class Function_C(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        print(f\"        Function C Initialized\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(f\"        Function C started\")\n",
    "        print(f\"        Function C done\")\n",
    "\n",
    "class Function_D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        print(f\"        Function D Initialized\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(f\"        Function D started\")\n",
    "        print(f\"        Function D done\")\n",
    "\n",
    "\n",
    "# Layer\n",
    "class Layer_AB(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.a = Function_A()\n",
    "        self.b = Function_B()\n",
    "\n",
    "        print(f\"    Layer AB Initialized\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(f\"    Layer AB started\")\n",
    "        self.a(x)\n",
    "        self.b(x)\n",
    "        print(f\"    Layer AB done\")\n",
    "\n",
    "class Layer_CD(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.c = Function_C()\n",
    "        self.d = Function_D()\n",
    "\n",
    "        print(f\"    Layer CD Initialized\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(f\"    Layer CD started\")\n",
    "        self.c(x)\n",
    "        self.d(x)\n",
    "        print(f\"    Layer CD done\")\n",
    "\n",
    "\n",
    "# Model\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.ab = Layer_AB()\n",
    "        self.cd = Layer_CD()\n",
    "\n",
    "        print(f\"Model ABCD Initialized\\n\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(f\"Model ABCD started\")\n",
    "        self.ab(x)\n",
    "        self.cd(x)\n",
    "        print(f\"Model ABCD done\\n\")\n",
    "\n",
    "\n",
    "x = torch.tensor([7])\n",
    "\n",
    "model = Model()\n",
    "model(x)\n",
    "\n",
    "print(\"ğŸ‰ğŸ‰ğŸ‰ ëª¨ë“  ë”¥ëŸ¬ë‹ ëª¨ë¸ì€ ì´ì²˜ëŸ¼ Moduleë“¤ì´ ìŒ“ì´ê³  ìŒ“ì—¬ì„œ ë§Œë“¤ì–´ì§‘ë‹ˆë‹¤! ğŸ‰ğŸ‰ğŸ‰\")\n",
    "print(\"ğŸ‰ğŸ‰ğŸ‰ íë¦„ì„ ëŠê»´ë³´ì‹œê³  ì´ íë¦„ì´ ì´í•´ê°€ ë˜ì‹  ë¶„ì€ ë‹¤ìŒìœ¼ë¡œ ê°€ì‹œë©´ ë©ë‹ˆë‹¤! ğŸ‰ğŸ‰\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36a99f4",
   "metadata": {},
   "source": [
    "### Parameter, Buffer, state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "167dfbb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 4., 4.],\n",
       "        [8., 8., 8.]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameter. ë¯¸ë¦¬ ë§Œë“¤ì–´ì§„ tensorë“¤ì„ nn.Module ì•ˆì— ë³´ê´€.\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "class Linear(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        \n",
    "        # initialize as parameter\n",
    "        self.W = Parameter(torch.ones((out_features, in_features)))\n",
    "        self.b = Parameter(torch.ones(out_features))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = torch.addmm(self.b, x, self.W.T)\n",
    "    \n",
    "        return output\n",
    "    \n",
    "x = torch.Tensor([[1, 2],\n",
    "                  [3, 4]])\n",
    "\n",
    "linear = Linear(2, 3)\n",
    "output = linear(x)\n",
    "output\n",
    "\n",
    "# Parameterë¥¼ ì‚¬ìš©í•´ì•¼ë§Œ output tensorì— gradientë¥¼ ê³„ì‚°í•˜ëŠ” grad_fnì´ ìƒì„±ë¨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "0fad6115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('W',\n",
       "              tensor([[1., 1.],\n",
       "                      [1., 1.],\n",
       "                      [1., 1.]])),\n",
       "             ('b', tensor([1., 1., 1.]))])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# state_dict()\n",
    "\n",
    "linear.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "686919fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7.])\n",
      "OrderedDict([('parameter', tensor([7.])), ('buffer', tensor([7.]))])\n"
     ]
    }
   ],
   "source": [
    "# Buffer. ParameterëŠ” ì•„ë‹ˆì§€ë§Œ ì €ì¥í•  ìˆ˜ ìˆëŠ” tensor.\n",
    "# ëª¨ë¸ì„ ì €ì¥í•  ë•Œ ê°™ì´ ì €ì¥ë¨.\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.parameter = Parameter(torch.Tensor([7]))\n",
    "        self.tensor = torch.Tensor([7])\n",
    "        self.register_buffer('buffer', torch.Tensor([7]), persistent=True)\n",
    "        \n",
    "model = Model()\n",
    "\n",
    "buffer = model.get_buffer('buffer')\n",
    "print(buffer)\n",
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcd4f6c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.5720], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "\n",
    "# ì•„ë˜ ì½”ë“œëŠ” ìˆ˜ì •í•˜ì‹¤ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤!\n",
    "# í•˜ì§€ë§Œ ì•„ë˜ ê³¼ì œë¥¼ ì§„í–‰í•˜ê¸° ì „ì— ì•„ë˜ ì½”ë“œë¥¼ ë³´ë©´ì„œ ìµœëŒ€í•œ ì´í•´í•´ë³´ì„¸ìš”!\n",
    "\n",
    "# Function\n",
    "class Function_A(nn.Module):\n",
    "    def __init__(self, name):\n",
    "        super().__init__()\n",
    "        self.name = name\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x * 2\n",
    "        return x\n",
    "\n",
    "class Function_B(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.W1 = Parameter(torch.Tensor([10]))\n",
    "        self.W2 = Parameter(torch.Tensor([2]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x / self.W1\n",
    "        x = x / self.W2\n",
    "\n",
    "        return x\n",
    "\n",
    "class Function_C(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.register_buffer('duck', torch.Tensor([7]), persistent=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x * self.duck\n",
    "        \n",
    "        return x\n",
    "\n",
    "class Function_D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.W1 = Parameter(torch.Tensor([3]))\n",
    "        self.W2 = Parameter(torch.Tensor([5]))\n",
    "        self.c = Function_C()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.W1\n",
    "        x = self.c(x)\n",
    "        x = x / self.W2\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# Layer\n",
    "class Layer_AB(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.a = Function_A('duck')\n",
    "        self.b = Function_B()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.a(x) / 5\n",
    "        x = self.b(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class Layer_CD(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.c = Function_C()\n",
    "        self.d = Function_D()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.c(x)\n",
    "        x = self.d(x) + 1\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# Model\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.ab = Layer_AB()\n",
    "        self.cd = Layer_CD()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.ab(x)\n",
    "        x = self.cd(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "x = torch.tensor([7])\n",
    "\n",
    "model = Model()\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50ee6e5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.5720])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = (((x*2/5/10/2*7)+3)*7/5)+1\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcdc3ad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('ab.b.W1', tensor([10.])),\n",
       "             ('ab.b.W2', tensor([2.])),\n",
       "             ('cd.c.duck', tensor([7.])),\n",
       "             ('cd.d.W1', tensor([3.])),\n",
       "             ('cd.d.W2', tensor([5.])),\n",
       "             ('cd.d.c.duck', tensor([7.]))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086e4671",
   "metadata": {},
   "source": [
    "### named_modules, named_children\n",
    "### named_parameters, parameters\n",
    "### named_buffers, buffers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cba13ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Name ] : \n",
      "[ Module ]\n",
      "Model(\n",
      "  (ab): Layer_AB(\n",
      "    (a): Function_A()\n",
      "    (b): Function_B()\n",
      "  )\n",
      "  (cd): Layer_CD(\n",
      "    (c): Function_C()\n",
      "    (d): Function_D(\n",
      "      (c): Function_C()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "------------------------------\n",
      "[ Name ] : ab\n",
      "[ Module ]\n",
      "Layer_AB(\n",
      "  (a): Function_A()\n",
      "  (b): Function_B()\n",
      ")\n",
      "------------------------------\n",
      "[ Name ] : ab.a\n",
      "[ Module ]\n",
      "Function_A()\n",
      "------------------------------\n",
      "[ Name ] : ab.b\n",
      "[ Module ]\n",
      "Function_B()\n",
      "------------------------------\n",
      "[ Name ] : cd\n",
      "[ Module ]\n",
      "Layer_CD(\n",
      "  (c): Function_C()\n",
      "  (d): Function_D(\n",
      "    (c): Function_C()\n",
      "  )\n",
      ")\n",
      "------------------------------\n",
      "[ Name ] : cd.c\n",
      "[ Module ]\n",
      "Function_C()\n",
      "------------------------------\n",
      "[ Name ] : cd.d\n",
      "[ Module ]\n",
      "Function_D(\n",
      "  (c): Function_C()\n",
      ")\n",
      "------------------------------\n",
      "[ Name ] : cd.d.c\n",
      "[ Module ]\n",
      "Function_C()\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# named_modules()\n",
    "\n",
    "for name, module in model.named_modules():\n",
    "    print(f\"[ Name ] : {name}\\n[ Module ]\\n{module}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6363d8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Name ] : ab\n",
      "[ Children ]\n",
      "Layer_AB(\n",
      "  (a): Function_A()\n",
      "  (b): Function_B()\n",
      ")\n",
      "------------------------------\n",
      "[ Name ] : cd\n",
      "[ Children ]\n",
      "Layer_CD(\n",
      "  (c): Function_C()\n",
      "  (d): Function_D(\n",
      "    (c): Function_C()\n",
      "  )\n",
      ")\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# named_children()\n",
    "\n",
    "for name, child in model.named_children():\n",
    "    print(f\"[ Name ] : {name}\\n[ Children ]\\n{child}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b34474ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Function_A()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get_submodule()\n",
    "\n",
    "submodule = model.get_submodule('ab.a')\n",
    "submodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db25d0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Name ] : ab.b.W1\n",
      "[ Parameter ]\n",
      "Parameter containing:\n",
      "tensor([10.], requires_grad=True)\n",
      "------------------------------\n",
      "[ Name ] : ab.b.W2\n",
      "[ Parameter ]\n",
      "Parameter containing:\n",
      "tensor([2.], requires_grad=True)\n",
      "------------------------------\n",
      "[ Name ] : cd.d.W1\n",
      "[ Parameter ]\n",
      "Parameter containing:\n",
      "tensor([3.], requires_grad=True)\n",
      "------------------------------\n",
      "[ Name ] : cd.d.W2\n",
      "[ Parameter ]\n",
      "Parameter containing:\n",
      "tensor([5.], requires_grad=True)\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# named_parameters()\n",
    "\n",
    "for name, parameter in model.named_parameters():\n",
    "    print(f\"[ Name ] : {name}\\n[ Parameter ]\\n{parameter}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be86012a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([10.], requires_grad=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get_parameter()\n",
    "\n",
    "parameter = model.get_parameter('ab.b.W1')\n",
    "parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a99a6409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Name ] : cd.c.duck\n",
      "[ Buffer ] : tensor([7.])\n",
      "------------------------------\n",
      "[ Name ] : cd.d.c.duck\n",
      "[ Buffer ] : tensor([7.])\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# named_buffers()\n",
    "\n",
    "for name, buffer in model.named_buffers():\n",
    "    print(f\"[ Name ] : {name}\\n[ Buffer ] : {buffer}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "854cb141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Buffer ] : tensor([7.])\n",
      "------------------------------\n",
      "[ Buffer ] : tensor([7.])\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# buffers()\n",
    "\n",
    "for buffer in model.buffers():\n",
    "    print(f\"[ Buffer ] : {buffer}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d6150c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffer = model.get_buffer('cd.c.duck')\n",
    "buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ee003b6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (ab): Layer_AB(\n",
       "    (a): Function_A(name=duck)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra_repr()\n",
    "\n",
    "class Function_A(nn.Module):\n",
    "    def __init__(self, name):\n",
    "        super().__init__()\n",
    "        self.name = name\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x * 2\n",
    "        return x\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return f'name={self.name}'\n",
    "    \n",
    "class Layer_AB(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.a = Function_A('duck')\n",
    "        # self.b = Function_B()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.a(x) / 5\n",
    "        x = self.b(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.ab = Layer_AB()\n",
    "        # self.cd = Layer_CD()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.ab(x)\n",
    "        # x = self.cd(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "model = Model()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5dea7e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "['running_mean', 'running_var', 'num_batches_tracked']\n"
     ]
    }
   ],
   "source": [
    "# parameters(), buffers(), named_buffers()\n",
    "\n",
    "module = nn.BatchNorm1d(10)\n",
    "\n",
    "parameter_n = len(list(module.parameters()))\n",
    "buffer_n = len(list(module.buffers()))\n",
    "\n",
    "print(parameter_n)\n",
    "print(buffer_n)\n",
    "\n",
    "buffer_names = [name for name, _ in module.named_buffers()]\n",
    "print(buffer_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "752402ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Name ] : weight\n",
      "[ Parameter ]\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "------------------------------\n",
      "[ Name ] : bias\n",
      "[ Parameter ]\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# named_parameters()\n",
    "\n",
    "for name, parameter in module.named_parameters():\n",
    "    print(f\"[ Name ] : {name}\\n[ Parameter ]\\n{parameter}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5569348b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Name ] : running_mean\n",
      "[ Buffer ] : tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "------------------------------\n",
      "[ Name ] : running_var\n",
      "[ Buffer ] : tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "------------------------------\n",
      "[ Name ] : num_batches_tracked\n",
      "[ Buffer ] : 0\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# named_buffers()\n",
    "\n",
    "for name, buffer in module.named_buffers():\n",
    "    print(f\"[ Name ] : {name}\\n[ Buffer ] : {buffer}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "43113f98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('running_mean',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('num_batches_tracked', tensor(0))])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# state_dict()\n",
    "\n",
    "module.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcbac4b",
   "metadata": {},
   "source": [
    "### hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f7cb43e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "program A processing!\n",
      "program B processing!\n"
     ]
    }
   ],
   "source": [
    "# íŒ¨í‚¤ì§€í™” ëœ ì½”ë“œì—ì„œ ë‹¤ë¥¸ í”„ë¡œê·¸ë˜ë¨¸ê°€\n",
    "# custom ì½”ë“œë¥¼ ì¤‘ê°„ì— ì‹¤í–‰ì‹œí‚¬ ìˆ˜ ìˆë„ë¡ ë§Œë“¤ì–´ë†“ì€ ì¸í„°í˜ì´ìŠ¤\n",
    "\n",
    "# í”„ë¡œê·¸ë¨ì˜ ì‹¤í–‰ ë¡œì§ì„ ë¶„ì„í•˜ê±°ë‚˜\n",
    "# í”„ë¡œê·¸ë¨ì— ì¶”ê°€ì ì¸ ê¸°ëŠ¥ì„ ì œê³µí•  ë•Œ ì‚¬ìš©\n",
    "\n",
    "def program_A(x):\n",
    "    print('program A processing!')\n",
    "    return x + 3\n",
    "\n",
    "def program_B(x):\n",
    "    print('program B processing!')\n",
    "    return x - 3\n",
    "\n",
    "class Package(object):\n",
    "    def __init__(self):\n",
    "        self.programs = [program_A, program_B]\n",
    "        \n",
    "        # ì´ë ‡ê²Œ Packageì—ëŠ” self.hookì´ë€ ë³€ìˆ˜ë¥¼ ë§Œë“¤ì–´ì¤˜ì•¼ í•¨\n",
    "        # í˜„ì¬ëŠ” hookì— ì•„ë¬´ ê²ƒë„ ì—†ëŠ” ìƒíƒœ\n",
    "        self.hooks = []\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for program in self.programs:\n",
    "            x = program(x)\n",
    "\n",
    "            # Packageë¥¼ ì‚¬ìš©í•˜ëŠ” ì‚¬ëŒì´ ìì‹ ë§Œì˜ custom programì„\n",
    "            # ë“±ë¡í•  ìˆ˜ ìˆë„ë¡ ë¯¸ë¦¬ ë§Œë“¤ì–´ë†“ì€ ì¸í„°í˜ì´ìŠ¤ hook\n",
    "            if self.hooks:\n",
    "                for hook in self.hooks:\n",
    "                    output = hook(x)\n",
    "\n",
    "                    if output:\n",
    "                        x = output\n",
    "\n",
    "        return x\n",
    "\n",
    "package = Package()\n",
    "\n",
    "input = 3\n",
    "output = package(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "86223872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "program A processing!\n",
      "hook for analysis, current value is 6\n",
      "program B processing!\n",
      "hook for analysis, current value is 3\n",
      "output: 3\n"
     ]
    }
   ],
   "source": [
    "# hookìœ¼ë¡œ ë¡œì§ ë¶„ì„í•˜ê¸°\n",
    "\n",
    "# module ë‚´ë¶€ì— printë¬¸ ì°ì–´ì£¼ëŠ” íš¨ê³¼\n",
    "\n",
    "def hook_analysis(x):\n",
    "    print(f'hook for analysis, current value is {x}')\n",
    "\n",
    "package.hooks = [] # ì´ê²Œ ì™œ í•„ìš”í•¨???\n",
    "package.hooks.append(hook_analysis)\n",
    "\n",
    "input = 3\n",
    "output = package(input)\n",
    "print(f'output: {output}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "620757aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "program A processing!\n",
      "hook for multiplying\n",
      "program B processing!\n",
      "hook for multiplying\n",
      "output: 45\n"
     ]
    }
   ],
   "source": [
    "# hookìœ¼ë¡œ ê¸°ëŠ¥ ì¶”ê°€í•˜ê¸°\n",
    "\n",
    "def hook_multiply(x):\n",
    "    print('hook for multiplying')\n",
    "    return x * 3\n",
    "\n",
    "package.hooks = []\n",
    "package.hooks.append(hook_multiply)\n",
    "\n",
    "input = 3\n",
    "output = package(input)\n",
    "print(f'output: {output}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5c1451e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "program A processing!\n",
      "hook for multiplying\n",
      "hook for analysis, current value is 18\n",
      "program B processing!\n",
      "hook for multiplying\n",
      "hook for analysis, current value is 45\n",
      "output: 45\n"
     ]
    }
   ],
   "source": [
    "# hookì— ì—¬ëŸ¬ ê°œì˜ ê¸°ëŠ¥ ë„£ê¸°\n",
    "\n",
    "package.hooks = []\n",
    "package.hooks.append(hook_multiply)\n",
    "package.hooks.append(hook_analysis)\n",
    "\n",
    "input = 3\n",
    "output = package(input)\n",
    "\n",
    "print(f'output: {output}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "660db12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre_hook()\n",
    "\n",
    "# í”„ë¡œê·¸ë¨ ì‹¤í–‰ ì „ì— ë„£ìœ¼ë‚˜ í›„ì— ë„£ìœ¼ë‚˜ ì„¤ê³„ì ë§ˆìŒ\n",
    "\n",
    "def program_A(x):\n",
    "    print('program A processing!')\n",
    "    return x + 3\n",
    "\n",
    "def program_B(x):\n",
    "    print('program B processing!')\n",
    "    return x - 3\n",
    "\n",
    "class Package(object):\n",
    "    def __init__(self):\n",
    "        self.programs = [program_A, program_B]\n",
    "\n",
    "        # pre_hooks\n",
    "        self.pre_hooks = []\n",
    "        \n",
    "        # hooks\n",
    "        self.hooks = []\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for program in self.programs:\n",
    "            \n",
    "            # pre_hooks\n",
    "            if self.pre_hooks:\n",
    "                for hook in self.pre_hooks:\n",
    "                    output = hook(x)\n",
    "                    if output:\n",
    "                        x = output\n",
    "\n",
    "            x = program(x)\n",
    "\n",
    "            # hooks\n",
    "            if self.hooks:\n",
    "                for hook in self.hooks:\n",
    "                    output = hook(x)\n",
    "                    if output:\n",
    "                        x = output\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83130dac",
   "metadata": {},
   "source": [
    "### hook in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65faa603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hook for Tensor\n",
    "    # backward hook\n",
    "        # function to use: tensor.register_hook(hook)\n",
    "\n",
    "# hook for Module\n",
    "    # forward pre hook\n",
    "        # function to use: register_forward_pre_hook(hook)\n",
    "    # forward hook\n",
    "        # function to use: register_forward_hook(hook)\n",
    "    # backward hook\n",
    "        # function to use: register_backward_hook(hook)\n",
    "    # full backward hook\n",
    "        # function to use: register_full_backward_hook(hook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5312ebfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([(1, <function __main__.tensor_hook(grad)>)])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# register_hook\n",
    "# _backward_hooks # ???\n",
    "\n",
    "import torch\n",
    "\n",
    "t = torch.rand(1, requires_grad=True)\n",
    "\n",
    "def tensor_hook(grad):\n",
    "    pass\n",
    "\n",
    "t.register_hook(tensor_hook)\n",
    "\n",
    "t._backward_hooks # ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4de862f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training': True,\n",
       " '_parameters': OrderedDict(),\n",
       " '_buffers': OrderedDict(),\n",
       " '_non_persistent_buffers_set': set(),\n",
       " '_backward_hooks': OrderedDict([(4, <function __main__.module_hook(grad)>)]),\n",
       " '_is_full_backward_hook': True,\n",
       " '_forward_hooks': OrderedDict([(3, <function __main__.module_hook(grad)>)]),\n",
       " '_forward_pre_hooks': OrderedDict([(2,\n",
       "               <function __main__.module_hook(grad)>)]),\n",
       " '_state_dict_hooks': OrderedDict(),\n",
       " '_load_state_dict_pre_hooks': OrderedDict(),\n",
       " '_modules': OrderedDict()}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# register_forward_pre_hook()\n",
    "# register_forward_hook()\n",
    "# register_full_backward_hook()\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "def module_hook(grad):\n",
    "    pass\n",
    "    \n",
    "model = Model()\n",
    "model.register_forward_pre_hook(module_hook)\n",
    "model.register_forward_hook(module_hook)\n",
    "model.register_full_backward_hook(module_hook)\n",
    "\n",
    "model.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cd0b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward_pre_hooks\n",
    "# forward_hooks\n",
    "# backward_hooks # deprecated # so backward_hooks is used for tensor only?\n",
    "# full_backward_hooks\n",
    "# state_dict_hooks # used internally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a8242063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0.8208]), tensor([0.0552]), tensor(0.8760)]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward_pre_hook\n",
    "# forward_hook\n",
    "# ìœ¼ë¡œ ê°’ ì €ì¥í•˜ê¸°\n",
    "\n",
    "class Add(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() \n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        output = torch.add(x1, x2)\n",
    "\n",
    "        return output\n",
    "\n",
    "add = Add()\n",
    "\n",
    "answer = []\n",
    "\n",
    "def pre_hook(module, input):\n",
    "    answer.extend(input)\n",
    "\n",
    "def hook(module, input, output):\n",
    "    answer.extend(output)\n",
    "\n",
    "add.register_forward_pre_hook(pre_hook)\n",
    "add.register_forward_hook(hook)\n",
    "\n",
    "x1 = torch.rand(1)\n",
    "x2 = torch.rand(1)\n",
    "\n",
    "output = add(x1, x2)\n",
    "\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2e7e499c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9335])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([5.9335])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hookìœ¼ë¡œ ê°’ ìˆ˜ì •í•˜ê¸°\n",
    "\n",
    "class Add(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() \n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        output = torch.add(x1, x2)\n",
    "\n",
    "        return output\n",
    "\n",
    "add = Add()\n",
    "\n",
    "def hook(module, input, output):\n",
    "    return output + 5\n",
    "\n",
    "add.register_forward_hook(hook)\n",
    "\n",
    "x1 = torch.rand(1)\n",
    "x2 = torch.rand(1)\n",
    "\n",
    "output = add(x1, x2)\n",
    "print(x1+x2)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "270981bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([4.8898]), tensor([2.8644]), tensor([1.])]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# listì— backprop gradientê°’ ì €ì¥í•˜ê¸°\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.W = Parameter(torch.Tensor([5]))\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        output = x1 * x2\n",
    "        output = output * self.W\n",
    "\n",
    "        return output\n",
    "\n",
    "model = Model()\n",
    "\n",
    "answer = []\n",
    "\n",
    "# TODO : hookë¥¼ ì´ìš©í•´ì„œ x1.grad, x2.grad, output.grad ê°’ì„ ì•Œì•„ë‚´ answerì— ì €ì¥í•˜ì„¸ìš”\n",
    "def module_hook(module, grad_input, grad_output):\n",
    "    answer.extend(grad_input)\n",
    "    answer.extend(grad_output)\n",
    "\n",
    "# full backward hook\n",
    "model.register_full_backward_hook(module_hook)\n",
    "\n",
    "\n",
    "x1 = torch.rand(1, requires_grad=True)\n",
    "x2 = torch.rand(1, requires_grad=True)\n",
    "\n",
    "output = model(x1, x2)\n",
    "output.retain_grad() \n",
    "# Tensor.retain_grad() -> None\n",
    "# Enables this tensor to have their grad populating during backward()\n",
    "output.backward() # backprop\n",
    "\n",
    "answer # [x1.grad, x2.grad, output.grad]\n",
    "\n",
    "# ???\n",
    "# xë‘ wë¥¼ ì´ìš©í•´ y_hat ê°’ì„ êµ¬í•˜ê³  ê·¸ê±¸ yê°€ í¬í•¨ëœ cost functionì— ë„£ì–´ì„œ\n",
    "# cost functionì˜ wì— ëŒ€í•œ gradientë¥¼ êµ¬í•˜ëŠ”ê²Œ layer ì•„ë‹Œê°€?\n",
    "# yë‘ cost functionì´ ì—†ëŠ”ë° ì–´ë–»ê²Œ gradientë¥¼ êµ¬í•˜ëŠ”ê±°ì§€?\n",
    "\n",
    "# -> ì—¬ê¸°ì— ë„£ëŠ” ê³„ì‚°ì‹ì€ forward propì´ ì•„ë‹ˆë¼ cost functionì„.\n",
    "# d(output) / d(input) ì„ êµ¬í•˜ëŠ”ê²Œ ëª©ì .\n",
    "\n",
    "# -> ê¸°ë³¸ì ìœ¼ë¡œ inputì„ outputìœ¼ë¡œ ë³€í™”ì‹œí‚¤ëŠ” ì‹ì´ ì¡´ì¬í•˜ë‹ˆê¹Œ,\n",
    "# inputì— ëŒ€í•œ outputì˜ ë¯¸ë¶„ê°’ì„ êµ¬í•˜ëŠ” ê²ƒ.\n",
    "# ì´ê±´ labelì´ ì—†ì–´ë„ ê°€ëŠ¥.\n",
    "# ì¦‰, forward propê³¼ cost functionì€ ë³¸ì§ˆì ìœ¼ë¡œ ë‹¤ë¥´ì§€ ì•Šë‹¤. \n",
    "# ëì— cost functionë§Œ ë¶™ì´ë©´ ë¨.\n",
    "# ì²«ë²ˆì§¸ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µ: cost functionë„ ê·¸ëƒ¥ functionì´ê³ , \n",
    "# ê²°êµ­ inputê³¼ ì‹ì„ ì¤¬ì„ ë•Œ outputì„ ê³„ì‚°í•˜ê³ , \n",
    "# d(output) / d(input) ì„ ê³„ì‚°í•˜ëŠ” êµ¬ì¡°ë¼ëŠ” ê²ƒ.\n",
    "# labelê³¼ cost functionì„ ëì— ì¶”ê°€í•´ ì™„ì„±ì‹œì¼œ ì£¼ë©´,\n",
    "# d(output, i.e. cost) / d(input, i.e. weight) ë¥¼ ì•Œì•„ë‚´ê³ ,\n",
    "# ê±°ê¸°ë‹¤ learning rateë¥¼ ê³±í•´ weightë¥¼ updateí•  amountë¥¼ ì •í•˜ëŠ” ê²ƒ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "50033fbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.3045)]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# module ë‹¨ìœ„ëŠ” backward hookì€ input gradient, output gradientê°’ë§Œ ê°€ì ¸ì™€ì„œ\n",
    "# module ë‚´ë¶€ì˜ tensorì˜ gradientê°’ì€ ì•Œì•„ë‚¼ ìˆ˜ ì—†ìŒ.\n",
    "# moduleì˜ Parameter Wì˜ gradientê°’ì„ ì•Œì•„ë‚´ê¸° ìœ„í•´\n",
    "# tensor ë‹¨ìœ„ì˜ backward hook ì‚¬ìš©í•´ì•¼.\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.W = Parameter(torch.Tensor([5]))\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        output = x1 * x2\n",
    "        output = output * self.W\n",
    "\n",
    "        return output\n",
    "\n",
    "model = Model()\n",
    "\n",
    "answer = []\n",
    "\n",
    "# TODO : hookë¥¼ ì´ìš©í•´ì„œ Wì˜ gradient ê°’ì„ ì•Œì•„ë‚´ answerì— ì €ì¥í•˜ì„¸ìš”\n",
    "def tensor_hook(grad):\n",
    "    answer.extend(grad)\n",
    "\n",
    "# model.Wì— register_hook() ì ìš©\n",
    "model.W.register_hook(tensor_hook)\n",
    "\n",
    "\n",
    "x1 = torch.rand(1, requires_grad=True)\n",
    "x2 = torch.rand(1, requires_grad=True)\n",
    "\n",
    "output = model(x1, x2)\n",
    "output.backward()\n",
    "\n",
    "answer # [model.W.grad]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7baeb4b2",
   "metadata": {},
   "source": [
    "### apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d9614148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=2, out_features=2, bias=True)\n",
      "Parameter containing:\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n",
      "Linear(in_features=2, out_features=2, bias=True)\n",
      "Parameter containing:\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n",
      "Sequential(\n",
      "  (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "  (1): Linear(in_features=2, out_features=2, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=2, out_features=2, bias=True)\n",
       "  (1): Linear(in_features=2, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "@torch.no_grad() # ???\n",
    "def init_weights(m):\n",
    "    print(m) # ???\n",
    "    if type(m) == nn.Linear:\n",
    "        m.weight.fill_(1.0)\n",
    "        print(m.weight) # ???\n",
    "\n",
    "net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))\n",
    "net.apply(init_weights) # ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "82ee289e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "\n",
    "# ì•„ë˜ ì½”ë“œëŠ” ìˆ˜ì •í•˜ì‹¤ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤!\n",
    "# í•˜ì§€ë§Œ ì•„ë˜ ê³¼ì œë¥¼ ì§„í–‰í•˜ê¸° ì „ì— ì•„ë˜ ì½”ë“œë¥¼ ë³´ë©´ì„œ ìµœëŒ€í•œ ì´í•´í•´ë³´ì„¸ìš”!\n",
    "\n",
    "# Function\n",
    "class Function_A(nn.Module):\n",
    "    def __init__(self, name):\n",
    "        super().__init__()\n",
    "        self.name = name\n",
    "        self.W = Parameter(torch.rand(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.W\n",
    "\n",
    "class Function_B(nn.Module):\n",
    "    def __init__(self, name):\n",
    "        super().__init__()\n",
    "        self.name = name\n",
    "        self.W = Parameter(torch.rand(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x - self.W\n",
    "\n",
    "class Function_C(nn.Module):\n",
    "    def __init__(self, name):\n",
    "        super().__init__()\n",
    "        self.name = name\n",
    "        self.W = Parameter(torch.rand(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * self.W\n",
    "\n",
    "class Function_D(nn.Module):\n",
    "    def __init__(self, name):\n",
    "        super().__init__()\n",
    "        self.name = name\n",
    "        self.W = Parameter(torch.rand(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x / self.W\n",
    "\n",
    "\n",
    "# Layer\n",
    "class Layer_AB(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.a = Function_A('plus')\n",
    "        self.b = Function_B('substract')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.a(x)\n",
    "        x = self.b(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class Layer_CD(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.c = Function_C('multiply')\n",
    "        self.d = Function_D('divide')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.c(x)\n",
    "        x = self.d(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# Model\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.ab = Layer_AB()\n",
    "        self.cd = Layer_CD()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.ab(x)\n",
    "        x = self.cd(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "324b7a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function_A()\n",
      "------------------------------\n",
      "Function_B()\n",
      "------------------------------\n",
      "Layer_AB(\n",
      "  (a): Function_A()\n",
      "  (b): Function_B()\n",
      ")\n",
      "------------------------------\n",
      "Function_C()\n",
      "------------------------------\n",
      "Function_D()\n",
      "------------------------------\n",
      "Layer_CD(\n",
      "  (c): Function_C()\n",
      "  (d): Function_D()\n",
      ")\n",
      "------------------------------\n",
      "Model(\n",
      "  (ab): Layer_AB(\n",
      "    (a): Function_A()\n",
      "    (b): Function_B()\n",
      "  )\n",
      "  (cd): Layer_CD(\n",
      "    (c): Function_C()\n",
      "    (d): Function_D()\n",
      "  )\n",
      ")\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "def print_module(module):\n",
    "    print(module)\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "# ğŸ¦† applyëŠ” applyê°€ ì ìš©ëœ moduleì„ return í•´ì¤˜ìš”!\n",
    "returned_module = model.apply(print_module)\n",
    "# returned_moduleì€ ì–´ë””ë‹¤ ì”€?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d3be8175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('ab.a.W', tensor([0.1178])), ('ab.b.W', tensor([0.3057])), ('cd.c.W', tensor([0.1448])), ('cd.d.W', tensor([0.4942]))])\n",
      "OrderedDict([('ab.a.W', tensor([1.])), ('ab.b.W', tensor([1.])), ('cd.c.W', tensor([1.])), ('cd.d.W', tensor([1.]))])\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "\n",
    "print(model.state_dict())\n",
    "\n",
    "# TODO : applyë¥¼ ì´ìš©í•´ ëª¨ë“  Parameter ê°’ì„ 1ë¡œ ë§Œë“¤ì–´ë³´ì„¸ìš”!\n",
    "def weight_initialization(module):\n",
    "    module_name = module.__class__.__name__\n",
    "\n",
    "    if module_name.split('_')[0] == \"Function\":\n",
    "        module.W.data.fill_(1.)\n",
    "\n",
    "# ğŸ¦† applyëŠ” applyê°€ ì ìš©ëœ moduleì„ return í•´ì¤˜ìš”!\n",
    "returned_module = model.apply(weight_initialization)\n",
    "\n",
    "\n",
    "# ì•„ë˜ ì½”ë“œëŠ” ìˆ˜ì •í•˜ì‹¤ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤!\n",
    "x = torch.rand(1)\n",
    "\n",
    "output = model(x)\n",
    "\n",
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "459194e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "\n",
    "# TODO : applyë¥¼ ì´ìš©í•´ì„œ ë¶€ë•ì´ê°€ ì›í•˜ëŠ”ëŒ€ë¡œ repr ì¶œë ¥ì„ ìˆ˜ì •í•´ì£¼ì„¸ìš”!\n",
    "from functools import partial\n",
    "\n",
    "def function_repr(self):\n",
    "    return f'name={self.name}'\n",
    "\n",
    "def add_repr(module):\n",
    "    module_name = module.__class__.__name__\n",
    "\n",
    "    if module_name.split('_')[0] == \"Function\":\n",
    "        module.extra_repr = partial(function_repr, module) # ???\n",
    "\n",
    "\n",
    "# ğŸ¦† applyëŠ” applyê°€ ì ìš©ëœ moduleì„ return í•´ì¤˜ìš”!\n",
    "returned_module = model.apply(add_repr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ee8063cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (ab): Layer_AB(\n",
       "    (a): Function_A(name=plus)\n",
       "    (b): Function_B(name=substract)\n",
       "  )\n",
       "  (cd): Layer_CD(\n",
       "    (c): Function_C(name=multiply)\n",
       "    (d): Function_D(name=divide)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "2a61b8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (ab): Layer_AB(\n",
      "    (a): Function_A(name=plus)\n",
      "    (b): Function_B(name=substract)\n",
      "  )\n",
      "  (cd): Layer_CD(\n",
      "    (c): Function_C(name=multiply)\n",
      "    (d): Function_D(name=divide)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_repr = repr(model)\n",
    "print(model_repr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfefa26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í˜„ì¬ 4ê°œì˜ Function A, B, C, Dê°€ ìˆì–´ìš”!\n",
    "\n",
    "# - A : x + W\n",
    "# - B : x - W\n",
    "# - C : x * W\n",
    "# - D : x / W\n",
    "\n",
    "# ì´ê±¸ ë‹¤ìŒì²˜ëŸ¼ linear transformationì²˜ëŸ¼ ë™ì‘í•˜ë„ë¡ ë°”ê¿”ë³´ë˜ìš”!\n",
    "\n",
    "# - A : x @ W + b\n",
    "# - B : x @ W + b\n",
    "# - C : x @ W + b\n",
    "# - D : x @ W + b\n",
    "\n",
    "# WëŠ” ì´ë¯¸ ê° Functionì— ìƒì„±ëœ Parameterì´ê³ \n",
    "# bëŠ” ìƒˆë¡­ê²Œ ë§Œë“¤ì–´ì•¼ í•˜ëŠ” Parameterì—ìš”!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0eb84c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "\n",
    "# ì•„ë˜ ì½”ë“œëŠ” ìˆ˜ì •í•˜ì‹¤ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤!\n",
    "# ì‹¤í–‰ë§Œ ì‹œì¼œì£¼ì‹œê³  ë‹¤ìŒ ì…€ë¡œ ë„˜ì–´ê°€ì£¼ì„¸ìš”!\n",
    "\n",
    "# Function\n",
    "class Function_A(nn.Module):\n",
    "    def __init__(self, name):\n",
    "        super().__init__()\n",
    "        self.name = name\n",
    "        self.W = Parameter(torch.rand(2, 2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.W\n",
    "\n",
    "class Function_B(nn.Module):\n",
    "    def __init__(self, name):\n",
    "        super().__init__()\n",
    "        self.name = name\n",
    "        self.W = Parameter(torch.rand(2, 2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x - self.W\n",
    "\n",
    "class Function_C(nn.Module):\n",
    "    def __init__(self, name):\n",
    "        super().__init__()\n",
    "        self.name = name\n",
    "        self.W = Parameter(torch.rand(2, 2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * self.W\n",
    "\n",
    "class Function_D(nn.Module):\n",
    "    def __init__(self, name):\n",
    "        super().__init__()\n",
    "        self.name = name\n",
    "        self.W = Parameter(torch.rand(2, 2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x / self.W\n",
    "\n",
    "\n",
    "# Layer\n",
    "class Layer_AB(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.a = Function_A('plus')\n",
    "        self.b = Function_B('substract')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.a(x)\n",
    "        x = self.b(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class Layer_CD(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.c = Function_C('multiply')\n",
    "        self.d = Function_D('divide')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.c(x)\n",
    "        x = self.d(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# Model\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.ab = Layer_AB()\n",
    "        self.cd = Layer_CD()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.ab(x)\n",
    "        x = self.cd(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f76937bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# register_parameter()\n",
    "# data.fill_()\n",
    "# Function_A, B, C, Dì˜ ê³„ì‚° ê²°ê³¼ ë˜ëŒë¦¬ê¸°\n",
    "# torch.addmm(b, output, W.T)\n",
    "# module.register.forward_hook()\n",
    "# returned_module = model.apply()\n",
    "\n",
    "model = Model()\n",
    "\n",
    "\n",
    "# TODO : applyë¥¼ ì´ìš©í•´ Parameter bë¥¼ ì¶”ê°€í•´ë³´ì„¸ìš”!\n",
    "def add_bias(module):\n",
    "    module_name = module.__class__.__name__\n",
    "\n",
    "    if module_name.split('_')[0] == \"Function\":\n",
    "        module.register_parameter('b', Parameter(torch.rand(2)))\n",
    "\n",
    "\n",
    "# TODO : applyë¥¼ ì´ìš©í•´ ì¶”ê°€ëœ bë„ ê°’ì„ 1ë¡œ ì´ˆê¸°í™”í•´ì£¼ì„¸ìš”!\n",
    "def weight_initialization(module):\n",
    "    module_name = module.__class__.__name__\n",
    "\n",
    "    if module_name.split('_')[0] == \"Function\":\n",
    "        module.W.data.fill_(1.)\n",
    "        module.b.data.fill_(1.)\n",
    "\n",
    "\n",
    "# TODO : applyë¥¼ ì´ìš©í•´ ëª¨ë“  Functionì„ linear transformationìœ¼ë¡œ ë°”ê¿”ë³´ì„¸ìš”!\n",
    "#        X @ W + b\n",
    "def linear_transformation(module):\n",
    "    module_name = module.__class__.__name__\n",
    "\n",
    "    if module_name == \"Function_A\":\n",
    "        def hook_A(module, input, output):\n",
    "            W, b = module.W, module.b\n",
    "            output = output - W \n",
    "            output = torch.addmm(b, output, W.T)\n",
    "\n",
    "            return output\n",
    "\n",
    "        module.register_forward_hook(hook_A)\n",
    "\n",
    "    elif module_name == \"Function_B\":\n",
    "        def hook_B(module, input, output):\n",
    "            W, b = module.W, module.b\n",
    "            output = output + W\n",
    "            output = torch.addmm(b, output, W.T)\n",
    "\n",
    "            return output\n",
    "\n",
    "        module.register_forward_hook(hook_B)\n",
    "\n",
    "    elif module_name == \"Function_C\":\n",
    "        def hook_C(module, input, output):\n",
    "            W, b = module.W, module.b\n",
    "            output = output / W\n",
    "            output = torch.addmm(b, output, W.T)\n",
    "\n",
    "            return output\n",
    "\n",
    "        module.register_forward_hook(hook_C)\n",
    "\n",
    "    elif module_name == \"Function_D\":\n",
    "        def hook_D(module, input, output):\n",
    "            W, b = module.W, module.b\n",
    "            output = output * W\n",
    "            output = torch.addmm(b, output, W.T)\n",
    "\n",
    "            return output\n",
    "\n",
    "        module.register_forward_hook(hook_D)\n",
    "\n",
    "returned_module = model.apply(add_bias)\n",
    "returned_module = model.apply(weight_initialization)\n",
    "returned_module = model.apply(linear_transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6aaf89e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('ab.a.W',\n",
       "              tensor([[1., 1.],\n",
       "                      [1., 1.]])),\n",
       "             ('ab.a.b', tensor([1., 1.])),\n",
       "             ('ab.b.W',\n",
       "              tensor([[1., 1.],\n",
       "                      [1., 1.]])),\n",
       "             ('ab.b.b', tensor([1., 1.])),\n",
       "             ('cd.c.W',\n",
       "              tensor([[1., 1.],\n",
       "                      [1., 1.]])),\n",
       "             ('cd.c.b', tensor([1., 1.])),\n",
       "             ('cd.d.W',\n",
       "              tensor([[1., 1.],\n",
       "                      [1., 1.]])),\n",
       "             ('cd.d.b', tensor([1., 1.]))])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "368b9551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7199, 0.8792],\n",
      "        [0.0292, 0.5850]], requires_grad=True)\n",
      "tensor(95.4112, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2, 2, requires_grad=True)\n",
    "\n",
    "print(x)\n",
    "\n",
    "output = model(x)\n",
    "output = output.sum()\n",
    "output.backward()\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b9fe5265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ab.a.W', tensor([[69.7755, 71.5895],\n",
      "        [69.7755, 71.5895]])), ('ab.a.b', tensor([144., 144.])), ('ab.b.W', tensor([[142.6825, 142.6825],\n",
      "        [142.6825, 142.6825]])), ('ab.b.b', tensor([72., 72.])), ('cd.c.W', tensor([[178.6825, 178.6825],\n",
      "        [178.6825, 178.6825]])), ('cd.c.b', tensor([36., 36.])), ('cd.d.W', tensor([[196.6825, 196.6825],\n",
      "        [196.6825, 196.6825]])), ('cd.d.b', tensor([18., 18.]))]\n"
     ]
    }
   ],
   "source": [
    "grads = [(name, param.grad) for name, param in model.named_parameters()]\n",
    "\n",
    "print(grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a670f73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
