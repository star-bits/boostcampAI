{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmcv import Config\n",
    "from mmdet.datasets import build_dataset\n",
    "from mmdet.models import build_detector\n",
    "from mmdet.apis import train_detector\n",
    "from mmdet.datasets import (build_dataloader, build_dataset,\n",
    "                            replace_ImageToTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config.fromfile(\"./_universe_config.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.20s)\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      "CocoDataset Train dataset with number of images 4883, and instance counts: \n",
      "+-------------------+-------+---------------+-------+-----------------+-------+-------------+-------+--------------+-------+\n",
      "| category          | count | category      | count | category        | count | category    | count | category     | count |\n",
      "+-------------------+-------+---------------+-------+-----------------+-------+-------------+-------+--------------+-------+\n",
      "| 0 [General trash] | 3965  | 1 [Paper]     | 6352  | 2 [Paper pack]  | 897   | 3 [Metal]   | 936   | 4 [Glass]    | 982   |\n",
      "| 5 [Plastic]       | 2943  | 6 [Styrofoam] | 1263  | 7 [Plastic bag] | 5178  | 8 [Battery] | 159   | 9 [Clothing] | 468   |\n",
      "+-------------------+-------+---------------+-------+-----------------+-------+-------------+-------+--------------+-------+\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      "CocoDataset Train dataset with number of images 488, and instance counts: \n",
      "+-------------------+-------+---------------+-------+-----------------+-------+-------------+-------+--------------+-------+\n",
      "| category          | count | category      | count | category        | count | category    | count | category     | count |\n",
      "+-------------------+-------+---------------+-------+-----------------+-------+-------------+-------+--------------+-------+\n",
      "| 0 [General trash] | 392   | 1 [Paper]     | 650   | 2 [Paper pack]  | 95    | 3 [Metal]   | 81    | 4 [Glass]    | 76    |\n",
      "| 5 [Plastic]       | 303   | 6 [Styrofoam] | 114   | 7 [Plastic bag] | 456   | 8 [Battery] | 10    | 9 [Clothing] | 36    |\n",
      "+-------------------+-------+---------------+-------+-----------------+-------+-------------+-------+--------------+-------+\n"
     ]
    }
   ],
   "source": [
    "dataset = build_dataset(cfg.data.train)\n",
    "print(dataset)\n",
    "\n",
    "print(build_dataset(cfg.data.val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/ml/detection/baseline/mmdetection/mmdet/models/dense_heads/anchor_head.py:118: UserWarning: DeprecationWarning: `num_anchors` is deprecated, for consistency or also use `num_base_priors` instead\n",
      "  warnings.warn('DeprecationWarning: `num_anchors` is deprecated, '\n",
      "2022-04-07 02:10:53,803 - mmdet - INFO - load checkpoint from local path: ./swin_large_patch4_window7_224_22kto1k.pth\n",
      "2022-04-07 02:10:54,443 - mmdet - INFO - initialize FPN with init_cfg {'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}\n",
      "2022-04-07 02:10:54,591 - mmdet - INFO - initialize GFLSEPCHead with init_cfg {'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01, 'override': {'type': 'Normal', 'name': 'gfl_cls', 'std': 0.01, 'bias_prob': 0.01}}\n",
      "2022-04-07 02:10:54,599 - mmcv - INFO - \n",
      "backbone.patch_embed.projection.weight - torch.Size([192, 3, 4, 4]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,601 - mmcv - INFO - \n",
      "backbone.patch_embed.projection.bias - torch.Size([192]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,601 - mmcv - INFO - \n",
      "backbone.patch_embed.norm.weight - torch.Size([192]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,604 - mmcv - INFO - \n",
      "backbone.patch_embed.norm.bias - torch.Size([192]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,604 - mmcv - INFO - \n",
      "backbone.stages.0.blocks.0.norm1.weight - torch.Size([192]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,607 - mmcv - INFO - \n",
      "backbone.stages.0.blocks.0.norm1.bias - torch.Size([192]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,607 - mmcv - INFO - \n",
      "backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table - torch.Size([169, 6]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,609 - mmcv - INFO - \n",
      "backbone.stages.0.blocks.0.attn.w_msa.qkv.weight - torch.Size([576, 192]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,610 - mmcv - INFO - \n",
      "backbone.stages.0.blocks.0.attn.w_msa.qkv.bias - torch.Size([576]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,612 - mmcv - INFO - \n",
      "backbone.stages.0.blocks.0.attn.w_msa.proj.weight - torch.Size([192, 192]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,614 - mmcv - INFO - \n",
      "backbone.stages.0.blocks.0.attn.w_msa.proj.bias - torch.Size([192]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,615 - mmcv - INFO - \n",
      "backbone.stages.0.blocks.0.norm2.weight - torch.Size([192]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,617 - mmcv - INFO - \n",
      "backbone.stages.0.blocks.0.norm2.bias - torch.Size([192]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,618 - mmcv - INFO - \n",
      "backbone.stages.0.blocks.0.ffn.layers.0.0.weight - torch.Size([768, 192]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,619 - mmcv - INFO - \n",
      "backbone.stages.0.blocks.0.ffn.layers.0.0.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,622 - mmcv - INFO - \n",
      "backbone.stages.0.blocks.0.ffn.layers.1.weight - torch.Size([192, 768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,622 - mmcv - INFO - \n",
      "backbone.stages.0.blocks.0.ffn.layers.1.bias - torch.Size([192]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,624 - mmcv - INFO - \n",
      "backbone.stages.0.blocks.1.norm1.weight - torch.Size([192]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,624 - mmcv - INFO - \n",
      "backbone.stages.0.blocks.1.norm1.bias - torch.Size([192]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,627 - mmcv - INFO - \n",
      "backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table - torch.Size([169, 6]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,628 - mmcv - INFO - \n",
      "backbone.stages.0.blocks.1.attn.w_msa.qkv.weight - torch.Size([576, 192]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,630 - mmcv - INFO - \n",
      "backbone.stages.0.blocks.1.attn.w_msa.qkv.bias - torch.Size([576]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,631 - mmcv - INFO - \n",
      "backbone.stages.0.blocks.1.attn.w_msa.proj.weight - torch.Size([192, 192]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,631 - mmcv - INFO - \n",
      "backbone.stages.0.blocks.1.attn.w_msa.proj.bias - torch.Size([192]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,632 - mmcv - INFO - \n",
      "backbone.stages.0.blocks.1.norm2.weight - torch.Size([192]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,632 - mmcv - INFO - \n",
      "backbone.stages.0.blocks.1.norm2.bias - torch.Size([192]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,633 - mmcv - INFO - \n",
      "backbone.stages.0.blocks.1.ffn.layers.0.0.weight - torch.Size([768, 192]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,633 - mmcv - INFO - \n",
      "backbone.stages.0.blocks.1.ffn.layers.0.0.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,634 - mmcv - INFO - \n",
      "backbone.stages.0.blocks.1.ffn.layers.1.weight - torch.Size([192, 768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,634 - mmcv - INFO - \n",
      "backbone.stages.0.blocks.1.ffn.layers.1.bias - torch.Size([192]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,635 - mmcv - INFO - \n",
      "backbone.stages.0.downsample.norm.weight - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,635 - mmcv - INFO - \n",
      "backbone.stages.0.downsample.norm.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,636 - mmcv - INFO - \n",
      "backbone.stages.0.downsample.reduction.weight - torch.Size([384, 768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,636 - mmcv - INFO - \n",
      "backbone.stages.1.blocks.0.norm1.weight - torch.Size([384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,637 - mmcv - INFO - \n",
      "backbone.stages.1.blocks.0.norm1.bias - torch.Size([384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,637 - mmcv - INFO - \n",
      "backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,638 - mmcv - INFO - \n",
      "backbone.stages.1.blocks.0.attn.w_msa.qkv.weight - torch.Size([1152, 384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,638 - mmcv - INFO - \n",
      "backbone.stages.1.blocks.0.attn.w_msa.qkv.bias - torch.Size([1152]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,639 - mmcv - INFO - \n",
      "backbone.stages.1.blocks.0.attn.w_msa.proj.weight - torch.Size([384, 384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,639 - mmcv - INFO - \n",
      "backbone.stages.1.blocks.0.attn.w_msa.proj.bias - torch.Size([384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,640 - mmcv - INFO - \n",
      "backbone.stages.1.blocks.0.norm2.weight - torch.Size([384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,640 - mmcv - INFO - \n",
      "backbone.stages.1.blocks.0.norm2.bias - torch.Size([384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,641 - mmcv - INFO - \n",
      "backbone.stages.1.blocks.0.ffn.layers.0.0.weight - torch.Size([1536, 384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,641 - mmcv - INFO - \n",
      "backbone.stages.1.blocks.0.ffn.layers.0.0.bias - torch.Size([1536]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,642 - mmcv - INFO - \n",
      "backbone.stages.1.blocks.0.ffn.layers.1.weight - torch.Size([384, 1536]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,643 - mmcv - INFO - \n",
      "backbone.stages.1.blocks.0.ffn.layers.1.bias - torch.Size([384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,643 - mmcv - INFO - \n",
      "backbone.stages.1.blocks.1.norm1.weight - torch.Size([384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,644 - mmcv - INFO - \n",
      "backbone.stages.1.blocks.1.norm1.bias - torch.Size([384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,644 - mmcv - INFO - \n",
      "backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,645 - mmcv - INFO - \n",
      "backbone.stages.1.blocks.1.attn.w_msa.qkv.weight - torch.Size([1152, 384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,645 - mmcv - INFO - \n",
      "backbone.stages.1.blocks.1.attn.w_msa.qkv.bias - torch.Size([1152]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,646 - mmcv - INFO - \n",
      "backbone.stages.1.blocks.1.attn.w_msa.proj.weight - torch.Size([384, 384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,646 - mmcv - INFO - \n",
      "backbone.stages.1.blocks.1.attn.w_msa.proj.bias - torch.Size([384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,647 - mmcv - INFO - \n",
      "backbone.stages.1.blocks.1.norm2.weight - torch.Size([384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,647 - mmcv - INFO - \n",
      "backbone.stages.1.blocks.1.norm2.bias - torch.Size([384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,651 - mmcv - INFO - \n",
      "backbone.stages.1.blocks.1.ffn.layers.0.0.weight - torch.Size([1536, 384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,652 - mmcv - INFO - \n",
      "backbone.stages.1.blocks.1.ffn.layers.0.0.bias - torch.Size([1536]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,653 - mmcv - INFO - \n",
      "backbone.stages.1.blocks.1.ffn.layers.1.weight - torch.Size([384, 1536]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,653 - mmcv - INFO - \n",
      "backbone.stages.1.blocks.1.ffn.layers.1.bias - torch.Size([384]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,654 - mmcv - INFO - \n",
      "backbone.stages.1.downsample.norm.weight - torch.Size([1536]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,654 - mmcv - INFO - \n",
      "backbone.stages.1.downsample.norm.bias - torch.Size([1536]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,655 - mmcv - INFO - \n",
      "backbone.stages.1.downsample.reduction.weight - torch.Size([768, 1536]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,655 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.0.norm1.weight - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,656 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.0.norm1.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,656 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table - torch.Size([169, 24]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,657 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.0.attn.w_msa.qkv.weight - torch.Size([2304, 768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,657 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.0.attn.w_msa.qkv.bias - torch.Size([2304]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,658 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.0.attn.w_msa.proj.weight - torch.Size([768, 768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,658 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.0.attn.w_msa.proj.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,659 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.0.norm2.weight - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,659 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.0.norm2.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,660 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.0.ffn.layers.0.0.weight - torch.Size([3072, 768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,661 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.0.ffn.layers.0.0.bias - torch.Size([3072]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,661 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.0.ffn.layers.1.weight - torch.Size([768, 3072]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,662 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.0.ffn.layers.1.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,662 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.1.norm1.weight - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,663 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.1.norm1.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,663 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table - torch.Size([169, 24]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,664 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.1.attn.w_msa.qkv.weight - torch.Size([2304, 768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,664 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.1.attn.w_msa.qkv.bias - torch.Size([2304]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,665 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.1.attn.w_msa.proj.weight - torch.Size([768, 768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,665 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.1.attn.w_msa.proj.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,666 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.1.norm2.weight - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,666 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.1.norm2.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,667 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.1.ffn.layers.0.0.weight - torch.Size([3072, 768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,667 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.1.ffn.layers.0.0.bias - torch.Size([3072]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,668 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.1.ffn.layers.1.weight - torch.Size([768, 3072]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,668 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.1.ffn.layers.1.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,669 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.2.norm1.weight - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,669 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.2.norm1.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,670 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table - torch.Size([169, 24]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,670 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.2.attn.w_msa.qkv.weight - torch.Size([2304, 768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,671 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.2.attn.w_msa.qkv.bias - torch.Size([2304]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,671 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.2.attn.w_msa.proj.weight - torch.Size([768, 768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,672 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.2.attn.w_msa.proj.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,673 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.2.norm2.weight - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,673 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.2.norm2.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,674 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.2.ffn.layers.0.0.weight - torch.Size([3072, 768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,674 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.2.ffn.layers.0.0.bias - torch.Size([3072]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,675 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.2.ffn.layers.1.weight - torch.Size([768, 3072]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,675 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.2.ffn.layers.1.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,676 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.3.norm1.weight - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,676 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.3.norm1.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,677 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table - torch.Size([169, 24]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,677 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.3.attn.w_msa.qkv.weight - torch.Size([2304, 768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,678 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.3.attn.w_msa.qkv.bias - torch.Size([2304]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,679 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.3.attn.w_msa.proj.weight - torch.Size([768, 768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,679 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.3.attn.w_msa.proj.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,680 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.3.norm2.weight - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,680 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.3.norm2.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,681 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.3.ffn.layers.0.0.weight - torch.Size([3072, 768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,681 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.3.ffn.layers.0.0.bias - torch.Size([3072]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,682 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.3.ffn.layers.1.weight - torch.Size([768, 3072]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,683 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.3.ffn.layers.1.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,683 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.4.norm1.weight - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,684 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.4.norm1.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,684 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table - torch.Size([169, 24]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,685 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.4.attn.w_msa.qkv.weight - torch.Size([2304, 768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,685 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.4.attn.w_msa.qkv.bias - torch.Size([2304]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,686 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.4.attn.w_msa.proj.weight - torch.Size([768, 768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,686 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.4.attn.w_msa.proj.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,687 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.4.norm2.weight - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,688 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.4.norm2.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,688 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.4.ffn.layers.0.0.weight - torch.Size([3072, 768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,689 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.4.ffn.layers.0.0.bias - torch.Size([3072]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,689 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.4.ffn.layers.1.weight - torch.Size([768, 3072]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,690 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.4.ffn.layers.1.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,691 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.5.norm1.weight - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,691 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.5.norm1.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,692 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table - torch.Size([169, 24]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,692 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.5.attn.w_msa.qkv.weight - torch.Size([2304, 768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,693 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.5.attn.w_msa.qkv.bias - torch.Size([2304]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,694 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.5.attn.w_msa.proj.weight - torch.Size([768, 768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,694 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.5.attn.w_msa.proj.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,695 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.5.norm2.weight - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,695 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.5.norm2.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,696 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.5.ffn.layers.0.0.weight - torch.Size([3072, 768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,697 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.5.ffn.layers.0.0.bias - torch.Size([3072]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,697 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.5.ffn.layers.1.weight - torch.Size([768, 3072]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,698 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.5.ffn.layers.1.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,699 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.6.norm1.weight - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,699 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.6.norm1.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,700 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.6.attn.w_msa.relative_position_bias_table - torch.Size([169, 24]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,700 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.6.attn.w_msa.qkv.weight - torch.Size([2304, 768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,701 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.6.attn.w_msa.qkv.bias - torch.Size([2304]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,702 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.6.attn.w_msa.proj.weight - torch.Size([768, 768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,702 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.6.attn.w_msa.proj.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,703 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.6.norm2.weight - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,703 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.6.norm2.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,704 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.6.ffn.layers.0.0.weight - torch.Size([3072, 768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,705 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.6.ffn.layers.0.0.bias - torch.Size([3072]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,705 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.6.ffn.layers.1.weight - torch.Size([768, 3072]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,706 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.6.ffn.layers.1.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,707 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.7.norm1.weight - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,707 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.7.norm1.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,708 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.7.attn.w_msa.relative_position_bias_table - torch.Size([169, 24]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,708 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.7.attn.w_msa.qkv.weight - torch.Size([2304, 768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,709 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.7.attn.w_msa.qkv.bias - torch.Size([2304]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,710 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.7.attn.w_msa.proj.weight - torch.Size([768, 768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,710 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.7.attn.w_msa.proj.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,711 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.7.norm2.weight - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,712 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.7.norm2.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,712 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.7.ffn.layers.0.0.weight - torch.Size([3072, 768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,713 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.7.ffn.layers.0.0.bias - torch.Size([3072]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,713 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.7.ffn.layers.1.weight - torch.Size([768, 3072]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,714 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.7.ffn.layers.1.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,715 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.8.norm1.weight - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,715 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.8.norm1.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,716 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.8.attn.w_msa.relative_position_bias_table - torch.Size([169, 24]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,717 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.8.attn.w_msa.qkv.weight - torch.Size([2304, 768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,717 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.8.attn.w_msa.qkv.bias - torch.Size([2304]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,718 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.8.attn.w_msa.proj.weight - torch.Size([768, 768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,718 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.8.attn.w_msa.proj.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,719 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.8.norm2.weight - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,720 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.8.norm2.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,720 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.8.ffn.layers.0.0.weight - torch.Size([3072, 768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,721 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.8.ffn.layers.0.0.bias - torch.Size([3072]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,721 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.8.ffn.layers.1.weight - torch.Size([768, 3072]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,722 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.8.ffn.layers.1.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,723 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.9.norm1.weight - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,723 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.9.norm1.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,724 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.9.attn.w_msa.relative_position_bias_table - torch.Size([169, 24]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,725 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.9.attn.w_msa.qkv.weight - torch.Size([2304, 768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,725 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.9.attn.w_msa.qkv.bias - torch.Size([2304]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,726 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.9.attn.w_msa.proj.weight - torch.Size([768, 768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,726 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.9.attn.w_msa.proj.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,727 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.9.norm2.weight - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,728 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.9.norm2.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,728 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.9.ffn.layers.0.0.weight - torch.Size([3072, 768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,729 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.9.ffn.layers.0.0.bias - torch.Size([3072]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,729 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.9.ffn.layers.1.weight - torch.Size([768, 3072]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,730 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.9.ffn.layers.1.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,731 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.10.norm1.weight - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,731 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.10.norm1.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,732 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.10.attn.w_msa.relative_position_bias_table - torch.Size([169, 24]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,732 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.10.attn.w_msa.qkv.weight - torch.Size([2304, 768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,733 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.10.attn.w_msa.qkv.bias - torch.Size([2304]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,734 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.10.attn.w_msa.proj.weight - torch.Size([768, 768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,734 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.10.attn.w_msa.proj.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,735 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.10.norm2.weight - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,735 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.10.norm2.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,736 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.10.ffn.layers.0.0.weight - torch.Size([3072, 768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,737 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.10.ffn.layers.0.0.bias - torch.Size([3072]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,737 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.10.ffn.layers.1.weight - torch.Size([768, 3072]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,738 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.10.ffn.layers.1.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,738 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.11.norm1.weight - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,739 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.11.norm1.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,740 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.11.attn.w_msa.relative_position_bias_table - torch.Size([169, 24]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,740 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.11.attn.w_msa.qkv.weight - torch.Size([2304, 768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,741 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.11.attn.w_msa.qkv.bias - torch.Size([2304]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,741 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.11.attn.w_msa.proj.weight - torch.Size([768, 768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,742 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.11.attn.w_msa.proj.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,743 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.11.norm2.weight - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,743 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.11.norm2.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,744 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.11.ffn.layers.0.0.weight - torch.Size([3072, 768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,744 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.11.ffn.layers.0.0.bias - torch.Size([3072]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,745 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.11.ffn.layers.1.weight - torch.Size([768, 3072]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,746 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.11.ffn.layers.1.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,746 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.12.norm1.weight - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,747 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.12.norm1.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,748 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.12.attn.w_msa.relative_position_bias_table - torch.Size([169, 24]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,748 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.12.attn.w_msa.qkv.weight - torch.Size([2304, 768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,749 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.12.attn.w_msa.qkv.bias - torch.Size([2304]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,749 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.12.attn.w_msa.proj.weight - torch.Size([768, 768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,750 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.12.attn.w_msa.proj.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,751 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.12.norm2.weight - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,751 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.12.norm2.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,752 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.12.ffn.layers.0.0.weight - torch.Size([3072, 768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,752 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.12.ffn.layers.0.0.bias - torch.Size([3072]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,753 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.12.ffn.layers.1.weight - torch.Size([768, 3072]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,754 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.12.ffn.layers.1.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,754 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.13.norm1.weight - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,755 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.13.norm1.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,756 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.13.attn.w_msa.relative_position_bias_table - torch.Size([169, 24]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,756 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.13.attn.w_msa.qkv.weight - torch.Size([2304, 768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,757 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.13.attn.w_msa.qkv.bias - torch.Size([2304]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,757 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.13.attn.w_msa.proj.weight - torch.Size([768, 768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,758 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.13.attn.w_msa.proj.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,759 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.13.norm2.weight - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,759 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.13.norm2.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,760 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.13.ffn.layers.0.0.weight - torch.Size([3072, 768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,760 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.13.ffn.layers.0.0.bias - torch.Size([3072]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,761 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.13.ffn.layers.1.weight - torch.Size([768, 3072]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,762 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.13.ffn.layers.1.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,762 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.14.norm1.weight - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,763 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.14.norm1.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,764 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.14.attn.w_msa.relative_position_bias_table - torch.Size([169, 24]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,764 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.14.attn.w_msa.qkv.weight - torch.Size([2304, 768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,765 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.14.attn.w_msa.qkv.bias - torch.Size([2304]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,765 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.14.attn.w_msa.proj.weight - torch.Size([768, 768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,766 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.14.attn.w_msa.proj.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,767 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.14.norm2.weight - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,767 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.14.norm2.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,768 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.14.ffn.layers.0.0.weight - torch.Size([3072, 768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,768 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.14.ffn.layers.0.0.bias - torch.Size([3072]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,769 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.14.ffn.layers.1.weight - torch.Size([768, 3072]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,770 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.14.ffn.layers.1.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,770 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.15.norm1.weight - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,771 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.15.norm1.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,772 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.15.attn.w_msa.relative_position_bias_table - torch.Size([169, 24]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,773 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.15.attn.w_msa.qkv.weight - torch.Size([2304, 768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,773 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.15.attn.w_msa.qkv.bias - torch.Size([2304]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,774 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.15.attn.w_msa.proj.weight - torch.Size([768, 768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,774 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.15.attn.w_msa.proj.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,775 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.15.norm2.weight - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,776 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.15.norm2.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,776 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.15.ffn.layers.0.0.weight - torch.Size([3072, 768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,777 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.15.ffn.layers.0.0.bias - torch.Size([3072]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,777 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.15.ffn.layers.1.weight - torch.Size([768, 3072]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,778 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.15.ffn.layers.1.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,779 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.16.norm1.weight - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,779 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.16.norm1.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,780 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.16.attn.w_msa.relative_position_bias_table - torch.Size([169, 24]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,780 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.16.attn.w_msa.qkv.weight - torch.Size([2304, 768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,781 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.16.attn.w_msa.qkv.bias - torch.Size([2304]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,782 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.16.attn.w_msa.proj.weight - torch.Size([768, 768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,782 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.16.attn.w_msa.proj.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,783 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.16.norm2.weight - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,783 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.16.norm2.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,784 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.16.ffn.layers.0.0.weight - torch.Size([3072, 768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,784 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.16.ffn.layers.0.0.bias - torch.Size([3072]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,785 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.16.ffn.layers.1.weight - torch.Size([768, 3072]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,785 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.16.ffn.layers.1.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,786 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.17.norm1.weight - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,786 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.17.norm1.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,787 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.17.attn.w_msa.relative_position_bias_table - torch.Size([169, 24]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,787 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.17.attn.w_msa.qkv.weight - torch.Size([2304, 768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,787 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.17.attn.w_msa.qkv.bias - torch.Size([2304]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,788 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.17.attn.w_msa.proj.weight - torch.Size([768, 768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,788 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.17.attn.w_msa.proj.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,789 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.17.norm2.weight - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,789 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.17.norm2.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,790 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.17.ffn.layers.0.0.weight - torch.Size([3072, 768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,790 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.17.ffn.layers.0.0.bias - torch.Size([3072]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,790 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.17.ffn.layers.1.weight - torch.Size([768, 3072]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,791 - mmcv - INFO - \n",
      "backbone.stages.2.blocks.17.ffn.layers.1.bias - torch.Size([768]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,791 - mmcv - INFO - \n",
      "backbone.stages.2.downsample.norm.weight - torch.Size([3072]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,792 - mmcv - INFO - \n",
      "backbone.stages.2.downsample.norm.bias - torch.Size([3072]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,792 - mmcv - INFO - \n",
      "backbone.stages.2.downsample.reduction.weight - torch.Size([1536, 3072]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,793 - mmcv - INFO - \n",
      "backbone.stages.3.blocks.0.norm1.weight - torch.Size([1536]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,793 - mmcv - INFO - \n",
      "backbone.stages.3.blocks.0.norm1.bias - torch.Size([1536]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,793 - mmcv - INFO - \n",
      "backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table - torch.Size([169, 48]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,794 - mmcv - INFO - \n",
      "backbone.stages.3.blocks.0.attn.w_msa.qkv.weight - torch.Size([4608, 1536]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,794 - mmcv - INFO - \n",
      "backbone.stages.3.blocks.0.attn.w_msa.qkv.bias - torch.Size([4608]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,795 - mmcv - INFO - \n",
      "backbone.stages.3.blocks.0.attn.w_msa.proj.weight - torch.Size([1536, 1536]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,795 - mmcv - INFO - \n",
      "backbone.stages.3.blocks.0.attn.w_msa.proj.bias - torch.Size([1536]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,796 - mmcv - INFO - \n",
      "backbone.stages.3.blocks.0.norm2.weight - torch.Size([1536]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,796 - mmcv - INFO - \n",
      "backbone.stages.3.blocks.0.norm2.bias - torch.Size([1536]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,796 - mmcv - INFO - \n",
      "backbone.stages.3.blocks.0.ffn.layers.0.0.weight - torch.Size([6144, 1536]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,797 - mmcv - INFO - \n",
      "backbone.stages.3.blocks.0.ffn.layers.0.0.bias - torch.Size([6144]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,797 - mmcv - INFO - \n",
      "backbone.stages.3.blocks.0.ffn.layers.1.weight - torch.Size([1536, 6144]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,798 - mmcv - INFO - \n",
      "backbone.stages.3.blocks.0.ffn.layers.1.bias - torch.Size([1536]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,798 - mmcv - INFO - \n",
      "backbone.stages.3.blocks.1.norm1.weight - torch.Size([1536]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,799 - mmcv - INFO - \n",
      "backbone.stages.3.blocks.1.norm1.bias - torch.Size([1536]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,799 - mmcv - INFO - \n",
      "backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table - torch.Size([169, 48]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,800 - mmcv - INFO - \n",
      "backbone.stages.3.blocks.1.attn.w_msa.qkv.weight - torch.Size([4608, 1536]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,800 - mmcv - INFO - \n",
      "backbone.stages.3.blocks.1.attn.w_msa.qkv.bias - torch.Size([4608]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,801 - mmcv - INFO - \n",
      "backbone.stages.3.blocks.1.attn.w_msa.proj.weight - torch.Size([1536, 1536]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,801 - mmcv - INFO - \n",
      "backbone.stages.3.blocks.1.attn.w_msa.proj.bias - torch.Size([1536]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,802 - mmcv - INFO - \n",
      "backbone.stages.3.blocks.1.norm2.weight - torch.Size([1536]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,802 - mmcv - INFO - \n",
      "backbone.stages.3.blocks.1.norm2.bias - torch.Size([1536]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,803 - mmcv - INFO - \n",
      "backbone.stages.3.blocks.1.ffn.layers.0.0.weight - torch.Size([6144, 1536]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,803 - mmcv - INFO - \n",
      "backbone.stages.3.blocks.1.ffn.layers.0.0.bias - torch.Size([6144]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,803 - mmcv - INFO - \n",
      "backbone.stages.3.blocks.1.ffn.layers.1.weight - torch.Size([1536, 6144]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,804 - mmcv - INFO - \n",
      "backbone.stages.3.blocks.1.ffn.layers.1.bias - torch.Size([1536]): \n",
      "Initialized by user-defined `init_weights` in SwinTransformer  \n",
      " \n",
      "2022-04-07 02:10:54,804 - mmcv - INFO - \n",
      "backbone.norm0.weight - torch.Size([192]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,805 - mmcv - INFO - \n",
      "backbone.norm0.bias - torch.Size([192]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,805 - mmcv - INFO - \n",
      "backbone.norm1.weight - torch.Size([384]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,806 - mmcv - INFO - \n",
      "backbone.norm1.bias - torch.Size([384]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,806 - mmcv - INFO - \n",
      "backbone.norm2.weight - torch.Size([768]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,807 - mmcv - INFO - \n",
      "backbone.norm2.bias - torch.Size([768]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,807 - mmcv - INFO - \n",
      "backbone.norm3.weight - torch.Size([1536]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,808 - mmcv - INFO - \n",
      "backbone.norm3.bias - torch.Size([1536]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,808 - mmcv - INFO - \n",
      "neck.0.lateral_convs.0.conv.weight - torch.Size([256, 192, 1, 1]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2022-04-07 02:10:54,809 - mmcv - INFO - \n",
      "neck.0.lateral_convs.0.conv.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,809 - mmcv - INFO - \n",
      "neck.0.lateral_convs.1.conv.weight - torch.Size([256, 384, 1, 1]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2022-04-07 02:10:54,810 - mmcv - INFO - \n",
      "neck.0.lateral_convs.1.conv.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,811 - mmcv - INFO - \n",
      "neck.0.lateral_convs.2.conv.weight - torch.Size([256, 768, 1, 1]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2022-04-07 02:10:54,811 - mmcv - INFO - \n",
      "neck.0.lateral_convs.2.conv.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,812 - mmcv - INFO - \n",
      "neck.0.lateral_convs.3.conv.weight - torch.Size([256, 1536, 1, 1]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2022-04-07 02:10:54,812 - mmcv - INFO - \n",
      "neck.0.lateral_convs.3.conv.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,813 - mmcv - INFO - \n",
      "neck.0.fpn_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2022-04-07 02:10:54,813 - mmcv - INFO - \n",
      "neck.0.fpn_convs.0.conv.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,814 - mmcv - INFO - \n",
      "neck.0.fpn_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2022-04-07 02:10:54,814 - mmcv - INFO - \n",
      "neck.0.fpn_convs.1.conv.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,815 - mmcv - INFO - \n",
      "neck.0.fpn_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2022-04-07 02:10:54,815 - mmcv - INFO - \n",
      "neck.0.fpn_convs.2.conv.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,815 - mmcv - INFO - \n",
      "neck.0.fpn_convs.3.conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2022-04-07 02:10:54,816 - mmcv - INFO - \n",
      "neck.0.fpn_convs.3.conv.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,816 - mmcv - INFO - \n",
      "neck.1.pconvs.0.pconv.0.weight - torch.Size([256, 256, 3, 3]): \n",
      "Initialized by user-defined `init_weights` in PConvModule  \n",
      " \n",
      "2022-04-07 02:10:54,817 - mmcv - INFO - \n",
      "neck.1.pconvs.0.pconv.0.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,819 - mmcv - INFO - \n",
      "neck.1.pconvs.0.pconv.0.conv_offset.weight - torch.Size([18, 256, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,819 - mmcv - INFO - \n",
      "neck.1.pconvs.0.pconv.0.conv_offset.bias - torch.Size([18]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,822 - mmcv - INFO - \n",
      "neck.1.pconvs.0.pconv.1.weight - torch.Size([256, 256, 3, 3]): \n",
      "Initialized by user-defined `init_weights` in PConvModule  \n",
      " \n",
      "2022-04-07 02:10:54,822 - mmcv - INFO - \n",
      "neck.1.pconvs.0.pconv.1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,823 - mmcv - INFO - \n",
      "neck.1.pconvs.0.pconv.1.conv_offset.weight - torch.Size([18, 256, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,823 - mmcv - INFO - \n",
      "neck.1.pconvs.0.pconv.1.conv_offset.bias - torch.Size([18]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,824 - mmcv - INFO - \n",
      "neck.1.pconvs.0.pconv.2.weight - torch.Size([256, 256, 3, 3]): \n",
      "Initialized by user-defined `init_weights` in PConvModule  \n",
      " \n",
      "2022-04-07 02:10:54,824 - mmcv - INFO - \n",
      "neck.1.pconvs.0.pconv.2.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,824 - mmcv - INFO - \n",
      "neck.1.pconvs.0.pconv.2.conv_offset.weight - torch.Size([18, 256, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,825 - mmcv - INFO - \n",
      "neck.1.pconvs.0.pconv.2.conv_offset.bias - torch.Size([18]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,825 - mmcv - INFO - \n",
      "neck.1.pconvs.0.bn.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,826 - mmcv - INFO - \n",
      "neck.1.pconvs.0.bn.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,826 - mmcv - INFO - \n",
      "neck.1.pconvs.1.pconv.0.weight - torch.Size([256, 256, 3, 3]): \n",
      "Initialized by user-defined `init_weights` in PConvModule  \n",
      " \n",
      "2022-04-07 02:10:54,827 - mmcv - INFO - \n",
      "neck.1.pconvs.1.pconv.0.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,828 - mmcv - INFO - \n",
      "neck.1.pconvs.1.pconv.0.conv_offset.weight - torch.Size([18, 256, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,833 - mmcv - INFO - \n",
      "neck.1.pconvs.1.pconv.0.conv_offset.bias - torch.Size([18]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,837 - mmcv - INFO - \n",
      "neck.1.pconvs.1.pconv.1.weight - torch.Size([256, 256, 3, 3]): \n",
      "Initialized by user-defined `init_weights` in PConvModule  \n",
      " \n",
      "2022-04-07 02:10:54,837 - mmcv - INFO - \n",
      "neck.1.pconvs.1.pconv.1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,838 - mmcv - INFO - \n",
      "neck.1.pconvs.1.pconv.1.conv_offset.weight - torch.Size([18, 256, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,838 - mmcv - INFO - \n",
      "neck.1.pconvs.1.pconv.1.conv_offset.bias - torch.Size([18]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,838 - mmcv - INFO - \n",
      "neck.1.pconvs.1.pconv.2.weight - torch.Size([256, 256, 3, 3]): \n",
      "Initialized by user-defined `init_weights` in PConvModule  \n",
      " \n",
      "2022-04-07 02:10:54,839 - mmcv - INFO - \n",
      "neck.1.pconvs.1.pconv.2.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,839 - mmcv - INFO - \n",
      "neck.1.pconvs.1.pconv.2.conv_offset.weight - torch.Size([18, 256, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,840 - mmcv - INFO - \n",
      "neck.1.pconvs.1.pconv.2.conv_offset.bias - torch.Size([18]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,840 - mmcv - INFO - \n",
      "neck.1.pconvs.1.bn.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,841 - mmcv - INFO - \n",
      "neck.1.pconvs.1.bn.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,841 - mmcv - INFO - \n",
      "neck.1.pconvs.2.pconv.0.weight - torch.Size([256, 256, 3, 3]): \n",
      "Initialized by user-defined `init_weights` in PConvModule  \n",
      " \n",
      "2022-04-07 02:10:54,842 - mmcv - INFO - \n",
      "neck.1.pconvs.2.pconv.0.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,842 - mmcv - INFO - \n",
      "neck.1.pconvs.2.pconv.0.conv_offset.weight - torch.Size([18, 256, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,843 - mmcv - INFO - \n",
      "neck.1.pconvs.2.pconv.0.conv_offset.bias - torch.Size([18]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,843 - mmcv - INFO - \n",
      "neck.1.pconvs.2.pconv.1.weight - torch.Size([256, 256, 3, 3]): \n",
      "Initialized by user-defined `init_weights` in PConvModule  \n",
      " \n",
      "2022-04-07 02:10:54,844 - mmcv - INFO - \n",
      "neck.1.pconvs.2.pconv.1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,844 - mmcv - INFO - \n",
      "neck.1.pconvs.2.pconv.1.conv_offset.weight - torch.Size([18, 256, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,845 - mmcv - INFO - \n",
      "neck.1.pconvs.2.pconv.1.conv_offset.bias - torch.Size([18]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,845 - mmcv - INFO - \n",
      "neck.1.pconvs.2.pconv.2.weight - torch.Size([256, 256, 3, 3]): \n",
      "Initialized by user-defined `init_weights` in PConvModule  \n",
      " \n",
      "2022-04-07 02:10:54,846 - mmcv - INFO - \n",
      "neck.1.pconvs.2.pconv.2.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,846 - mmcv - INFO - \n",
      "neck.1.pconvs.2.pconv.2.conv_offset.weight - torch.Size([18, 256, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,846 - mmcv - INFO - \n",
      "neck.1.pconvs.2.pconv.2.conv_offset.bias - torch.Size([18]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,849 - mmcv - INFO - \n",
      "neck.1.pconvs.2.bn.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,852 - mmcv - INFO - \n",
      "neck.1.pconvs.2.bn.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,852 - mmcv - INFO - \n",
      "neck.1.pconvs.3.pconv.0.weight - torch.Size([256, 256, 3, 3]): \n",
      "Initialized by user-defined `init_weights` in PConvModule  \n",
      " \n",
      "2022-04-07 02:10:54,853 - mmcv - INFO - \n",
      "neck.1.pconvs.3.pconv.0.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,853 - mmcv - INFO - \n",
      "neck.1.pconvs.3.pconv.0.conv_offset.weight - torch.Size([18, 256, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,853 - mmcv - INFO - \n",
      "neck.1.pconvs.3.pconv.0.conv_offset.bias - torch.Size([18]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,854 - mmcv - INFO - \n",
      "neck.1.pconvs.3.pconv.1.weight - torch.Size([256, 256, 3, 3]): \n",
      "Initialized by user-defined `init_weights` in PConvModule  \n",
      " \n",
      "2022-04-07 02:10:54,854 - mmcv - INFO - \n",
      "neck.1.pconvs.3.pconv.1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,855 - mmcv - INFO - \n",
      "neck.1.pconvs.3.pconv.1.conv_offset.weight - torch.Size([18, 256, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,855 - mmcv - INFO - \n",
      "neck.1.pconvs.3.pconv.1.conv_offset.bias - torch.Size([18]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,856 - mmcv - INFO - \n",
      "neck.1.pconvs.3.pconv.2.weight - torch.Size([256, 256, 3, 3]): \n",
      "Initialized by user-defined `init_weights` in PConvModule  \n",
      " \n",
      "2022-04-07 02:10:54,856 - mmcv - INFO - \n",
      "neck.1.pconvs.3.pconv.2.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,857 - mmcv - INFO - \n",
      "neck.1.pconvs.3.pconv.2.conv_offset.weight - torch.Size([18, 256, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,859 - mmcv - INFO - \n",
      "neck.1.pconvs.3.pconv.2.conv_offset.bias - torch.Size([18]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,859 - mmcv - INFO - \n",
      "neck.1.pconvs.3.bn.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,860 - mmcv - INFO - \n",
      "neck.1.pconvs.3.bn.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,862 - mmcv - INFO - \n",
      "neck.1.lconv.weight - torch.Size([256, 256, 3, 3]): \n",
      "Initialized by user-defined `init_weights` in SEPC  \n",
      " \n",
      "2022-04-07 02:10:54,870 - mmcv - INFO - \n",
      "neck.1.lconv.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,870 - mmcv - INFO - \n",
      "neck.1.lconv.conv_offset.weight - torch.Size([18, 256, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,871 - mmcv - INFO - \n",
      "neck.1.lconv.conv_offset.bias - torch.Size([18]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,871 - mmcv - INFO - \n",
      "neck.1.cconv.weight - torch.Size([256, 256, 3, 3]): \n",
      "Initialized by user-defined `init_weights` in SEPC  \n",
      " \n",
      "2022-04-07 02:10:54,872 - mmcv - INFO - \n",
      "neck.1.cconv.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,872 - mmcv - INFO - \n",
      "neck.1.cconv.conv_offset.weight - torch.Size([18, 256, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,872 - mmcv - INFO - \n",
      "neck.1.cconv.conv_offset.bias - torch.Size([18]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,873 - mmcv - INFO - \n",
      "neck.1.bn_loc.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,873 - mmcv - INFO - \n",
      "neck.1.bn_loc.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,874 - mmcv - INFO - \n",
      "neck.1.bn_cls.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,874 - mmcv - INFO - \n",
      "neck.1.bn_cls.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,875 - mmcv - INFO - \n",
      "bbox_head.gfl_cls.weight - torch.Size([10, 256, 3, 3]): \n",
      "NormalInit: mean=0, std=0.01, bias=-4.59511985013459 \n",
      " \n",
      "2022-04-07 02:10:54,875 - mmcv - INFO - \n",
      "bbox_head.gfl_cls.bias - torch.Size([10]): \n",
      "NormalInit: mean=0, std=0.01, bias=-4.59511985013459 \n",
      " \n",
      "2022-04-07 02:10:54,879 - mmcv - INFO - \n",
      "bbox_head.gfl_reg.weight - torch.Size([68, 256, 3, 3]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "2022-04-07 02:10:54,880 - mmcv - INFO - \n",
      "bbox_head.gfl_reg.bias - torch.Size([68]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "2022-04-07 02:10:54,880 - mmcv - INFO - \n",
      "bbox_head.scales.0.scale - torch.Size([]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,881 - mmcv - INFO - \n",
      "bbox_head.scales.1.scale - torch.Size([]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,881 - mmcv - INFO - \n",
      "bbox_head.scales.2.scale - torch.Size([]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,882 - mmcv - INFO - \n",
      "bbox_head.scales.3.scale - torch.Size([]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n",
      "2022-04-07 02:10:54,882 - mmcv - INFO - \n",
      "bbox_head.scales.4.scale - torch.Size([]): \n",
      "The value is the same before and after calling `init_weights` of GFL  \n",
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GFL(\n",
      "  (backbone): SwinTransformer(\n",
      "    (patch_embed): PatchEmbed(\n",
      "      (adap_padding): AdaptivePadding()\n",
      "      (projection): Conv2d(3, 192, kernel_size=(4, 4), stride=(4, 4))\n",
      "      (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (drop_after_pos): Dropout(p=0.0, inplace=False)\n",
      "    (stages): ModuleList(\n",
      "      (0): SwinBlockSequence(\n",
      "        (blocks): ModuleList(\n",
      "          (0): SwinBlock(\n",
      "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): ShiftWindowMSA(\n",
      "              (w_msa): WindowMSA(\n",
      "                (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop): DropPath()\n",
      "            )\n",
      "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            (ffn): FFN(\n",
      "              (activate): GELU()\n",
      "              (layers): Sequential(\n",
      "                (0): Sequential(\n",
      "                  (0): Linear(in_features=192, out_features=768, bias=True)\n",
      "                  (1): GELU()\n",
      "                  (2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (1): Linear(in_features=768, out_features=192, bias=True)\n",
      "                (2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (dropout_layer): DropPath()\n",
      "            )\n",
      "          )\n",
      "          (1): SwinBlock(\n",
      "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): ShiftWindowMSA(\n",
      "              (w_msa): WindowMSA(\n",
      "                (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop): DropPath()\n",
      "            )\n",
      "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            (ffn): FFN(\n",
      "              (activate): GELU()\n",
      "              (layers): Sequential(\n",
      "                (0): Sequential(\n",
      "                  (0): Linear(in_features=192, out_features=768, bias=True)\n",
      "                  (1): GELU()\n",
      "                  (2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (1): Linear(in_features=768, out_features=192, bias=True)\n",
      "                (2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (dropout_layer): DropPath()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (downsample): PatchMerging(\n",
      "          (adap_padding): AdaptivePadding()\n",
      "          (sampler): Unfold(kernel_size=(2, 2), dilation=(1, 1), padding=(0, 0), stride=(2, 2))\n",
      "          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
      "        )\n",
      "      )\n",
      "      (1): SwinBlockSequence(\n",
      "        (blocks): ModuleList(\n",
      "          (0): SwinBlock(\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): ShiftWindowMSA(\n",
      "              (w_msa): WindowMSA(\n",
      "                (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop): DropPath()\n",
      "            )\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (ffn): FFN(\n",
      "              (activate): GELU()\n",
      "              (layers): Sequential(\n",
      "                (0): Sequential(\n",
      "                  (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                  (1): GELU()\n",
      "                  (2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (1): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (dropout_layer): DropPath()\n",
      "            )\n",
      "          )\n",
      "          (1): SwinBlock(\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): ShiftWindowMSA(\n",
      "              (w_msa): WindowMSA(\n",
      "                (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop): DropPath()\n",
      "            )\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (ffn): FFN(\n",
      "              (activate): GELU()\n",
      "              (layers): Sequential(\n",
      "                (0): Sequential(\n",
      "                  (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                  (1): GELU()\n",
      "                  (2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (1): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (dropout_layer): DropPath()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (downsample): PatchMerging(\n",
      "          (adap_padding): AdaptivePadding()\n",
      "          (sampler): Unfold(kernel_size=(2, 2), dilation=(1, 1), padding=(0, 0), stride=(2, 2))\n",
      "          (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "          (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
      "        )\n",
      "      )\n",
      "      (2): SwinBlockSequence(\n",
      "        (blocks): ModuleList(\n",
      "          (0): SwinBlock(\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): ShiftWindowMSA(\n",
      "              (w_msa): WindowMSA(\n",
      "                (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop): DropPath()\n",
      "            )\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (ffn): FFN(\n",
      "              (activate): GELU()\n",
      "              (layers): Sequential(\n",
      "                (0): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (1): GELU()\n",
      "                  (2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (1): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (dropout_layer): DropPath()\n",
      "            )\n",
      "          )\n",
      "          (1): SwinBlock(\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): ShiftWindowMSA(\n",
      "              (w_msa): WindowMSA(\n",
      "                (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop): DropPath()\n",
      "            )\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (ffn): FFN(\n",
      "              (activate): GELU()\n",
      "              (layers): Sequential(\n",
      "                (0): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (1): GELU()\n",
      "                  (2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (1): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (dropout_layer): DropPath()\n",
      "            )\n",
      "          )\n",
      "          (2): SwinBlock(\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): ShiftWindowMSA(\n",
      "              (w_msa): WindowMSA(\n",
      "                (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop): DropPath()\n",
      "            )\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (ffn): FFN(\n",
      "              (activate): GELU()\n",
      "              (layers): Sequential(\n",
      "                (0): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (1): GELU()\n",
      "                  (2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (1): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (dropout_layer): DropPath()\n",
      "            )\n",
      "          )\n",
      "          (3): SwinBlock(\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): ShiftWindowMSA(\n",
      "              (w_msa): WindowMSA(\n",
      "                (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop): DropPath()\n",
      "            )\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (ffn): FFN(\n",
      "              (activate): GELU()\n",
      "              (layers): Sequential(\n",
      "                (0): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (1): GELU()\n",
      "                  (2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (1): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (dropout_layer): DropPath()\n",
      "            )\n",
      "          )\n",
      "          (4): SwinBlock(\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): ShiftWindowMSA(\n",
      "              (w_msa): WindowMSA(\n",
      "                (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop): DropPath()\n",
      "            )\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (ffn): FFN(\n",
      "              (activate): GELU()\n",
      "              (layers): Sequential(\n",
      "                (0): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (1): GELU()\n",
      "                  (2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (1): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (dropout_layer): DropPath()\n",
      "            )\n",
      "          )\n",
      "          (5): SwinBlock(\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): ShiftWindowMSA(\n",
      "              (w_msa): WindowMSA(\n",
      "                (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop): DropPath()\n",
      "            )\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (ffn): FFN(\n",
      "              (activate): GELU()\n",
      "              (layers): Sequential(\n",
      "                (0): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (1): GELU()\n",
      "                  (2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (1): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (dropout_layer): DropPath()\n",
      "            )\n",
      "          )\n",
      "          (6): SwinBlock(\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): ShiftWindowMSA(\n",
      "              (w_msa): WindowMSA(\n",
      "                (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop): DropPath()\n",
      "            )\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (ffn): FFN(\n",
      "              (activate): GELU()\n",
      "              (layers): Sequential(\n",
      "                (0): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (1): GELU()\n",
      "                  (2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (1): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (dropout_layer): DropPath()\n",
      "            )\n",
      "          )\n",
      "          (7): SwinBlock(\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): ShiftWindowMSA(\n",
      "              (w_msa): WindowMSA(\n",
      "                (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop): DropPath()\n",
      "            )\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (ffn): FFN(\n",
      "              (activate): GELU()\n",
      "              (layers): Sequential(\n",
      "                (0): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (1): GELU()\n",
      "                  (2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (1): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (dropout_layer): DropPath()\n",
      "            )\n",
      "          )\n",
      "          (8): SwinBlock(\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): ShiftWindowMSA(\n",
      "              (w_msa): WindowMSA(\n",
      "                (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop): DropPath()\n",
      "            )\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (ffn): FFN(\n",
      "              (activate): GELU()\n",
      "              (layers): Sequential(\n",
      "                (0): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (1): GELU()\n",
      "                  (2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (1): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (dropout_layer): DropPath()\n",
      "            )\n",
      "          )\n",
      "          (9): SwinBlock(\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): ShiftWindowMSA(\n",
      "              (w_msa): WindowMSA(\n",
      "                (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop): DropPath()\n",
      "            )\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (ffn): FFN(\n",
      "              (activate): GELU()\n",
      "              (layers): Sequential(\n",
      "                (0): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (1): GELU()\n",
      "                  (2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (1): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (dropout_layer): DropPath()\n",
      "            )\n",
      "          )\n",
      "          (10): SwinBlock(\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): ShiftWindowMSA(\n",
      "              (w_msa): WindowMSA(\n",
      "                (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop): DropPath()\n",
      "            )\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (ffn): FFN(\n",
      "              (activate): GELU()\n",
      "              (layers): Sequential(\n",
      "                (0): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (1): GELU()\n",
      "                  (2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (1): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (dropout_layer): DropPath()\n",
      "            )\n",
      "          )\n",
      "          (11): SwinBlock(\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): ShiftWindowMSA(\n",
      "              (w_msa): WindowMSA(\n",
      "                (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop): DropPath()\n",
      "            )\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (ffn): FFN(\n",
      "              (activate): GELU()\n",
      "              (layers): Sequential(\n",
      "                (0): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (1): GELU()\n",
      "                  (2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (1): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (dropout_layer): DropPath()\n",
      "            )\n",
      "          )\n",
      "          (12): SwinBlock(\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): ShiftWindowMSA(\n",
      "              (w_msa): WindowMSA(\n",
      "                (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop): DropPath()\n",
      "            )\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (ffn): FFN(\n",
      "              (activate): GELU()\n",
      "              (layers): Sequential(\n",
      "                (0): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (1): GELU()\n",
      "                  (2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (1): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (dropout_layer): DropPath()\n",
      "            )\n",
      "          )\n",
      "          (13): SwinBlock(\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): ShiftWindowMSA(\n",
      "              (w_msa): WindowMSA(\n",
      "                (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop): DropPath()\n",
      "            )\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (ffn): FFN(\n",
      "              (activate): GELU()\n",
      "              (layers): Sequential(\n",
      "                (0): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (1): GELU()\n",
      "                  (2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (1): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (dropout_layer): DropPath()\n",
      "            )\n",
      "          )\n",
      "          (14): SwinBlock(\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): ShiftWindowMSA(\n",
      "              (w_msa): WindowMSA(\n",
      "                (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop): DropPath()\n",
      "            )\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (ffn): FFN(\n",
      "              (activate): GELU()\n",
      "              (layers): Sequential(\n",
      "                (0): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (1): GELU()\n",
      "                  (2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (1): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (dropout_layer): DropPath()\n",
      "            )\n",
      "          )\n",
      "          (15): SwinBlock(\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): ShiftWindowMSA(\n",
      "              (w_msa): WindowMSA(\n",
      "                (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop): DropPath()\n",
      "            )\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (ffn): FFN(\n",
      "              (activate): GELU()\n",
      "              (layers): Sequential(\n",
      "                (0): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (1): GELU()\n",
      "                  (2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (1): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (dropout_layer): DropPath()\n",
      "            )\n",
      "          )\n",
      "          (16): SwinBlock(\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): ShiftWindowMSA(\n",
      "              (w_msa): WindowMSA(\n",
      "                (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop): DropPath()\n",
      "            )\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (ffn): FFN(\n",
      "              (activate): GELU()\n",
      "              (layers): Sequential(\n",
      "                (0): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (1): GELU()\n",
      "                  (2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (1): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (dropout_layer): DropPath()\n",
      "            )\n",
      "          )\n",
      "          (17): SwinBlock(\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): ShiftWindowMSA(\n",
      "              (w_msa): WindowMSA(\n",
      "                (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop): DropPath()\n",
      "            )\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (ffn): FFN(\n",
      "              (activate): GELU()\n",
      "              (layers): Sequential(\n",
      "                (0): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (1): GELU()\n",
      "                  (2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (1): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (dropout_layer): DropPath()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (downsample): PatchMerging(\n",
      "          (adap_padding): AdaptivePadding()\n",
      "          (sampler): Unfold(kernel_size=(2, 2), dilation=(1, 1), padding=(0, 0), stride=(2, 2))\n",
      "          (norm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
      "          (reduction): Linear(in_features=3072, out_features=1536, bias=False)\n",
      "        )\n",
      "      )\n",
      "      (3): SwinBlockSequence(\n",
      "        (blocks): ModuleList(\n",
      "          (0): SwinBlock(\n",
      "            (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): ShiftWindowMSA(\n",
      "              (w_msa): WindowMSA(\n",
      "                (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop): DropPath()\n",
      "            )\n",
      "            (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "            (ffn): FFN(\n",
      "              (activate): GELU()\n",
      "              (layers): Sequential(\n",
      "                (0): Sequential(\n",
      "                  (0): Linear(in_features=1536, out_features=6144, bias=True)\n",
      "                  (1): GELU()\n",
      "                  (2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (1): Linear(in_features=6144, out_features=1536, bias=True)\n",
      "                (2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (dropout_layer): DropPath()\n",
      "            )\n",
      "          )\n",
      "          (1): SwinBlock(\n",
      "            (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): ShiftWindowMSA(\n",
      "              (w_msa): WindowMSA(\n",
      "                (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop): DropPath()\n",
      "            )\n",
      "            (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "            (ffn): FFN(\n",
      "              (activate): GELU()\n",
      "              (layers): Sequential(\n",
      "                (0): Sequential(\n",
      "                  (0): Linear(in_features=1536, out_features=6144, bias=True)\n",
      "                  (1): GELU()\n",
      "                  (2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (1): Linear(in_features=6144, out_features=1536, bias=True)\n",
      "                (2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (dropout_layer): DropPath()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (norm0): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm3): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  init_cfg={'type': 'Pretrained', 'checkpoint': './swin_large_patch4_window7_224_22kto1k.pth'}\n",
      "  (neck): Sequential(\n",
      "    (0): FPN(\n",
      "      (lateral_convs): ModuleList(\n",
      "        (0): ConvModule(\n",
      "          (conv): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1): ConvModule(\n",
      "          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (2): ConvModule(\n",
      "          (conv): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (3): ConvModule(\n",
      "          (conv): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (fpn_convs): ModuleList(\n",
      "        (0): ConvModule(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (1): ConvModule(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (2): ConvModule(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (3): ConvModule(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    init_cfg={'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}\n",
      "    (1): SEPC(\n",
      "      (pconvs): ModuleList(\n",
      "        (0): PConvModule(\n",
      "          (pconv): ModuleList(\n",
      "            (0): SEPCConv(in_channels=256,\n",
      "            out_channels=256,\n",
      "            kernel_size=(3, 3),\n",
      "            stride=(1, 1),\n",
      "            padding=(1, 1),\n",
      "            dilation=(1, 1),\n",
      "            groups=1,\n",
      "            deform_groups=1,\n",
      "            bias=False)\n",
      "            (1): SEPCConv(in_channels=256,\n",
      "            out_channels=256,\n",
      "            kernel_size=(3, 3),\n",
      "            stride=(1, 1),\n",
      "            padding=(1, 1),\n",
      "            dilation=(1, 1),\n",
      "            groups=1,\n",
      "            deform_groups=1,\n",
      "            bias=False)\n",
      "            (2): SEPCConv(in_channels=256,\n",
      "            out_channels=256,\n",
      "            kernel_size=(3, 3),\n",
      "            stride=(2, 2),\n",
      "            padding=(1, 1),\n",
      "            dilation=(1, 1),\n",
      "            groups=1,\n",
      "            deform_groups=1,\n",
      "            bias=False)\n",
      "          )\n",
      "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (1): PConvModule(\n",
      "          (pconv): ModuleList(\n",
      "            (0): SEPCConv(in_channels=256,\n",
      "            out_channels=256,\n",
      "            kernel_size=(3, 3),\n",
      "            stride=(1, 1),\n",
      "            padding=(1, 1),\n",
      "            dilation=(1, 1),\n",
      "            groups=1,\n",
      "            deform_groups=1,\n",
      "            bias=False)\n",
      "            (1): SEPCConv(in_channels=256,\n",
      "            out_channels=256,\n",
      "            kernel_size=(3, 3),\n",
      "            stride=(1, 1),\n",
      "            padding=(1, 1),\n",
      "            dilation=(1, 1),\n",
      "            groups=1,\n",
      "            deform_groups=1,\n",
      "            bias=False)\n",
      "            (2): SEPCConv(in_channels=256,\n",
      "            out_channels=256,\n",
      "            kernel_size=(3, 3),\n",
      "            stride=(2, 2),\n",
      "            padding=(1, 1),\n",
      "            dilation=(1, 1),\n",
      "            groups=1,\n",
      "            deform_groups=1,\n",
      "            bias=False)\n",
      "          )\n",
      "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (2): PConvModule(\n",
      "          (pconv): ModuleList(\n",
      "            (0): SEPCConv(in_channels=256,\n",
      "            out_channels=256,\n",
      "            kernel_size=(3, 3),\n",
      "            stride=(1, 1),\n",
      "            padding=(1, 1),\n",
      "            dilation=(1, 1),\n",
      "            groups=1,\n",
      "            deform_groups=1,\n",
      "            bias=False)\n",
      "            (1): SEPCConv(in_channels=256,\n",
      "            out_channels=256,\n",
      "            kernel_size=(3, 3),\n",
      "            stride=(1, 1),\n",
      "            padding=(1, 1),\n",
      "            dilation=(1, 1),\n",
      "            groups=1,\n",
      "            deform_groups=1,\n",
      "            bias=False)\n",
      "            (2): SEPCConv(in_channels=256,\n",
      "            out_channels=256,\n",
      "            kernel_size=(3, 3),\n",
      "            stride=(2, 2),\n",
      "            padding=(1, 1),\n",
      "            dilation=(1, 1),\n",
      "            groups=1,\n",
      "            deform_groups=1,\n",
      "            bias=False)\n",
      "          )\n",
      "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (3): PConvModule(\n",
      "          (pconv): ModuleList(\n",
      "            (0): SEPCConv(in_channels=256,\n",
      "            out_channels=256,\n",
      "            kernel_size=(3, 3),\n",
      "            stride=(1, 1),\n",
      "            padding=(1, 1),\n",
      "            dilation=(1, 1),\n",
      "            groups=1,\n",
      "            deform_groups=1,\n",
      "            bias=False)\n",
      "            (1): SEPCConv(in_channels=256,\n",
      "            out_channels=256,\n",
      "            kernel_size=(3, 3),\n",
      "            stride=(1, 1),\n",
      "            padding=(1, 1),\n",
      "            dilation=(1, 1),\n",
      "            groups=1,\n",
      "            deform_groups=1,\n",
      "            bias=False)\n",
      "            (2): SEPCConv(in_channels=256,\n",
      "            out_channels=256,\n",
      "            kernel_size=(3, 3),\n",
      "            stride=(2, 2),\n",
      "            padding=(1, 1),\n",
      "            dilation=(1, 1),\n",
      "            groups=1,\n",
      "            deform_groups=1,\n",
      "            bias=False)\n",
      "          )\n",
      "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (lconv): SEPCConv(in_channels=256,\n",
      "      out_channels=256,\n",
      "      kernel_size=(3, 3),\n",
      "      stride=(1, 1),\n",
      "      padding=(1, 1),\n",
      "      dilation=(1, 1),\n",
      "      groups=1,\n",
      "      deform_groups=1,\n",
      "      bias=False)\n",
      "      (cconv): SEPCConv(in_channels=256,\n",
      "      out_channels=256,\n",
      "      kernel_size=(3, 3),\n",
      "      stride=(1, 1),\n",
      "      padding=(1, 1),\n",
      "      dilation=(1, 1),\n",
      "      groups=1,\n",
      "      deform_groups=1,\n",
      "      bias=False)\n",
      "      (bn_loc): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn_cls): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (bbox_head): GFLSEPCHead(\n",
      "    (loss_cls): QualityFocalLoss()\n",
      "    (loss_bbox): GIoULoss()\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (cls_convs): ModuleList()\n",
      "    (reg_convs): ModuleList()\n",
      "    (gfl_cls): Conv2d(256, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (gfl_reg): Conv2d(256, 68, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (scales): ModuleList(\n",
      "      (0): Scale()\n",
      "      (1): Scale()\n",
      "      (2): Scale()\n",
      "      (3): Scale()\n",
      "      (4): Scale()\n",
      "    )\n",
      "    (integral): Integral()\n",
      "    (loss_dfl): DistributionFocalLoss()\n",
      "  )\n",
      "  init_cfg={'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01, 'override': {'type': 'Normal', 'name': 'gfl_cls', 'std': 0.01, 'bias_prob': 0.01}}\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = build_detector(cfg.model)\n",
    "model.init_weights()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-07 02:11:07,665 - mmdet - INFO - load checkpoint from local path: ./work_dirs/_universe/epoch_22.pth\n",
      "2022-04-07 02:11:09,185 - mmdet - INFO - resumed epoch 22, iter 53724\n",
      "2022-04-07 02:11:09,189 - mmdet - INFO - Start running, host: root@2603c2edf705, work_dir: /opt/ml/detection/baseline/mmdetection/work_dirs/_universe\n",
      "2022-04-07 02:11:09,191 - mmdet - INFO - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(ABOVE_NORMAL) Fp16OptimizerHook                  \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) NumClassCheckHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(ABOVE_NORMAL) Fp16OptimizerHook                  \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) NumClassCheckHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_run:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "2022-04-07 02:11:09,192 - mmdet - INFO - workflow: [('train', 1)], max: 30 epochs\n",
      "2022-04-07 02:11:09,196 - mmdet - INFO - Checkpoints will be saved to /opt/ml/detection/baseline/mmdetection/work_dirs/_universe by HardDiskBackend.\n",
      "/opt/ml/detection/baseline/mmdetection/mmdet/models/losses/gfocal_loss.py:43: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /opt/conda/conda-bld/pytorch_1607370156314/work/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  pos = ((label >= 0) & (label < bg_class_ind)).nonzero().squeeze(1)\n",
      "2022-04-07 02:12:10,437 - mmdet - INFO - Epoch [23][50/2442]\tlr: 1.000e-04, eta: 6:37:43, time: 1.225, data_time: 0.058, memory: 17952, loss_cls: 0.3641, loss_bbox: 0.2733, loss_dfl: 0.2136, loss: 0.8510\n",
      "2022-04-07 02:13:08,476 - mmdet - INFO - Epoch [23][100/2442]\tlr: 1.000e-04, eta: 6:26:21, time: 1.161, data_time: 0.006, memory: 17952, loss_cls: 0.2891, loss_bbox: 0.2621, loss_dfl: 0.2057, loss: 0.7568\n",
      "2022-04-07 02:14:06,583 - mmdet - INFO - Epoch [23][150/2442]\tlr: 1.000e-04, eta: 6:22:04, time: 1.162, data_time: 0.006, memory: 17952, loss_cls: 0.3199, loss_bbox: 0.2723, loss_dfl: 0.2072, loss: 0.7994\n",
      "2022-04-07 02:15:04,631 - mmdet - INFO - Epoch [23][200/2442]\tlr: 1.000e-04, eta: 6:19:20, time: 1.161, data_time: 0.006, memory: 17952, loss_cls: 0.2935, loss_bbox: 0.2646, loss_dfl: 0.2056, loss: 0.7636\n",
      "2022-04-07 02:16:02,584 - mmdet - INFO - Epoch [23][250/2442]\tlr: 1.000e-04, eta: 6:17:12, time: 1.159, data_time: 0.006, memory: 17952, loss_cls: 0.2883, loss_bbox: 0.2692, loss_dfl: 0.2075, loss: 0.7649\n",
      "2022-04-07 02:17:00,523 - mmdet - INFO - Epoch [23][300/2442]\tlr: 1.000e-04, eta: 6:15:26, time: 1.159, data_time: 0.006, memory: 17952, loss_cls: 0.2877, loss_bbox: 0.2730, loss_dfl: 0.2111, loss: 0.7718\n",
      "2022-04-07 02:17:58,716 - mmdet - INFO - Epoch [23][350/2442]\tlr: 1.000e-04, eta: 6:14:07, time: 1.164, data_time: 0.006, memory: 17952, loss_cls: 0.2844, loss_bbox: 0.2492, loss_dfl: 0.1997, loss: 0.7333\n",
      "2022-04-07 02:18:56,732 - mmdet - INFO - Epoch [23][400/2442]\tlr: 1.000e-04, eta: 6:12:46, time: 1.160, data_time: 0.006, memory: 17952, loss_cls: 0.2911, loss_bbox: 0.2545, loss_dfl: 0.2025, loss: 0.7481\n",
      "2022-04-07 02:19:54,778 - mmdet - INFO - Epoch [23][450/2442]\tlr: 1.000e-04, eta: 6:11:31, time: 1.161, data_time: 0.006, memory: 17952, loss_cls: 0.2859, loss_bbox: 0.2753, loss_dfl: 0.2099, loss: 0.7712\n",
      "2022-04-07 02:20:52,777 - mmdet - INFO - Epoch [23][500/2442]\tlr: 1.000e-04, eta: 6:10:17, time: 1.160, data_time: 0.006, memory: 17952, loss_cls: 0.3148, loss_bbox: 0.3031, loss_dfl: 0.2183, loss: 0.8363\n",
      "2022-04-07 02:21:50,869 - mmdet - INFO - Epoch [23][550/2442]\tlr: 1.000e-04, eta: 6:09:10, time: 1.162, data_time: 0.006, memory: 17952, loss_cls: 0.3096, loss_bbox: 0.2207, loss_dfl: 0.1876, loss: 0.7180\n",
      "2022-04-07 02:22:48,793 - mmdet - INFO - Epoch [23][600/2442]\tlr: 1.000e-04, eta: 6:07:58, time: 1.158, data_time: 0.006, memory: 17952, loss_cls: 0.3071, loss_bbox: 0.2384, loss_dfl: 0.1950, loss: 0.7405\n",
      "2022-04-07 02:23:46,803 - mmdet - INFO - Epoch [23][650/2442]\tlr: 1.000e-04, eta: 6:06:52, time: 1.160, data_time: 0.006, memory: 17952, loss_cls: 0.3234, loss_bbox: 0.2562, loss_dfl: 0.2043, loss: 0.7839\n",
      "2022-04-07 02:24:44,868 - mmdet - INFO - Epoch [23][700/2442]\tlr: 1.000e-04, eta: 6:05:48, time: 1.161, data_time: 0.006, memory: 17952, loss_cls: 0.3298, loss_bbox: 0.2732, loss_dfl: 0.2104, loss: 0.8134\n",
      "2022-04-07 02:25:42,856 - mmdet - INFO - Epoch [23][750/2442]\tlr: 1.000e-04, eta: 6:04:42, time: 1.160, data_time: 0.006, memory: 17952, loss_cls: 0.3214, loss_bbox: 0.2420, loss_dfl: 0.1969, loss: 0.7603\n",
      "2022-04-07 02:26:40,821 - mmdet - INFO - Epoch [23][800/2442]\tlr: 1.000e-04, eta: 6:03:38, time: 1.159, data_time: 0.006, memory: 17952, loss_cls: 0.3578, loss_bbox: 0.2544, loss_dfl: 0.2008, loss: 0.8130\n",
      "2022-04-07 02:27:39,048 - mmdet - INFO - Epoch [23][850/2442]\tlr: 1.000e-04, eta: 6:02:39, time: 1.165, data_time: 0.006, memory: 17952, loss_cls: 0.3509, loss_bbox: 0.2608, loss_dfl: 0.2027, loss: 0.8144\n",
      "2022-04-07 02:28:37,178 - mmdet - INFO - Epoch [23][900/2442]\tlr: 1.000e-04, eta: 6:01:39, time: 1.163, data_time: 0.006, memory: 17952, loss_cls: 0.3428, loss_bbox: 0.2364, loss_dfl: 0.1974, loss: 0.7766\n",
      "2022-04-07 02:29:35,393 - mmdet - INFO - Epoch [23][950/2442]\tlr: 1.000e-04, eta: 6:00:41, time: 1.164, data_time: 0.006, memory: 17952, loss_cls: 0.2771, loss_bbox: 0.2417, loss_dfl: 0.1950, loss: 0.7138\n",
      "2022-04-07 02:30:33,503 - mmdet - INFO - Epoch [23][1000/2442]\tlr: 1.000e-04, eta: 5:59:41, time: 1.162, data_time: 0.006, memory: 17952, loss_cls: 0.2717, loss_bbox: 0.2427, loss_dfl: 0.1971, loss: 0.7116\n",
      "2022-04-07 02:31:31,564 - mmdet - INFO - Epoch [23][1050/2442]\tlr: 1.000e-04, eta: 5:58:40, time: 1.161, data_time: 0.006, memory: 17952, loss_cls: 0.3227, loss_bbox: 0.2714, loss_dfl: 0.2084, loss: 0.8025\n",
      "2022-04-07 02:32:29,535 - mmdet - INFO - Epoch [23][1100/2442]\tlr: 1.000e-04, eta: 5:57:38, time: 1.159, data_time: 0.006, memory: 17952, loss_cls: 0.2993, loss_bbox: 0.2520, loss_dfl: 0.2002, loss: 0.7514\n",
      "2022-04-07 02:33:27,556 - mmdet - INFO - Epoch [23][1150/2442]\tlr: 1.000e-04, eta: 5:56:37, time: 1.160, data_time: 0.006, memory: 17952, loss_cls: 0.3684, loss_bbox: 0.2820, loss_dfl: 0.2102, loss: 0.8606\n",
      "2022-04-07 02:34:25,576 - mmdet - INFO - Epoch [23][1200/2442]\tlr: 1.000e-04, eta: 5:55:36, time: 1.160, data_time: 0.006, memory: 17952, loss_cls: 0.3114, loss_bbox: 0.2461, loss_dfl: 0.2010, loss: 0.7586\n",
      "2022-04-07 02:35:23,536 - mmdet - INFO - Epoch [23][1250/2442]\tlr: 1.000e-04, eta: 5:54:34, time: 1.159, data_time: 0.006, memory: 17952, loss_cls: 0.2853, loss_bbox: 0.2372, loss_dfl: 0.1951, loss: 0.7175\n",
      "2022-04-07 02:36:21,936 - mmdet - INFO - Epoch [23][1300/2442]\tlr: 1.000e-04, eta: 5:53:39, time: 1.168, data_time: 0.006, memory: 17952, loss_cls: 0.3319, loss_bbox: 0.2659, loss_dfl: 0.2052, loss: 0.8030\n",
      "2022-04-07 02:37:20,018 - mmdet - INFO - Epoch [23][1350/2442]\tlr: 1.000e-04, eta: 5:52:40, time: 1.162, data_time: 0.006, memory: 17952, loss_cls: 0.2884, loss_bbox: 0.2673, loss_dfl: 0.2098, loss: 0.7655\n",
      "2022-04-07 02:38:17,990 - mmdet - INFO - Epoch [23][1400/2442]\tlr: 1.000e-04, eta: 5:51:39, time: 1.159, data_time: 0.006, memory: 17952, loss_cls: 0.3080, loss_bbox: 0.2409, loss_dfl: 0.1954, loss: 0.7442\n",
      "2022-04-07 02:39:16,042 - mmdet - INFO - Epoch [23][1450/2442]\tlr: 1.000e-04, eta: 5:50:39, time: 1.161, data_time: 0.006, memory: 17952, loss_cls: 0.3113, loss_bbox: 0.2543, loss_dfl: 0.2021, loss: 0.7677\n",
      "2022-04-07 02:40:14,014 - mmdet - INFO - Epoch [23][1500/2442]\tlr: 1.000e-04, eta: 5:49:39, time: 1.159, data_time: 0.006, memory: 17952, loss_cls: 0.3260, loss_bbox: 0.2663, loss_dfl: 0.2112, loss: 0.8036\n",
      "2022-04-07 02:41:12,105 - mmdet - INFO - Epoch [23][1550/2442]\tlr: 1.000e-04, eta: 5:48:40, time: 1.162, data_time: 0.006, memory: 17952, loss_cls: 0.3312, loss_bbox: 0.2781, loss_dfl: 0.2124, loss: 0.8217\n",
      "2022-04-07 02:42:10,152 - mmdet - INFO - Epoch [23][1600/2442]\tlr: 1.000e-04, eta: 5:47:40, time: 1.161, data_time: 0.006, memory: 17952, loss_cls: 0.3444, loss_bbox: 0.2633, loss_dfl: 0.2027, loss: 0.8104\n",
      "2022-04-07 02:43:08,139 - mmdet - INFO - Epoch [23][1650/2442]\tlr: 1.000e-04, eta: 5:46:41, time: 1.160, data_time: 0.006, memory: 17952, loss_cls: 0.3003, loss_bbox: 0.2403, loss_dfl: 0.1975, loss: 0.7381\n",
      "2022-04-07 02:44:06,466 - mmdet - INFO - Epoch [23][1700/2442]\tlr: 1.000e-04, eta: 5:45:44, time: 1.167, data_time: 0.007, memory: 17952, loss_cls: 0.3702, loss_bbox: 0.2906, loss_dfl: 0.2191, loss: 0.8799\n",
      "2022-04-07 02:45:04,487 - mmdet - INFO - Epoch [23][1750/2442]\tlr: 1.000e-04, eta: 5:44:45, time: 1.160, data_time: 0.006, memory: 17952, loss_cls: 0.2910, loss_bbox: 0.2394, loss_dfl: 0.1996, loss: 0.7299\n",
      "2022-04-07 02:46:02,617 - mmdet - INFO - Epoch [23][1800/2442]\tlr: 1.000e-04, eta: 5:43:46, time: 1.163, data_time: 0.006, memory: 17952, loss_cls: 0.3404, loss_bbox: 0.2656, loss_dfl: 0.2061, loss: 0.8120\n",
      "2022-04-07 02:47:00,655 - mmdet - INFO - Epoch [23][1850/2442]\tlr: 1.000e-04, eta: 5:42:47, time: 1.161, data_time: 0.006, memory: 17952, loss_cls: 0.3226, loss_bbox: 0.2455, loss_dfl: 0.1966, loss: 0.7648\n",
      "2022-04-07 02:47:58,664 - mmdet - INFO - Epoch [23][1900/2442]\tlr: 1.000e-04, eta: 5:41:48, time: 1.160, data_time: 0.006, memory: 17952, loss_cls: 0.2708, loss_bbox: 0.2557, loss_dfl: 0.2003, loss: 0.7268\n",
      "2022-04-07 02:48:56,736 - mmdet - INFO - Epoch [23][1950/2442]\tlr: 1.000e-04, eta: 5:40:49, time: 1.161, data_time: 0.006, memory: 17952, loss_cls: 0.3253, loss_bbox: 0.2732, loss_dfl: 0.2087, loss: 0.8072\n",
      "2022-04-07 02:49:54,703 - mmdet - INFO - Epoch [23][2000/2442]\tlr: 1.000e-04, eta: 5:39:49, time: 1.159, data_time: 0.006, memory: 17952, loss_cls: 0.2841, loss_bbox: 0.2805, loss_dfl: 0.2131, loss: 0.7777\n",
      "2022-04-07 02:50:52,742 - mmdet - INFO - Epoch [23][2050/2442]\tlr: 1.000e-04, eta: 5:38:50, time: 1.161, data_time: 0.006, memory: 17952, loss_cls: 0.2915, loss_bbox: 0.2798, loss_dfl: 0.2105, loss: 0.7819\n",
      "2022-04-07 02:51:50,681 - mmdet - INFO - Epoch [23][2100/2442]\tlr: 1.000e-04, eta: 5:37:51, time: 1.159, data_time: 0.006, memory: 17952, loss_cls: 0.3072, loss_bbox: 0.2756, loss_dfl: 0.2099, loss: 0.7926\n",
      "2022-04-07 02:52:48,765 - mmdet - INFO - Epoch [23][2150/2442]\tlr: 1.000e-04, eta: 5:36:52, time: 1.162, data_time: 0.006, memory: 17952, loss_cls: 0.3567, loss_bbox: 0.2865, loss_dfl: 0.2150, loss: 0.8583\n",
      "2022-04-07 02:53:46,807 - mmdet - INFO - Epoch [23][2200/2442]\tlr: 1.000e-04, eta: 5:35:53, time: 1.161, data_time: 0.006, memory: 17952, loss_cls: 0.3152, loss_bbox: 0.2625, loss_dfl: 0.2093, loss: 0.7869\n",
      "2022-04-07 02:54:44,812 - mmdet - INFO - Epoch [23][2250/2442]\tlr: 1.000e-04, eta: 5:34:54, time: 1.160, data_time: 0.006, memory: 17952, loss_cls: 0.3517, loss_bbox: 0.2796, loss_dfl: 0.2147, loss: 0.8460\n",
      "2022-04-07 02:55:42,894 - mmdet - INFO - Epoch [23][2300/2442]\tlr: 1.000e-04, eta: 5:33:56, time: 1.162, data_time: 0.006, memory: 17952, loss_cls: 0.3331, loss_bbox: 0.2923, loss_dfl: 0.2176, loss: 0.8430\n",
      "2022-04-07 02:56:40,779 - mmdet - INFO - Epoch [23][2350/2442]\tlr: 1.000e-04, eta: 5:32:56, time: 1.158, data_time: 0.006, memory: 17952, loss_cls: 0.3261, loss_bbox: 0.2911, loss_dfl: 0.2118, loss: 0.8290\n",
      "2022-04-07 02:57:38,841 - mmdet - INFO - Epoch [23][2400/2442]\tlr: 1.000e-04, eta: 5:31:57, time: 1.161, data_time: 0.006, memory: 17952, loss_cls: 0.3156, loss_bbox: 0.2436, loss_dfl: 0.2005, loss: 0.7597\n",
      "2022-04-07 02:58:27,701 - mmdet - INFO - Saving checkpoint at 23 epochs\n",
      "2022-04-07 02:59:35,438 - mmdet - INFO - Epoch [24][50/2442]\tlr: 1.000e-04, eta: 5:24:56, time: 1.219, data_time: 0.058, memory: 17952, loss_cls: 0.2730, loss_bbox: 0.2356, loss_dfl: 0.1889, loss: 0.6975\n",
      "2022-04-07 03:00:33,503 - mmdet - INFO - Epoch [24][100/2442]\tlr: 1.000e-04, eta: 5:24:04, time: 1.161, data_time: 0.007, memory: 17952, loss_cls: 0.3072, loss_bbox: 0.2696, loss_dfl: 0.2081, loss: 0.7850\n",
      "2022-04-07 03:01:31,550 - mmdet - INFO - Epoch [24][150/2442]\tlr: 1.000e-04, eta: 5:23:13, time: 1.161, data_time: 0.006, memory: 17952, loss_cls: 0.2616, loss_bbox: 0.2379, loss_dfl: 0.1969, loss: 0.6965\n",
      "2022-04-07 03:02:29,677 - mmdet - INFO - Epoch [24][200/2442]\tlr: 1.000e-04, eta: 5:22:21, time: 1.163, data_time: 0.007, memory: 17952, loss_cls: 0.3471, loss_bbox: 0.2572, loss_dfl: 0.2042, loss: 0.8086\n",
      "2022-04-07 03:03:27,663 - mmdet - INFO - Epoch [24][250/2442]\tlr: 1.000e-04, eta: 5:21:29, time: 1.160, data_time: 0.006, memory: 17952, loss_cls: 0.3109, loss_bbox: 0.2624, loss_dfl: 0.2036, loss: 0.7770\n",
      "2022-04-07 03:04:25,802 - mmdet - INFO - Epoch [24][300/2442]\tlr: 1.000e-04, eta: 5:20:37, time: 1.163, data_time: 0.006, memory: 17952, loss_cls: 0.3183, loss_bbox: 0.2423, loss_dfl: 0.1958, loss: 0.7564\n",
      "2022-04-07 03:05:24,042 - mmdet - INFO - Epoch [24][350/2442]\tlr: 1.000e-04, eta: 5:19:45, time: 1.165, data_time: 0.006, memory: 17952, loss_cls: 0.3199, loss_bbox: 0.2917, loss_dfl: 0.2154, loss: 0.8271\n",
      "2022-04-07 03:06:22,008 - mmdet - INFO - Epoch [24][400/2442]\tlr: 1.000e-04, eta: 5:18:52, time: 1.159, data_time: 0.006, memory: 17952, loss_cls: 0.3116, loss_bbox: 0.2464, loss_dfl: 0.1989, loss: 0.7569\n",
      "2022-04-07 03:07:20,130 - mmdet - INFO - Epoch [24][450/2442]\tlr: 1.000e-04, eta: 5:17:59, time: 1.162, data_time: 0.006, memory: 17952, loss_cls: 0.3359, loss_bbox: 0.2879, loss_dfl: 0.2141, loss: 0.8379\n",
      "2022-04-07 03:08:18,121 - mmdet - INFO - Epoch [24][500/2442]\tlr: 1.000e-04, eta: 5:17:06, time: 1.160, data_time: 0.006, memory: 17952, loss_cls: 0.2488, loss_bbox: 0.2630, loss_dfl: 0.2061, loss: 0.7179\n",
      "2022-04-07 03:09:16,169 - mmdet - INFO - Epoch [24][550/2442]\tlr: 1.000e-04, eta: 5:16:12, time: 1.161, data_time: 0.006, memory: 17952, loss_cls: 0.2527, loss_bbox: 0.2413, loss_dfl: 0.1951, loss: 0.6891\n",
      "2022-04-07 03:10:14,221 - mmdet - INFO - Epoch [24][600/2442]\tlr: 1.000e-04, eta: 5:15:19, time: 1.161, data_time: 0.007, memory: 17952, loss_cls: 0.2955, loss_bbox: 0.2457, loss_dfl: 0.1988, loss: 0.7401\n",
      "2022-04-07 03:11:12,230 - mmdet - INFO - Epoch [24][650/2442]\tlr: 1.000e-04, eta: 5:14:25, time: 1.160, data_time: 0.006, memory: 17952, loss_cls: 0.4322, loss_bbox: 0.2754, loss_dfl: 0.2109, loss: 0.9186\n",
      "2022-04-07 03:12:10,225 - mmdet - INFO - Epoch [24][700/2442]\tlr: 1.000e-04, eta: 5:13:31, time: 1.160, data_time: 0.006, memory: 17952, loss_cls: 0.3602, loss_bbox: 0.2684, loss_dfl: 0.2100, loss: 0.8386\n",
      "2022-04-07 03:13:08,159 - mmdet - INFO - Epoch [24][750/2442]\tlr: 1.000e-04, eta: 5:12:37, time: 1.159, data_time: 0.006, memory: 17952, loss_cls: 0.3127, loss_bbox: 0.2253, loss_dfl: 0.1902, loss: 0.7282\n",
      "2022-04-07 03:14:06,298 - mmdet - INFO - Epoch [24][800/2442]\tlr: 1.000e-04, eta: 5:11:43, time: 1.163, data_time: 0.006, memory: 17952, loss_cls: 0.3835, loss_bbox: 0.2803, loss_dfl: 0.2123, loss: 0.8761\n",
      "2022-04-07 03:15:04,400 - mmdet - INFO - Epoch [24][850/2442]\tlr: 1.000e-04, eta: 5:10:49, time: 1.162, data_time: 0.006, memory: 17952, loss_cls: 0.3114, loss_bbox: 0.3000, loss_dfl: 0.2149, loss: 0.8263\n",
      "2022-04-07 03:16:02,325 - mmdet - INFO - Epoch [24][900/2442]\tlr: 1.000e-04, eta: 5:09:54, time: 1.158, data_time: 0.007, memory: 17952, loss_cls: 0.3023, loss_bbox: 0.2518, loss_dfl: 0.2031, loss: 0.7572\n",
      "2022-04-07 03:17:00,564 - mmdet - INFO - Epoch [24][950/2442]\tlr: 1.000e-04, eta: 5:09:01, time: 1.165, data_time: 0.007, memory: 17952, loss_cls: 0.3730, loss_bbox: 0.3027, loss_dfl: 0.2250, loss: 0.9008\n",
      "2022-04-07 03:17:58,641 - mmdet - INFO - Epoch [24][1000/2442]\tlr: 1.000e-04, eta: 5:08:06, time: 1.162, data_time: 0.006, memory: 17952, loss_cls: 0.3098, loss_bbox: 0.2507, loss_dfl: 0.2010, loss: 0.7615\n",
      "2022-04-07 03:18:56,753 - mmdet - INFO - Epoch [24][1050/2442]\tlr: 1.000e-04, eta: 5:07:12, time: 1.162, data_time: 0.006, memory: 17952, loss_cls: 0.3547, loss_bbox: 0.2769, loss_dfl: 0.2103, loss: 0.8418\n",
      "2022-04-07 03:19:54,782 - mmdet - INFO - Epoch [24][1100/2442]\tlr: 1.000e-04, eta: 5:06:17, time: 1.161, data_time: 0.006, memory: 17952, loss_cls: 0.3169, loss_bbox: 0.2886, loss_dfl: 0.2105, loss: 0.8161\n",
      "2022-04-07 03:20:52,818 - mmdet - INFO - Epoch [24][1150/2442]\tlr: 1.000e-04, eta: 5:05:22, time: 1.161, data_time: 0.006, memory: 17952, loss_cls: 0.3138, loss_bbox: 0.2753, loss_dfl: 0.2097, loss: 0.7988\n",
      "2022-04-07 03:21:50,837 - mmdet - INFO - Epoch [24][1200/2442]\tlr: 1.000e-04, eta: 5:04:27, time: 1.160, data_time: 0.006, memory: 17952, loss_cls: 0.2851, loss_bbox: 0.2624, loss_dfl: 0.2054, loss: 0.7528\n",
      "2022-04-07 03:22:48,811 - mmdet - INFO - Epoch [24][1250/2442]\tlr: 1.000e-04, eta: 5:03:32, time: 1.159, data_time: 0.006, memory: 17952, loss_cls: 0.2889, loss_bbox: 0.2531, loss_dfl: 0.1993, loss: 0.7412\n",
      "2022-04-07 03:23:46,892 - mmdet - INFO - Epoch [24][1300/2442]\tlr: 1.000e-04, eta: 5:02:37, time: 1.162, data_time: 0.006, memory: 17952, loss_cls: 0.3223, loss_bbox: 0.2804, loss_dfl: 0.2110, loss: 0.8137\n",
      "2022-04-07 03:24:44,829 - mmdet - INFO - Epoch [24][1350/2442]\tlr: 1.000e-04, eta: 5:01:41, time: 1.159, data_time: 0.006, memory: 17952, loss_cls: 0.3186, loss_bbox: 0.2643, loss_dfl: 0.2045, loss: 0.7873\n",
      "2022-04-07 03:25:42,939 - mmdet - INFO - Epoch [24][1400/2442]\tlr: 1.000e-04, eta: 5:00:47, time: 1.162, data_time: 0.006, memory: 17952, loss_cls: 0.2977, loss_bbox: 0.2420, loss_dfl: 0.1992, loss: 0.7389\n",
      "2022-04-07 03:26:41,038 - mmdet - INFO - Epoch [24][1450/2442]\tlr: 1.000e-04, eta: 4:59:51, time: 1.162, data_time: 0.006, memory: 17952, loss_cls: 0.3349, loss_bbox: 0.2939, loss_dfl: 0.2207, loss: 0.8495\n",
      "2022-04-07 03:27:39,528 - mmdet - INFO - Epoch [24][1500/2442]\tlr: 1.000e-04, eta: 4:58:58, time: 1.170, data_time: 0.006, memory: 17952, loss_cls: 0.3824, loss_bbox: 0.2764, loss_dfl: 0.2114, loss: 0.8702\n",
      "2022-04-07 03:28:37,799 - mmdet - INFO - Epoch [24][1550/2442]\tlr: 1.000e-04, eta: 4:58:03, time: 1.165, data_time: 0.007, memory: 17952, loss_cls: 0.3198, loss_bbox: 0.2521, loss_dfl: 0.2015, loss: 0.7734\n",
      "2022-04-07 03:29:35,892 - mmdet - INFO - Epoch [24][1600/2442]\tlr: 1.000e-04, eta: 4:57:08, time: 1.162, data_time: 0.006, memory: 17952, loss_cls: 0.3520, loss_bbox: 0.2576, loss_dfl: 0.2030, loss: 0.8126\n",
      "2022-04-07 03:30:34,011 - mmdet - INFO - Epoch [24][1650/2442]\tlr: 1.000e-04, eta: 4:56:13, time: 1.162, data_time: 0.007, memory: 17952, loss_cls: 0.3170, loss_bbox: 0.2972, loss_dfl: 0.2198, loss: 0.8341\n",
      "2022-04-07 03:31:31,954 - mmdet - INFO - Epoch [24][1700/2442]\tlr: 1.000e-04, eta: 4:55:17, time: 1.159, data_time: 0.006, memory: 17952, loss_cls: 0.3472, loss_bbox: 0.2435, loss_dfl: 0.2017, loss: 0.7924\n",
      "2022-04-07 03:32:30,630 - mmdet - INFO - Epoch [24][1750/2442]\tlr: 1.000e-04, eta: 4:54:23, time: 1.174, data_time: 0.006, memory: 17952, loss_cls: 0.4122, loss_bbox: 0.2919, loss_dfl: 0.2166, loss: 0.9207\n",
      "2022-04-07 03:33:28,645 - mmdet - INFO - Epoch [24][1800/2442]\tlr: 1.000e-04, eta: 4:53:27, time: 1.160, data_time: 0.006, memory: 17952, loss_cls: 0.3142, loss_bbox: 0.2854, loss_dfl: 0.2135, loss: 0.8131\n",
      "2022-04-07 03:34:26,702 - mmdet - INFO - Epoch [24][1850/2442]\tlr: 1.000e-04, eta: 4:52:31, time: 1.161, data_time: 0.006, memory: 17952, loss_cls: 0.2883, loss_bbox: 0.2713, loss_dfl: 0.2095, loss: 0.7691\n",
      "2022-04-07 03:35:24,713 - mmdet - INFO - Epoch [24][1900/2442]\tlr: 1.000e-04, eta: 4:51:35, time: 1.160, data_time: 0.007, memory: 17952, loss_cls: 0.2747, loss_bbox: 0.2360, loss_dfl: 0.1938, loss: 0.7045\n",
      "2022-04-07 03:36:22,785 - mmdet - INFO - Epoch [24][1950/2442]\tlr: 1.000e-04, eta: 4:50:39, time: 1.161, data_time: 0.007, memory: 17952, loss_cls: 0.3329, loss_bbox: 0.2524, loss_dfl: 0.1967, loss: 0.7821\n",
      "2022-04-07 03:37:20,709 - mmdet - INFO - Epoch [24][2000/2442]\tlr: 1.000e-04, eta: 4:49:43, time: 1.158, data_time: 0.006, memory: 17952, loss_cls: 0.3169, loss_bbox: 0.2521, loss_dfl: 0.2000, loss: 0.7690\n",
      "2022-04-07 03:38:18,540 - mmdet - INFO - Epoch [24][2050/2442]\tlr: 1.000e-04, eta: 4:48:46, time: 1.157, data_time: 0.007, memory: 17952, loss_cls: 0.3050, loss_bbox: 0.2414, loss_dfl: 0.1964, loss: 0.7427\n",
      "2022-04-07 03:39:16,429 - mmdet - INFO - Epoch [24][2100/2442]\tlr: 1.000e-04, eta: 4:47:50, time: 1.158, data_time: 0.007, memory: 17952, loss_cls: 0.3007, loss_bbox: 0.2824, loss_dfl: 0.2110, loss: 0.7941\n",
      "2022-04-07 03:40:14,356 - mmdet - INFO - Epoch [24][2150/2442]\tlr: 1.000e-04, eta: 4:46:53, time: 1.159, data_time: 0.006, memory: 17952, loss_cls: 0.2916, loss_bbox: 0.2562, loss_dfl: 0.2029, loss: 0.7507\n",
      "2022-04-07 03:41:12,359 - mmdet - INFO - Epoch [24][2200/2442]\tlr: 1.000e-04, eta: 4:45:57, time: 1.160, data_time: 0.007, memory: 17952, loss_cls: 0.2916, loss_bbox: 0.2540, loss_dfl: 0.2002, loss: 0.7457\n",
      "2022-04-07 03:42:10,396 - mmdet - INFO - Epoch [24][2250/2442]\tlr: 1.000e-04, eta: 4:45:01, time: 1.161, data_time: 0.006, memory: 17952, loss_cls: 0.3009, loss_bbox: 0.2342, loss_dfl: 0.1957, loss: 0.7309\n",
      "2022-04-07 03:43:08,724 - mmdet - INFO - Epoch [24][2300/2442]\tlr: 1.000e-04, eta: 4:44:05, time: 1.167, data_time: 0.007, memory: 17952, loss_cls: 0.3078, loss_bbox: 0.2447, loss_dfl: 0.1958, loss: 0.7483\n",
      "2022-04-07 03:44:06,726 - mmdet - INFO - Epoch [24][2350/2442]\tlr: 1.000e-04, eta: 4:43:09, time: 1.160, data_time: 0.006, memory: 17952, loss_cls: 0.3176, loss_bbox: 0.2543, loss_dfl: 0.1995, loss: 0.7714\n",
      "2022-04-07 03:45:04,886 - mmdet - INFO - Epoch [24][2400/2442]\tlr: 1.000e-04, eta: 4:42:13, time: 1.163, data_time: 0.006, memory: 17952, loss_cls: 0.2828, loss_bbox: 0.2644, loss_dfl: 0.2092, loss: 0.7565\n",
      "2022-04-07 03:45:53,692 - mmdet - INFO - Saving checkpoint at 24 epochs\n",
      "2022-04-07 03:47:01,801 - mmdet - INFO - Epoch [25][50/2442]\tlr: 1.000e-04, eta: 4:38:15, time: 1.227, data_time: 0.058, memory: 17952, loss_cls: 0.2862, loss_bbox: 0.2623, loss_dfl: 0.2031, loss: 0.7516\n",
      "2022-04-07 03:47:59,742 - mmdet - INFO - Epoch [25][100/2442]\tlr: 1.000e-04, eta: 4:37:20, time: 1.159, data_time: 0.006, memory: 17952, loss_cls: 0.2728, loss_bbox: 0.2491, loss_dfl: 0.1976, loss: 0.7195\n",
      "2022-04-07 03:48:57,747 - mmdet - INFO - Epoch [25][150/2442]\tlr: 1.000e-04, eta: 4:36:25, time: 1.160, data_time: 0.006, memory: 17952, loss_cls: 0.2907, loss_bbox: 0.2392, loss_dfl: 0.1951, loss: 0.7249\n",
      "2022-04-07 03:49:55,718 - mmdet - INFO - Epoch [25][200/2442]\tlr: 1.000e-04, eta: 4:35:30, time: 1.159, data_time: 0.007, memory: 17952, loss_cls: 0.2492, loss_bbox: 0.2683, loss_dfl: 0.2085, loss: 0.7260\n",
      "2022-04-07 03:50:53,626 - mmdet - INFO - Epoch [25][250/2442]\tlr: 1.000e-04, eta: 4:34:35, time: 1.158, data_time: 0.006, memory: 17952, loss_cls: 0.2860, loss_bbox: 0.2469, loss_dfl: 0.1995, loss: 0.7324\n",
      "2022-04-07 03:51:51,490 - mmdet - INFO - Epoch [25][300/2442]\tlr: 1.000e-04, eta: 4:33:40, time: 1.157, data_time: 0.007, memory: 17952, loss_cls: 0.3117, loss_bbox: 0.2615, loss_dfl: 0.2050, loss: 0.7781\n",
      "2022-04-07 03:52:49,465 - mmdet - INFO - Epoch [25][350/2442]\tlr: 1.000e-04, eta: 4:32:45, time: 1.159, data_time: 0.006, memory: 17952, loss_cls: 0.2809, loss_bbox: 0.2394, loss_dfl: 0.1946, loss: 0.7150\n",
      "2022-04-07 03:53:47,404 - mmdet - INFO - Epoch [25][400/2442]\tlr: 1.000e-04, eta: 4:31:49, time: 1.159, data_time: 0.006, memory: 17952, loss_cls: 0.2430, loss_bbox: 0.2493, loss_dfl: 0.1975, loss: 0.6898\n",
      "2022-04-07 03:54:45,534 - mmdet - INFO - Epoch [25][450/2442]\tlr: 1.000e-04, eta: 4:30:54, time: 1.163, data_time: 0.006, memory: 17952, loss_cls: 0.2723, loss_bbox: 0.2497, loss_dfl: 0.1974, loss: 0.7194\n",
      "2022-04-07 03:55:43,579 - mmdet - INFO - Epoch [25][500/2442]\tlr: 1.000e-04, eta: 4:29:59, time: 1.161, data_time: 0.007, memory: 17952, loss_cls: 0.3567, loss_bbox: 0.2297, loss_dfl: 0.1914, loss: 0.7779\n",
      "2022-04-07 03:56:41,912 - mmdet - INFO - Epoch [25][550/2442]\tlr: 1.000e-04, eta: 4:29:05, time: 1.167, data_time: 0.007, memory: 17952, loss_cls: 0.3881, loss_bbox: 0.2783, loss_dfl: 0.2135, loss: 0.8799\n",
      "2022-04-07 03:57:39,931 - mmdet - INFO - Epoch [25][600/2442]\tlr: 1.000e-04, eta: 4:28:10, time: 1.160, data_time: 0.006, memory: 17952, loss_cls: 0.3123, loss_bbox: 0.2478, loss_dfl: 0.2020, loss: 0.7620\n",
      "2022-04-07 03:58:38,195 - mmdet - INFO - Epoch [25][650/2442]\tlr: 1.000e-04, eta: 4:27:15, time: 1.165, data_time: 0.006, memory: 17952, loss_cls: 0.3027, loss_bbox: 0.2664, loss_dfl: 0.2071, loss: 0.7762\n",
      "2022-04-07 03:59:36,296 - mmdet - INFO - Epoch [25][700/2442]\tlr: 1.000e-04, eta: 4:26:20, time: 1.162, data_time: 0.006, memory: 17952, loss_cls: 0.2892, loss_bbox: 0.2739, loss_dfl: 0.2101, loss: 0.7732\n",
      "2022-04-07 04:00:34,427 - mmdet - INFO - Epoch [25][750/2442]\tlr: 1.000e-04, eta: 4:25:25, time: 1.163, data_time: 0.006, memory: 17952, loss_cls: 0.2936, loss_bbox: 0.2585, loss_dfl: 0.2015, loss: 0.7537\n",
      "2022-04-07 04:01:32,434 - mmdet - INFO - Epoch [25][800/2442]\tlr: 1.000e-04, eta: 4:24:29, time: 1.160, data_time: 0.006, memory: 17952, loss_cls: 0.2895, loss_bbox: 0.2551, loss_dfl: 0.2022, loss: 0.7468\n",
      "2022-04-07 04:02:30,589 - mmdet - INFO - Epoch [25][850/2442]\tlr: 1.000e-04, eta: 4:23:34, time: 1.163, data_time: 0.006, memory: 17952, loss_cls: 0.3015, loss_bbox: 0.3093, loss_dfl: 0.2251, loss: 0.8359\n",
      "2022-04-07 04:03:28,584 - mmdet - INFO - Epoch [25][900/2442]\tlr: 1.000e-04, eta: 4:22:38, time: 1.160, data_time: 0.006, memory: 17952, loss_cls: 0.3012, loss_bbox: 0.2709, loss_dfl: 0.2084, loss: 0.7805\n",
      "2022-04-07 04:04:26,767 - mmdet - INFO - Epoch [25][950/2442]\tlr: 1.000e-04, eta: 4:21:43, time: 1.164, data_time: 0.007, memory: 17952, loss_cls: 0.2945, loss_bbox: 0.2607, loss_dfl: 0.2034, loss: 0.7586\n",
      "2022-04-07 04:05:24,786 - mmdet - INFO - Epoch [25][1000/2442]\tlr: 1.000e-04, eta: 4:20:48, time: 1.160, data_time: 0.006, memory: 17952, loss_cls: 0.2595, loss_bbox: 0.2410, loss_dfl: 0.1990, loss: 0.6995\n",
      "2022-04-07 04:06:22,939 - mmdet - INFO - Epoch [25][1050/2442]\tlr: 1.000e-04, eta: 4:19:52, time: 1.163, data_time: 0.006, memory: 17952, loss_cls: 0.3364, loss_bbox: 0.2579, loss_dfl: 0.2048, loss: 0.7991\n",
      "2022-04-07 04:07:21,122 - mmdet - INFO - Epoch [25][1100/2442]\tlr: 1.000e-04, eta: 4:18:57, time: 1.164, data_time: 0.006, memory: 17952, loss_cls: 0.2719, loss_bbox: 0.2310, loss_dfl: 0.1912, loss: 0.6941\n",
      "2022-04-07 04:08:19,255 - mmdet - INFO - Epoch [25][1150/2442]\tlr: 1.000e-04, eta: 4:18:01, time: 1.163, data_time: 0.007, memory: 17952, loss_cls: 0.2660, loss_bbox: 0.2646, loss_dfl: 0.2050, loss: 0.7356\n",
      "2022-04-07 04:09:17,220 - mmdet - INFO - Epoch [25][1200/2442]\tlr: 1.000e-04, eta: 4:17:05, time: 1.159, data_time: 0.007, memory: 17952, loss_cls: 0.2772, loss_bbox: 0.2748, loss_dfl: 0.2064, loss: 0.7583\n",
      "2022-04-07 04:10:15,352 - mmdet - INFO - Epoch [25][1250/2442]\tlr: 1.000e-04, eta: 4:16:10, time: 1.163, data_time: 0.006, memory: 17952, loss_cls: 0.2883, loss_bbox: 0.2630, loss_dfl: 0.2037, loss: 0.7549\n",
      "2022-04-07 04:11:13,522 - mmdet - INFO - Epoch [25][1300/2442]\tlr: 1.000e-04, eta: 4:15:14, time: 1.163, data_time: 0.006, memory: 17952, loss_cls: 0.2867, loss_bbox: 0.2503, loss_dfl: 0.2024, loss: 0.7393\n",
      "2022-04-07 04:12:11,480 - mmdet - INFO - Epoch [25][1350/2442]\tlr: 1.000e-04, eta: 4:14:18, time: 1.159, data_time: 0.006, memory: 17952, loss_cls: 0.2918, loss_bbox: 0.2439, loss_dfl: 0.1969, loss: 0.7326\n",
      "2022-04-07 04:13:09,546 - mmdet - INFO - Epoch [25][1400/2442]\tlr: 1.000e-04, eta: 4:13:22, time: 1.161, data_time: 0.006, memory: 17952, loss_cls: 0.3119, loss_bbox: 0.2888, loss_dfl: 0.2149, loss: 0.8157\n",
      "2022-04-07 04:14:07,547 - mmdet - INFO - Epoch [25][1450/2442]\tlr: 1.000e-04, eta: 4:12:26, time: 1.160, data_time: 0.007, memory: 17952, loss_cls: 0.3522, loss_bbox: 0.2661, loss_dfl: 0.2090, loss: 0.8274\n",
      "2022-04-07 04:15:05,812 - mmdet - INFO - Epoch [25][1500/2442]\tlr: 1.000e-04, eta: 4:11:31, time: 1.165, data_time: 0.007, memory: 17952, loss_cls: 0.3191, loss_bbox: 0.2385, loss_dfl: 0.1951, loss: 0.7527\n",
      "2022-04-07 04:16:04,090 - mmdet - INFO - Epoch [25][1550/2442]\tlr: 1.000e-04, eta: 4:10:35, time: 1.166, data_time: 0.007, memory: 17952, loss_cls: 0.2795, loss_bbox: 0.2789, loss_dfl: 0.2122, loss: 0.7706\n",
      "2022-04-07 04:17:02,312 - mmdet - INFO - Epoch [25][1600/2442]\tlr: 1.000e-04, eta: 4:09:40, time: 1.164, data_time: 0.006, memory: 17952, loss_cls: 0.2896, loss_bbox: 0.2492, loss_dfl: 0.2014, loss: 0.7402\n",
      "2022-04-07 04:18:00,330 - mmdet - INFO - Epoch [25][1650/2442]\tlr: 1.000e-04, eta: 4:08:43, time: 1.160, data_time: 0.006, memory: 17952, loss_cls: 0.2828, loss_bbox: 0.2499, loss_dfl: 0.1998, loss: 0.7325\n",
      "2022-04-07 04:18:58,360 - mmdet - INFO - Epoch [25][1700/2442]\tlr: 1.000e-04, eta: 4:07:47, time: 1.161, data_time: 0.006, memory: 17952, loss_cls: 0.3001, loss_bbox: 0.2693, loss_dfl: 0.2043, loss: 0.7737\n",
      "2022-04-07 04:19:56,394 - mmdet - INFO - Epoch [25][1750/2442]\tlr: 1.000e-04, eta: 4:06:51, time: 1.161, data_time: 0.006, memory: 17952, loss_cls: 0.3259, loss_bbox: 0.2611, loss_dfl: 0.2080, loss: 0.7951\n",
      "2022-04-07 04:20:54,655 - mmdet - INFO - Epoch [25][1800/2442]\tlr: 1.000e-04, eta: 4:05:55, time: 1.165, data_time: 0.007, memory: 17952, loss_cls: 0.3368, loss_bbox: 0.2600, loss_dfl: 0.2045, loss: 0.8013\n",
      "2022-04-07 04:21:52,585 - mmdet - INFO - Epoch [25][1850/2442]\tlr: 1.000e-04, eta: 4:04:59, time: 1.159, data_time: 0.006, memory: 17952, loss_cls: 0.3303, loss_bbox: 0.2517, loss_dfl: 0.2040, loss: 0.7860\n",
      "2022-04-07 04:22:50,413 - mmdet - INFO - Epoch [25][1900/2442]\tlr: 1.000e-04, eta: 4:04:02, time: 1.157, data_time: 0.006, memory: 17952, loss_cls: 0.2809, loss_bbox: 0.2153, loss_dfl: 0.1817, loss: 0.6779\n",
      "2022-04-07 04:23:48,436 - mmdet - INFO - Epoch [25][1950/2442]\tlr: 1.000e-04, eta: 4:03:06, time: 1.160, data_time: 0.007, memory: 17952, loss_cls: 0.3090, loss_bbox: 0.2514, loss_dfl: 0.1985, loss: 0.7588\n",
      "2022-04-07 04:24:46,466 - mmdet - INFO - Epoch [25][2000/2442]\tlr: 1.000e-04, eta: 4:02:10, time: 1.161, data_time: 0.006, memory: 17952, loss_cls: 0.3407, loss_bbox: 0.3038, loss_dfl: 0.2262, loss: 0.8707\n",
      "2022-04-07 04:25:44,410 - mmdet - INFO - Epoch [25][2050/2442]\tlr: 1.000e-04, eta: 4:01:13, time: 1.159, data_time: 0.007, memory: 17952, loss_cls: 0.3504, loss_bbox: 0.2722, loss_dfl: 0.2089, loss: 0.8316\n",
      "2022-04-07 04:26:42,424 - mmdet - INFO - Epoch [25][2100/2442]\tlr: 1.000e-04, eta: 4:00:17, time: 1.160, data_time: 0.007, memory: 17952, loss_cls: 0.3455, loss_bbox: 0.2426, loss_dfl: 0.1983, loss: 0.7863\n",
      "2022-04-07 04:27:40,442 - mmdet - INFO - Epoch [25][2150/2442]\tlr: 1.000e-04, eta: 3:59:21, time: 1.160, data_time: 0.007, memory: 17952, loss_cls: 0.3525, loss_bbox: 0.2667, loss_dfl: 0.2046, loss: 0.8238\n",
      "2022-04-07 04:28:38,690 - mmdet - INFO - Epoch [25][2200/2442]\tlr: 1.000e-04, eta: 3:58:25, time: 1.165, data_time: 0.007, memory: 17952, loss_cls: 0.3339, loss_bbox: 0.2845, loss_dfl: 0.2162, loss: 0.8347\n",
      "2022-04-07 04:29:36,720 - mmdet - INFO - Epoch [25][2250/2442]\tlr: 1.000e-04, eta: 3:57:28, time: 1.161, data_time: 0.007, memory: 17952, loss_cls: 0.2896, loss_bbox: 0.2595, loss_dfl: 0.2040, loss: 0.7531\n",
      "2022-04-07 04:30:34,764 - mmdet - INFO - Epoch [25][2300/2442]\tlr: 1.000e-04, eta: 3:56:32, time: 1.161, data_time: 0.007, memory: 17952, loss_cls: 0.3056, loss_bbox: 0.2614, loss_dfl: 0.2058, loss: 0.7729\n",
      "2022-04-07 04:31:32,716 - mmdet - INFO - Epoch [25][2350/2442]\tlr: 1.000e-04, eta: 3:55:35, time: 1.159, data_time: 0.006, memory: 17952, loss_cls: 0.2914, loss_bbox: 0.2246, loss_dfl: 0.1898, loss: 0.7058\n",
      "2022-04-07 04:32:30,706 - mmdet - INFO - Epoch [25][2400/2442]\tlr: 1.000e-04, eta: 3:54:39, time: 1.160, data_time: 0.007, memory: 17952, loss_cls: 0.3367, loss_bbox: 0.2302, loss_dfl: 0.1897, loss: 0.7566\n",
      "2022-04-07 04:33:19,502 - mmdet - INFO - Saving checkpoint at 25 epochs\n",
      "2022-04-07 04:34:27,308 - mmdet - INFO - Epoch [26][50/2442]\tlr: 1.000e-04, eta: 3:51:39, time: 1.222, data_time: 0.059, memory: 17952, loss_cls: 0.3102, loss_bbox: 0.2379, loss_dfl: 0.1979, loss: 0.7460\n",
      "2022-04-07 04:35:25,385 - mmdet - INFO - Epoch [26][100/2442]\tlr: 1.000e-04, eta: 3:50:44, time: 1.162, data_time: 0.006, memory: 17952, loss_cls: 0.2779, loss_bbox: 0.2497, loss_dfl: 0.1961, loss: 0.7237\n",
      "2022-04-07 04:36:23,645 - mmdet - INFO - Epoch [26][150/2442]\tlr: 1.000e-04, eta: 3:49:48, time: 1.165, data_time: 0.007, memory: 17952, loss_cls: 0.3233, loss_bbox: 0.2703, loss_dfl: 0.2073, loss: 0.8010\n",
      "2022-04-07 04:37:21,652 - mmdet - INFO - Epoch [26][200/2442]\tlr: 1.000e-04, eta: 3:48:52, time: 1.160, data_time: 0.007, memory: 17952, loss_cls: 0.2574, loss_bbox: 0.2462, loss_dfl: 0.1998, loss: 0.7034\n",
      "2022-04-07 04:38:19,719 - mmdet - INFO - Epoch [26][250/2442]\tlr: 1.000e-04, eta: 3:47:57, time: 1.161, data_time: 0.007, memory: 17952, loss_cls: 0.3048, loss_bbox: 0.2779, loss_dfl: 0.2070, loss: 0.7897\n",
      "2022-04-07 04:39:17,798 - mmdet - INFO - Epoch [26][300/2442]\tlr: 1.000e-04, eta: 3:47:01, time: 1.162, data_time: 0.007, memory: 17952, loss_cls: 0.3145, loss_bbox: 0.2823, loss_dfl: 0.2153, loss: 0.8120\n",
      "2022-04-07 04:40:16,425 - mmdet - INFO - Epoch [26][350/2442]\tlr: 1.000e-04, eta: 3:46:06, time: 1.173, data_time: 0.007, memory: 17952, loss_cls: 0.2916, loss_bbox: 0.2781, loss_dfl: 0.2116, loss: 0.7813\n",
      "2022-04-07 04:41:14,469 - mmdet - INFO - Epoch [26][400/2442]\tlr: 1.000e-04, eta: 3:45:10, time: 1.161, data_time: 0.007, memory: 17952, loss_cls: 0.2811, loss_bbox: 0.2643, loss_dfl: 0.2058, loss: 0.7512\n",
      "2022-04-07 04:42:12,485 - mmdet - INFO - Epoch [26][450/2442]\tlr: 1.000e-04, eta: 3:44:14, time: 1.160, data_time: 0.007, memory: 17952, loss_cls: 0.2474, loss_bbox: 0.2369, loss_dfl: 0.1970, loss: 0.6814\n",
      "2022-04-07 04:43:10,564 - mmdet - INFO - Epoch [26][500/2442]\tlr: 1.000e-04, eta: 3:43:18, time: 1.162, data_time: 0.007, memory: 17952, loss_cls: 0.2768, loss_bbox: 0.2525, loss_dfl: 0.2015, loss: 0.7309\n",
      "2022-04-07 04:44:08,663 - mmdet - INFO - Epoch [26][550/2442]\tlr: 1.000e-04, eta: 3:42:22, time: 1.162, data_time: 0.006, memory: 17952, loss_cls: 0.2767, loss_bbox: 0.2578, loss_dfl: 0.2030, loss: 0.7375\n",
      "2022-04-07 04:45:06,762 - mmdet - INFO - Epoch [26][600/2442]\tlr: 1.000e-04, eta: 3:41:26, time: 1.162, data_time: 0.007, memory: 17952, loss_cls: 0.2639, loss_bbox: 0.2427, loss_dfl: 0.1963, loss: 0.7029\n",
      "2022-04-07 04:46:04,828 - mmdet - INFO - Epoch [26][650/2442]\tlr: 1.000e-04, eta: 3:40:30, time: 1.161, data_time: 0.007, memory: 17952, loss_cls: 0.2765, loss_bbox: 0.2700, loss_dfl: 0.2112, loss: 0.7577\n",
      "2022-04-07 04:47:02,816 - mmdet - INFO - Epoch [26][700/2442]\tlr: 1.000e-04, eta: 3:39:34, time: 1.160, data_time: 0.007, memory: 17952, loss_cls: 0.2921, loss_bbox: 0.2441, loss_dfl: 0.1955, loss: 0.7317\n",
      "2022-04-07 04:48:00,819 - mmdet - INFO - Epoch [26][750/2442]\tlr: 1.000e-04, eta: 3:38:38, time: 1.160, data_time: 0.007, memory: 17952, loss_cls: 0.3226, loss_bbox: 0.2558, loss_dfl: 0.2034, loss: 0.7819\n",
      "2022-04-07 04:48:58,775 - mmdet - INFO - Epoch [26][800/2442]\tlr: 1.000e-04, eta: 3:37:42, time: 1.159, data_time: 0.007, memory: 17952, loss_cls: 0.3027, loss_bbox: 0.2562, loss_dfl: 0.2023, loss: 0.7613\n",
      "2022-04-07 04:49:56,680 - mmdet - INFO - Epoch [26][850/2442]\tlr: 1.000e-04, eta: 3:36:46, time: 1.158, data_time: 0.007, memory: 17952, loss_cls: 0.3536, loss_bbox: 0.2349, loss_dfl: 0.1944, loss: 0.7829\n",
      "2022-04-07 04:50:54,788 - mmdet - INFO - Epoch [26][900/2442]\tlr: 1.000e-04, eta: 3:35:49, time: 1.162, data_time: 0.007, memory: 17952, loss_cls: 0.3707, loss_bbox: 0.2667, loss_dfl: 0.2076, loss: 0.8450\n",
      "2022-04-07 04:51:53,236 - mmdet - INFO - Epoch [26][950/2442]\tlr: 1.000e-04, eta: 3:34:54, time: 1.169, data_time: 0.007, memory: 17952, loss_cls: 0.3719, loss_bbox: 0.2946, loss_dfl: 0.2178, loss: 0.8842\n",
      "2022-04-07 04:52:51,368 - mmdet - INFO - Epoch [26][1000/2442]\tlr: 1.000e-04, eta: 3:33:58, time: 1.163, data_time: 0.007, memory: 17952, loss_cls: 0.3451, loss_bbox: 0.2754, loss_dfl: 0.2160, loss: 0.8364\n",
      "2022-04-07 04:53:49,390 - mmdet - INFO - Epoch [26][1050/2442]\tlr: 1.000e-04, eta: 3:33:02, time: 1.160, data_time: 0.007, memory: 17952, loss_cls: 0.2760, loss_bbox: 0.2606, loss_dfl: 0.2033, loss: 0.7398\n",
      "2022-04-07 04:54:47,460 - mmdet - INFO - Epoch [26][1100/2442]\tlr: 1.000e-04, eta: 3:32:05, time: 1.161, data_time: 0.007, memory: 17952, loss_cls: 0.3234, loss_bbox: 0.2329, loss_dfl: 0.1939, loss: 0.7502\n",
      "2022-04-07 04:55:45,380 - mmdet - INFO - Epoch [26][1150/2442]\tlr: 1.000e-04, eta: 3:31:09, time: 1.158, data_time: 0.007, memory: 17952, loss_cls: 0.2928, loss_bbox: 0.2528, loss_dfl: 0.2017, loss: 0.7473\n",
      "2022-04-07 04:56:43,735 - mmdet - INFO - Epoch [26][1200/2442]\tlr: 1.000e-04, eta: 3:30:13, time: 1.167, data_time: 0.007, memory: 17952, loss_cls: 0.3094, loss_bbox: 0.2451, loss_dfl: 0.1978, loss: 0.7522\n",
      "2022-04-07 04:57:41,795 - mmdet - INFO - Epoch [26][1250/2442]\tlr: 1.000e-04, eta: 3:29:17, time: 1.161, data_time: 0.007, memory: 17952, loss_cls: 0.3006, loss_bbox: 0.2900, loss_dfl: 0.2163, loss: 0.8070\n",
      "2022-04-07 04:58:39,869 - mmdet - INFO - Epoch [26][1300/2442]\tlr: 1.000e-04, eta: 3:28:20, time: 1.161, data_time: 0.007, memory: 17952, loss_cls: 0.3032, loss_bbox: 0.2383, loss_dfl: 0.2005, loss: 0.7420\n",
      "2022-04-07 04:59:37,911 - mmdet - INFO - Epoch [26][1350/2442]\tlr: 1.000e-04, eta: 3:27:24, time: 1.161, data_time: 0.007, memory: 17952, loss_cls: 0.3584, loss_bbox: 0.2543, loss_dfl: 0.2064, loss: 0.8190\n",
      "2022-04-07 05:00:35,895 - mmdet - INFO - Epoch [26][1400/2442]\tlr: 1.000e-04, eta: 3:26:28, time: 1.160, data_time: 0.007, memory: 17952, loss_cls: 0.3540, loss_bbox: 0.2596, loss_dfl: 0.2021, loss: 0.8157\n",
      "2022-04-07 05:01:33,922 - mmdet - INFO - Epoch [26][1450/2442]\tlr: 1.000e-04, eta: 3:25:31, time: 1.161, data_time: 0.007, memory: 17952, loss_cls: 0.3632, loss_bbox: 0.2597, loss_dfl: 0.2047, loss: 0.8276\n",
      "2022-04-07 05:02:32,094 - mmdet - INFO - Epoch [26][1500/2442]\tlr: 1.000e-04, eta: 3:24:35, time: 1.163, data_time: 0.007, memory: 17952, loss_cls: 0.3423, loss_bbox: 0.2643, loss_dfl: 0.2042, loss: 0.8108\n",
      "2022-04-07 05:03:30,048 - mmdet - INFO - Epoch [26][1550/2442]\tlr: 1.000e-04, eta: 3:23:38, time: 1.159, data_time: 0.007, memory: 17952, loss_cls: 0.3007, loss_bbox: 0.2421, loss_dfl: 0.2017, loss: 0.7445\n",
      "2022-04-07 05:04:28,090 - mmdet - INFO - Epoch [26][1600/2442]\tlr: 1.000e-04, eta: 3:22:42, time: 1.161, data_time: 0.007, memory: 17952, loss_cls: 0.2781, loss_bbox: 0.2500, loss_dfl: 0.1973, loss: 0.7255\n",
      "2022-04-07 05:05:26,109 - mmdet - INFO - Epoch [26][1650/2442]\tlr: 1.000e-04, eta: 3:21:45, time: 1.160, data_time: 0.007, memory: 17952, loss_cls: 0.2637, loss_bbox: 0.2317, loss_dfl: 0.1924, loss: 0.6878\n",
      "2022-04-07 05:06:24,224 - mmdet - INFO - Epoch [26][1700/2442]\tlr: 1.000e-04, eta: 3:20:49, time: 1.162, data_time: 0.007, memory: 17952, loss_cls: 0.3436, loss_bbox: 0.2620, loss_dfl: 0.2037, loss: 0.8092\n",
      "2022-04-07 05:07:22,413 - mmdet - INFO - Epoch [26][1750/2442]\tlr: 1.000e-04, eta: 3:19:53, time: 1.164, data_time: 0.007, memory: 17952, loss_cls: 0.3074, loss_bbox: 0.2656, loss_dfl: 0.2080, loss: 0.7810\n",
      "2022-04-07 05:08:20,430 - mmdet - INFO - Epoch [26][1800/2442]\tlr: 1.000e-04, eta: 3:18:56, time: 1.160, data_time: 0.006, memory: 17952, loss_cls: 0.3227, loss_bbox: 0.2507, loss_dfl: 0.1990, loss: 0.7724\n",
      "2022-04-07 05:09:18,550 - mmdet - INFO - Epoch [26][1850/2442]\tlr: 1.000e-04, eta: 3:18:00, time: 1.162, data_time: 0.007, memory: 17952, loss_cls: 0.3092, loss_bbox: 0.2509, loss_dfl: 0.2009, loss: 0.7611\n",
      "2022-04-07 05:10:16,640 - mmdet - INFO - Epoch [26][1900/2442]\tlr: 1.000e-04, eta: 3:17:03, time: 1.162, data_time: 0.007, memory: 17952, loss_cls: 0.3396, loss_bbox: 0.2827, loss_dfl: 0.2110, loss: 0.8333\n",
      "2022-04-07 05:11:14,591 - mmdet - INFO - Epoch [26][1950/2442]\tlr: 1.000e-04, eta: 3:16:07, time: 1.159, data_time: 0.007, memory: 17952, loss_cls: 0.3038, loss_bbox: 0.2376, loss_dfl: 0.1929, loss: 0.7343\n",
      "2022-04-07 05:12:12,579 - mmdet - INFO - Epoch [26][2000/2442]\tlr: 1.000e-04, eta: 3:15:10, time: 1.160, data_time: 0.007, memory: 17952, loss_cls: 0.3213, loss_bbox: 0.2608, loss_dfl: 0.2050, loss: 0.7871\n",
      "2022-04-07 05:13:10,532 - mmdet - INFO - Epoch [26][2050/2442]\tlr: 1.000e-04, eta: 3:14:13, time: 1.159, data_time: 0.007, memory: 17952, loss_cls: 0.2636, loss_bbox: 0.2125, loss_dfl: 0.1865, loss: 0.6626\n",
      "2022-04-07 05:14:08,502 - mmdet - INFO - Epoch [26][2100/2442]\tlr: 1.000e-04, eta: 3:13:17, time: 1.159, data_time: 0.007, memory: 17952, loss_cls: 0.3101, loss_bbox: 0.2446, loss_dfl: 0.1962, loss: 0.7510\n",
      "2022-04-07 05:15:06,581 - mmdet - INFO - Epoch [26][2150/2442]\tlr: 1.000e-04, eta: 3:12:20, time: 1.162, data_time: 0.007, memory: 17952, loss_cls: 0.3660, loss_bbox: 0.2869, loss_dfl: 0.2137, loss: 0.8667\n",
      "2022-04-07 05:16:04,678 - mmdet - INFO - Epoch [26][2200/2442]\tlr: 1.000e-04, eta: 3:11:23, time: 1.162, data_time: 0.007, memory: 17952, loss_cls: 0.3654, loss_bbox: 0.2677, loss_dfl: 0.2070, loss: 0.8400\n",
      "2022-04-07 05:17:02,591 - mmdet - INFO - Epoch [26][2250/2442]\tlr: 1.000e-04, eta: 3:10:27, time: 1.158, data_time: 0.007, memory: 17952, loss_cls: 0.2894, loss_bbox: 0.2404, loss_dfl: 0.1979, loss: 0.7276\n",
      "2022-04-07 05:18:00,474 - mmdet - INFO - Epoch [26][2300/2442]\tlr: 1.000e-04, eta: 3:09:30, time: 1.158, data_time: 0.007, memory: 17952, loss_cls: 0.2694, loss_bbox: 0.2245, loss_dfl: 0.1900, loss: 0.6839\n",
      "2022-04-07 05:18:58,509 - mmdet - INFO - Epoch [26][2350/2442]\tlr: 1.000e-04, eta: 3:08:33, time: 1.161, data_time: 0.007, memory: 17952, loss_cls: 0.2631, loss_bbox: 0.2570, loss_dfl: 0.2029, loss: 0.7230\n",
      "2022-04-07 05:19:56,578 - mmdet - INFO - Epoch [26][2400/2442]\tlr: 1.000e-04, eta: 3:07:36, time: 1.161, data_time: 0.007, memory: 17952, loss_cls: 0.2678, loss_bbox: 0.2643, loss_dfl: 0.2060, loss: 0.7382\n",
      "2022-04-07 05:20:45,443 - mmdet - INFO - Saving checkpoint at 26 epochs\n",
      "2022-04-07 05:21:52,997 - mmdet - INFO - Epoch [27][50/2442]\tlr: 1.000e-04, eta: 3:05:07, time: 1.216, data_time: 0.057, memory: 17952, loss_cls: 0.2931, loss_bbox: 0.2359, loss_dfl: 0.1955, loss: 0.7245\n",
      "2022-04-07 05:22:51,054 - mmdet - INFO - Epoch [27][100/2442]\tlr: 1.000e-04, eta: 3:04:10, time: 1.161, data_time: 0.007, memory: 17952, loss_cls: 0.2818, loss_bbox: 0.2558, loss_dfl: 0.1985, loss: 0.7361\n",
      "2022-04-07 05:23:49,279 - mmdet - INFO - Epoch [27][150/2442]\tlr: 1.000e-04, eta: 3:03:14, time: 1.164, data_time: 0.007, memory: 17952, loss_cls: 0.2782, loss_bbox: 0.2525, loss_dfl: 0.1993, loss: 0.7300\n",
      "2022-04-07 05:24:47,278 - mmdet - INFO - Epoch [27][200/2442]\tlr: 1.000e-04, eta: 3:02:18, time: 1.160, data_time: 0.007, memory: 17952, loss_cls: 0.2620, loss_bbox: 0.2472, loss_dfl: 0.2000, loss: 0.7092\n",
      "2022-04-07 05:25:45,308 - mmdet - INFO - Epoch [27][250/2442]\tlr: 1.000e-04, eta: 3:01:22, time: 1.161, data_time: 0.006, memory: 17952, loss_cls: 0.3063, loss_bbox: 0.2601, loss_dfl: 0.2074, loss: 0.7738\n",
      "2022-04-07 05:26:43,246 - mmdet - INFO - Epoch [27][300/2442]\tlr: 1.000e-04, eta: 3:00:25, time: 1.159, data_time: 0.006, memory: 17952, loss_cls: 0.3417, loss_bbox: 0.2435, loss_dfl: 0.1992, loss: 0.7844\n",
      "2022-04-07 05:27:41,592 - mmdet - INFO - Epoch [27][350/2442]\tlr: 1.000e-04, eta: 2:59:29, time: 1.167, data_time: 0.006, memory: 17952, loss_cls: 0.2965, loss_bbox: 0.2561, loss_dfl: 0.2032, loss: 0.7558\n",
      "2022-04-07 05:28:39,547 - mmdet - INFO - Epoch [27][400/2442]\tlr: 1.000e-04, eta: 2:58:33, time: 1.159, data_time: 0.007, memory: 17952, loss_cls: 0.3226, loss_bbox: 0.2586, loss_dfl: 0.2054, loss: 0.7865\n",
      "2022-04-07 05:29:37,515 - mmdet - INFO - Epoch [27][450/2442]\tlr: 1.000e-04, eta: 2:57:36, time: 1.159, data_time: 0.006, memory: 17952, loss_cls: 0.3245, loss_bbox: 0.2813, loss_dfl: 0.2124, loss: 0.8182\n",
      "2022-04-07 05:30:35,533 - mmdet - INFO - Epoch [27][500/2442]\tlr: 1.000e-04, eta: 2:56:40, time: 1.160, data_time: 0.006, memory: 17952, loss_cls: 0.2714, loss_bbox: 0.2824, loss_dfl: 0.2166, loss: 0.7703\n",
      "2022-04-07 05:31:33,468 - mmdet - INFO - Epoch [27][550/2442]\tlr: 1.000e-04, eta: 2:55:43, time: 1.159, data_time: 0.006, memory: 17952, loss_cls: 0.2758, loss_bbox: 0.2612, loss_dfl: 0.2044, loss: 0.7414\n",
      "2022-04-07 05:32:31,649 - mmdet - INFO - Epoch [27][600/2442]\tlr: 1.000e-04, eta: 2:54:47, time: 1.164, data_time: 0.007, memory: 17952, loss_cls: 0.2568, loss_bbox: 0.2539, loss_dfl: 0.2022, loss: 0.7129\n",
      "2022-04-07 05:33:29,676 - mmdet - INFO - Epoch [27][650/2442]\tlr: 1.000e-04, eta: 2:53:50, time: 1.161, data_time: 0.006, memory: 17952, loss_cls: 0.2546, loss_bbox: 0.2403, loss_dfl: 0.2003, loss: 0.6952\n",
      "2022-04-07 05:34:27,742 - mmdet - INFO - Epoch [27][700/2442]\tlr: 1.000e-04, eta: 2:52:54, time: 1.161, data_time: 0.007, memory: 17952, loss_cls: 0.2479, loss_bbox: 0.2042, loss_dfl: 0.1806, loss: 0.6328\n",
      "2022-04-07 05:35:25,956 - mmdet - INFO - Epoch [27][750/2442]\tlr: 1.000e-04, eta: 2:51:58, time: 1.164, data_time: 0.006, memory: 17952, loss_cls: 0.2630, loss_bbox: 0.2483, loss_dfl: 0.1961, loss: 0.7074\n",
      "2022-04-07 05:36:23,997 - mmdet - INFO - Epoch [27][800/2442]\tlr: 1.000e-04, eta: 2:51:01, time: 1.161, data_time: 0.006, memory: 17952, loss_cls: 0.2654, loss_bbox: 0.2579, loss_dfl: 0.2048, loss: 0.7280\n",
      "2022-04-07 05:37:22,013 - mmdet - INFO - Epoch [27][850/2442]\tlr: 1.000e-04, eta: 2:50:05, time: 1.160, data_time: 0.007, memory: 17952, loss_cls: 0.3757, loss_bbox: 0.2344, loss_dfl: 0.1892, loss: 0.7994\n",
      "2022-04-07 05:38:19,950 - mmdet - INFO - Epoch [27][900/2442]\tlr: 1.000e-04, eta: 2:49:08, time: 1.159, data_time: 0.006, memory: 17952, loss_cls: 0.2835, loss_bbox: 0.2534, loss_dfl: 0.2009, loss: 0.7379\n",
      "2022-04-07 05:39:17,868 - mmdet - INFO - Epoch [27][950/2442]\tlr: 1.000e-04, eta: 2:48:11, time: 1.158, data_time: 0.006, memory: 17952, loss_cls: 0.2603, loss_bbox: 0.2511, loss_dfl: 0.1979, loss: 0.7094\n",
      "2022-04-07 05:40:15,923 - mmdet - INFO - Epoch [27][1000/2442]\tlr: 1.000e-04, eta: 2:47:15, time: 1.161, data_time: 0.007, memory: 17952, loss_cls: 0.2968, loss_bbox: 0.2463, loss_dfl: 0.2001, loss: 0.7433\n",
      "2022-04-07 05:41:13,952 - mmdet - INFO - Epoch [27][1050/2442]\tlr: 1.000e-04, eta: 2:46:18, time: 1.161, data_time: 0.007, memory: 17952, loss_cls: 0.3197, loss_bbox: 0.2652, loss_dfl: 0.2080, loss: 0.7929\n",
      "2022-04-07 05:42:11,956 - mmdet - INFO - Epoch [27][1100/2442]\tlr: 1.000e-04, eta: 2:45:22, time: 1.160, data_time: 0.006, memory: 17952, loss_cls: 0.2947, loss_bbox: 0.2358, loss_dfl: 0.2004, loss: 0.7309\n",
      "2022-04-07 05:43:09,991 - mmdet - INFO - Epoch [27][1150/2442]\tlr: 1.000e-04, eta: 2:44:25, time: 1.161, data_time: 0.006, memory: 17952, loss_cls: 0.3288, loss_bbox: 0.2636, loss_dfl: 0.2050, loss: 0.7974\n",
      "2022-04-07 05:44:08,000 - mmdet - INFO - Epoch [27][1200/2442]\tlr: 1.000e-04, eta: 2:43:28, time: 1.160, data_time: 0.006, memory: 17952, loss_cls: 0.3370, loss_bbox: 0.2369, loss_dfl: 0.1967, loss: 0.7706\n",
      "2022-04-07 05:45:06,177 - mmdet - INFO - Epoch [27][1250/2442]\tlr: 1.000e-04, eta: 2:42:32, time: 1.164, data_time: 0.007, memory: 17952, loss_cls: 0.3142, loss_bbox: 0.2554, loss_dfl: 0.1998, loss: 0.7694\n",
      "2022-04-07 05:46:04,301 - mmdet - INFO - Epoch [27][1300/2442]\tlr: 1.000e-04, eta: 2:41:35, time: 1.162, data_time: 0.007, memory: 17952, loss_cls: 0.2750, loss_bbox: 0.2619, loss_dfl: 0.2036, loss: 0.7405\n",
      "2022-04-07 05:47:02,710 - mmdet - INFO - Epoch [27][1350/2442]\tlr: 1.000e-04, eta: 2:40:39, time: 1.168, data_time: 0.006, memory: 17952, loss_cls: 0.2575, loss_bbox: 0.2374, loss_dfl: 0.1929, loss: 0.6878\n",
      "2022-04-07 05:48:00,578 - mmdet - INFO - Epoch [27][1400/2442]\tlr: 1.000e-04, eta: 2:39:42, time: 1.157, data_time: 0.007, memory: 17952, loss_cls: 0.2518, loss_bbox: 0.2506, loss_dfl: 0.1996, loss: 0.7019\n",
      "2022-04-07 05:48:58,609 - mmdet - INFO - Epoch [27][1450/2442]\tlr: 1.000e-04, eta: 2:38:45, time: 1.161, data_time: 0.006, memory: 17952, loss_cls: 0.3165, loss_bbox: 0.2497, loss_dfl: 0.1966, loss: 0.7628\n",
      "2022-04-07 05:49:56,621 - mmdet - INFO - Epoch [27][1500/2442]\tlr: 1.000e-04, eta: 2:37:49, time: 1.160, data_time: 0.007, memory: 17952, loss_cls: 0.2925, loss_bbox: 0.2486, loss_dfl: 0.1967, loss: 0.7378\n",
      "2022-04-07 05:50:54,751 - mmdet - INFO - Epoch [27][1550/2442]\tlr: 1.000e-04, eta: 2:36:52, time: 1.163, data_time: 0.007, memory: 17952, loss_cls: 0.3575, loss_bbox: 0.2409, loss_dfl: 0.1963, loss: 0.7947\n",
      "2022-04-07 05:51:53,066 - mmdet - INFO - Epoch [27][1600/2442]\tlr: 1.000e-04, eta: 2:35:55, time: 1.166, data_time: 0.006, memory: 17952, loss_cls: 0.4177, loss_bbox: 0.3014, loss_dfl: 0.2171, loss: 0.9361\n",
      "2022-04-07 05:52:51,074 - mmdet - INFO - Epoch [27][1650/2442]\tlr: 1.000e-04, eta: 2:34:59, time: 1.160, data_time: 0.006, memory: 17952, loss_cls: 0.3014, loss_bbox: 0.2385, loss_dfl: 0.1931, loss: 0.7330\n",
      "2022-04-07 05:53:49,048 - mmdet - INFO - Epoch [27][1700/2442]\tlr: 1.000e-04, eta: 2:34:02, time: 1.159, data_time: 0.006, memory: 17952, loss_cls: 0.2819, loss_bbox: 0.2510, loss_dfl: 0.1993, loss: 0.7322\n",
      "2022-04-07 05:54:47,299 - mmdet - INFO - Epoch [27][1750/2442]\tlr: 1.000e-04, eta: 2:33:05, time: 1.165, data_time: 0.007, memory: 17952, loss_cls: 0.3012, loss_bbox: 0.2358, loss_dfl: 0.1944, loss: 0.7313\n",
      "2022-04-07 05:55:45,458 - mmdet - INFO - Epoch [27][1800/2442]\tlr: 1.000e-04, eta: 2:32:09, time: 1.163, data_time: 0.006, memory: 17952, loss_cls: 0.2691, loss_bbox: 0.2274, loss_dfl: 0.1903, loss: 0.6868\n",
      "2022-04-07 05:56:43,461 - mmdet - INFO - Epoch [27][1850/2442]\tlr: 1.000e-04, eta: 2:31:12, time: 1.160, data_time: 0.006, memory: 17952, loss_cls: 0.2864, loss_bbox: 0.2244, loss_dfl: 0.1956, loss: 0.7064\n",
      "2022-04-07 05:57:41,804 - mmdet - INFO - Epoch [27][1900/2442]\tlr: 1.000e-04, eta: 2:30:15, time: 1.167, data_time: 0.007, memory: 17952, loss_cls: 0.3965, loss_bbox: 0.2845, loss_dfl: 0.2131, loss: 0.8942\n",
      "2022-04-07 05:58:39,967 - mmdet - INFO - Epoch [27][1950/2442]\tlr: 1.000e-04, eta: 2:29:19, time: 1.163, data_time: 0.007, memory: 17952, loss_cls: 0.2909, loss_bbox: 0.2465, loss_dfl: 0.1969, loss: 0.7343\n",
      "2022-04-07 05:59:38,378 - mmdet - INFO - Epoch [27][2000/2442]\tlr: 1.000e-04, eta: 2:28:22, time: 1.168, data_time: 0.007, memory: 17952, loss_cls: 0.3113, loss_bbox: 0.2958, loss_dfl: 0.2182, loss: 0.8253\n",
      "2022-04-07 06:00:36,470 - mmdet - INFO - Epoch [27][2050/2442]\tlr: 1.000e-04, eta: 2:27:25, time: 1.162, data_time: 0.007, memory: 17952, loss_cls: 0.2979, loss_bbox: 0.2754, loss_dfl: 0.2129, loss: 0.7863\n",
      "2022-04-07 06:01:34,418 - mmdet - INFO - Epoch [27][2100/2442]\tlr: 1.000e-04, eta: 2:26:28, time: 1.159, data_time: 0.007, memory: 17952, loss_cls: 0.2484, loss_bbox: 0.2570, loss_dfl: 0.2045, loss: 0.7099\n",
      "2022-04-07 06:02:32,499 - mmdet - INFO - Epoch [27][2150/2442]\tlr: 1.000e-04, eta: 2:25:32, time: 1.162, data_time: 0.006, memory: 17952, loss_cls: 0.2803, loss_bbox: 0.2530, loss_dfl: 0.2007, loss: 0.7340\n",
      "2022-04-07 06:03:30,580 - mmdet - INFO - Epoch [27][2200/2442]\tlr: 1.000e-04, eta: 2:24:35, time: 1.162, data_time: 0.007, memory: 17952, loss_cls: 0.3625, loss_bbox: 0.2663, loss_dfl: 0.2059, loss: 0.8347\n",
      "2022-04-07 06:04:28,733 - mmdet - INFO - Epoch [27][2250/2442]\tlr: 1.000e-04, eta: 2:23:38, time: 1.163, data_time: 0.007, memory: 17952, loss_cls: 0.3435, loss_bbox: 0.2728, loss_dfl: 0.2093, loss: 0.8256\n",
      "2022-04-07 06:05:27,036 - mmdet - INFO - Epoch [27][2300/2442]\tlr: 1.000e-04, eta: 2:22:41, time: 1.166, data_time: 0.007, memory: 17952, loss_cls: 0.3194, loss_bbox: 0.2516, loss_dfl: 0.1980, loss: 0.7690\n",
      "2022-04-07 06:06:25,188 - mmdet - INFO - Epoch [27][2350/2442]\tlr: 1.000e-04, eta: 2:21:44, time: 1.163, data_time: 0.007, memory: 17952, loss_cls: 0.2870, loss_bbox: 0.2489, loss_dfl: 0.1968, loss: 0.7327\n",
      "2022-04-07 06:07:23,200 - mmdet - INFO - Epoch [27][2400/2442]\tlr: 1.000e-04, eta: 2:20:47, time: 1.160, data_time: 0.007, memory: 17952, loss_cls: 0.2641, loss_bbox: 0.2541, loss_dfl: 0.1997, loss: 0.7179\n",
      "2022-04-07 06:08:12,031 - mmdet - INFO - Saving checkpoint at 27 epochs\n",
      "2022-04-07 06:09:19,894 - mmdet - INFO - Epoch [28][50/2442]\tlr: 1.000e-05, eta: 2:18:36, time: 1.223, data_time: 0.058, memory: 17952, loss_cls: 0.2652, loss_bbox: 0.2456, loss_dfl: 0.1975, loss: 0.7083\n",
      "2022-04-07 06:10:18,235 - mmdet - INFO - Epoch [28][100/2442]\tlr: 1.000e-05, eta: 2:17:39, time: 1.167, data_time: 0.007, memory: 17952, loss_cls: 0.2797, loss_bbox: 0.2788, loss_dfl: 0.2129, loss: 0.7714\n",
      "2022-04-07 06:11:16,461 - mmdet - INFO - Epoch [28][150/2442]\tlr: 1.000e-05, eta: 2:16:43, time: 1.164, data_time: 0.007, memory: 17952, loss_cls: 0.2692, loss_bbox: 0.2534, loss_dfl: 0.2042, loss: 0.7268\n",
      "2022-04-07 06:12:14,635 - mmdet - INFO - Epoch [28][200/2442]\tlr: 1.000e-05, eta: 2:15:46, time: 1.163, data_time: 0.007, memory: 17952, loss_cls: 0.2052, loss_bbox: 0.1697, loss_dfl: 0.1691, loss: 0.5440\n",
      "2022-04-07 06:13:12,744 - mmdet - INFO - Epoch [28][250/2442]\tlr: 1.000e-05, eta: 2:14:49, time: 1.162, data_time: 0.007, memory: 17952, loss_cls: 0.2043, loss_bbox: 0.2179, loss_dfl: 0.1887, loss: 0.6109\n",
      "2022-04-07 06:14:10,819 - mmdet - INFO - Epoch [28][300/2442]\tlr: 1.000e-05, eta: 2:13:53, time: 1.161, data_time: 0.007, memory: 17952, loss_cls: 0.2463, loss_bbox: 0.2424, loss_dfl: 0.2026, loss: 0.6913\n",
      "2022-04-07 06:15:08,794 - mmdet - INFO - Epoch [28][350/2442]\tlr: 1.000e-05, eta: 2:12:56, time: 1.159, data_time: 0.007, memory: 17952, loss_cls: 0.2378, loss_bbox: 0.2307, loss_dfl: 0.1920, loss: 0.6605\n",
      "2022-04-07 06:16:06,692 - mmdet - INFO - Epoch [28][400/2442]\tlr: 1.000e-05, eta: 2:11:59, time: 1.158, data_time: 0.007, memory: 17952, loss_cls: 0.2200, loss_bbox: 0.1904, loss_dfl: 0.1781, loss: 0.5885\n",
      "2022-04-07 06:17:05,218 - mmdet - INFO - Epoch [28][450/2442]\tlr: 1.000e-05, eta: 2:11:03, time: 1.171, data_time: 0.007, memory: 17952, loss_cls: 0.2408, loss_bbox: 0.2274, loss_dfl: 0.1914, loss: 0.6597\n",
      "2022-04-07 06:18:03,359 - mmdet - INFO - Epoch [28][500/2442]\tlr: 1.000e-05, eta: 2:10:06, time: 1.163, data_time: 0.007, memory: 17952, loss_cls: 0.2208, loss_bbox: 0.2116, loss_dfl: 0.1891, loss: 0.6214\n",
      "2022-04-07 06:19:01,418 - mmdet - INFO - Epoch [28][550/2442]\tlr: 1.000e-05, eta: 2:09:10, time: 1.161, data_time: 0.007, memory: 17952, loss_cls: 0.2000, loss_bbox: 0.1826, loss_dfl: 0.1742, loss: 0.5568\n",
      "2022-04-07 06:19:59,489 - mmdet - INFO - Epoch [28][600/2442]\tlr: 1.000e-05, eta: 2:08:13, time: 1.161, data_time: 0.006, memory: 17952, loss_cls: 0.2279, loss_bbox: 0.2212, loss_dfl: 0.1877, loss: 0.6368\n",
      "2022-04-07 06:20:57,416 - mmdet - INFO - Epoch [28][650/2442]\tlr: 1.000e-05, eta: 2:07:16, time: 1.159, data_time: 0.007, memory: 17952, loss_cls: 0.1957, loss_bbox: 0.1828, loss_dfl: 0.1782, loss: 0.5567\n",
      "2022-04-07 06:21:55,449 - mmdet - INFO - Epoch [28][700/2442]\tlr: 1.000e-05, eta: 2:06:19, time: 1.161, data_time: 0.006, memory: 17952, loss_cls: 0.2319, loss_bbox: 0.2068, loss_dfl: 0.1887, loss: 0.6274\n",
      "2022-04-07 06:22:53,567 - mmdet - INFO - Epoch [28][750/2442]\tlr: 1.000e-05, eta: 2:05:22, time: 1.162, data_time: 0.007, memory: 17952, loss_cls: 0.2636, loss_bbox: 0.2052, loss_dfl: 0.1873, loss: 0.6561\n",
      "2022-04-07 06:23:51,562 - mmdet - INFO - Epoch [28][800/2442]\tlr: 1.000e-05, eta: 2:04:26, time: 1.160, data_time: 0.006, memory: 17952, loss_cls: 0.2033, loss_bbox: 0.1928, loss_dfl: 0.1793, loss: 0.5754\n",
      "2022-04-07 06:24:49,627 - mmdet - INFO - Epoch [28][850/2442]\tlr: 1.000e-05, eta: 2:03:29, time: 1.161, data_time: 0.006, memory: 17952, loss_cls: 0.2276, loss_bbox: 0.2248, loss_dfl: 0.1900, loss: 0.6423\n",
      "2022-04-07 06:25:47,790 - mmdet - INFO - Epoch [28][900/2442]\tlr: 1.000e-05, eta: 2:02:32, time: 1.163, data_time: 0.006, memory: 17952, loss_cls: 0.2147, loss_bbox: 0.2039, loss_dfl: 0.1841, loss: 0.6027\n",
      "2022-04-07 06:26:46,037 - mmdet - INFO - Epoch [28][950/2442]\tlr: 1.000e-05, eta: 2:01:35, time: 1.165, data_time: 0.007, memory: 17952, loss_cls: 0.1798, loss_bbox: 0.1800, loss_dfl: 0.1788, loss: 0.5385\n",
      "2022-04-07 06:27:44,057 - mmdet - INFO - Epoch [28][1000/2442]\tlr: 1.000e-05, eta: 2:00:39, time: 1.160, data_time: 0.007, memory: 17952, loss_cls: 0.2444, loss_bbox: 0.2110, loss_dfl: 0.1862, loss: 0.6416\n",
      "2022-04-07 06:28:42,001 - mmdet - INFO - Epoch [28][1050/2442]\tlr: 1.000e-05, eta: 1:59:42, time: 1.159, data_time: 0.006, memory: 17952, loss_cls: 0.1913, loss_bbox: 0.1855, loss_dfl: 0.1775, loss: 0.5543\n",
      "2022-04-07 06:29:39,956 - mmdet - INFO - Epoch [28][1100/2442]\tlr: 1.000e-05, eta: 1:58:45, time: 1.159, data_time: 0.007, memory: 17952, loss_cls: 0.1832, loss_bbox: 0.1676, loss_dfl: 0.1714, loss: 0.5222\n",
      "2022-04-07 06:30:37,976 - mmdet - INFO - Epoch [28][1150/2442]\tlr: 1.000e-05, eta: 1:57:48, time: 1.160, data_time: 0.007, memory: 17952, loss_cls: 0.2133, loss_bbox: 0.2106, loss_dfl: 0.1867, loss: 0.6106\n",
      "2022-04-07 06:31:35,929 - mmdet - INFO - Epoch [28][1200/2442]\tlr: 1.000e-05, eta: 1:56:51, time: 1.159, data_time: 0.007, memory: 17952, loss_cls: 0.2026, loss_bbox: 0.1831, loss_dfl: 0.1728, loss: 0.5585\n",
      "2022-04-07 06:32:34,024 - mmdet - INFO - Epoch [28][1250/2442]\tlr: 1.000e-05, eta: 1:55:54, time: 1.162, data_time: 0.007, memory: 17952, loss_cls: 0.1894, loss_bbox: 0.1797, loss_dfl: 0.1764, loss: 0.5454\n",
      "2022-04-07 06:33:32,014 - mmdet - INFO - Epoch [28][1300/2442]\tlr: 1.000e-05, eta: 1:54:57, time: 1.160, data_time: 0.007, memory: 17952, loss_cls: 0.2275, loss_bbox: 0.2207, loss_dfl: 0.1900, loss: 0.6382\n",
      "2022-04-07 06:34:29,933 - mmdet - INFO - Epoch [28][1350/2442]\tlr: 1.000e-05, eta: 1:54:00, time: 1.158, data_time: 0.007, memory: 17952, loss_cls: 0.2116, loss_bbox: 0.2057, loss_dfl: 0.1864, loss: 0.6038\n",
      "2022-04-07 06:35:27,937 - mmdet - INFO - Epoch [28][1400/2442]\tlr: 1.000e-05, eta: 1:53:04, time: 1.160, data_time: 0.007, memory: 17952, loss_cls: 0.2108, loss_bbox: 0.2121, loss_dfl: 0.1884, loss: 0.6114\n",
      "2022-04-07 06:36:25,953 - mmdet - INFO - Epoch [28][1450/2442]\tlr: 1.000e-05, eta: 1:52:07, time: 1.160, data_time: 0.007, memory: 17952, loss_cls: 0.1975, loss_bbox: 0.1919, loss_dfl: 0.1810, loss: 0.5704\n",
      "2022-04-07 06:37:23,959 - mmdet - INFO - Epoch [28][1500/2442]\tlr: 1.000e-05, eta: 1:51:10, time: 1.160, data_time: 0.007, memory: 17952, loss_cls: 0.2473, loss_bbox: 0.2357, loss_dfl: 0.1989, loss: 0.6819\n",
      "2022-04-07 06:38:21,975 - mmdet - INFO - Epoch [28][1550/2442]\tlr: 1.000e-05, eta: 1:50:13, time: 1.160, data_time: 0.007, memory: 17952, loss_cls: 0.2122, loss_bbox: 0.1963, loss_dfl: 0.1820, loss: 0.5905\n",
      "2022-04-07 06:39:20,133 - mmdet - INFO - Epoch [28][1600/2442]\tlr: 1.000e-05, eta: 1:49:16, time: 1.163, data_time: 0.007, memory: 17952, loss_cls: 0.2169, loss_bbox: 0.1966, loss_dfl: 0.1803, loss: 0.5938\n",
      "2022-04-07 06:40:18,343 - mmdet - INFO - Epoch [28][1650/2442]\tlr: 1.000e-05, eta: 1:48:19, time: 1.164, data_time: 0.007, memory: 17952, loss_cls: 0.2124, loss_bbox: 0.1984, loss_dfl: 0.1834, loss: 0.5942\n",
      "2022-04-07 06:41:16,389 - mmdet - INFO - Epoch [28][1700/2442]\tlr: 1.000e-05, eta: 1:47:22, time: 1.161, data_time: 0.007, memory: 17952, loss_cls: 0.2193, loss_bbox: 0.2014, loss_dfl: 0.1845, loss: 0.6051\n",
      "2022-04-07 06:42:14,357 - mmdet - INFO - Epoch [28][1750/2442]\tlr: 1.000e-05, eta: 1:46:25, time: 1.159, data_time: 0.007, memory: 17952, loss_cls: 0.2218, loss_bbox: 0.1960, loss_dfl: 0.1825, loss: 0.6002\n",
      "2022-04-07 06:43:12,425 - mmdet - INFO - Epoch [28][1800/2442]\tlr: 1.000e-05, eta: 1:45:28, time: 1.161, data_time: 0.007, memory: 17952, loss_cls: 0.2176, loss_bbox: 0.2038, loss_dfl: 0.1805, loss: 0.6019\n",
      "2022-04-07 06:44:10,586 - mmdet - INFO - Epoch [28][1850/2442]\tlr: 1.000e-05, eta: 1:44:31, time: 1.163, data_time: 0.007, memory: 17952, loss_cls: 0.1999, loss_bbox: 0.1779, loss_dfl: 0.1739, loss: 0.5517\n",
      "2022-04-07 06:45:08,765 - mmdet - INFO - Epoch [28][1900/2442]\tlr: 1.000e-05, eta: 1:43:34, time: 1.164, data_time: 0.007, memory: 17952, loss_cls: 0.2180, loss_bbox: 0.2165, loss_dfl: 0.1881, loss: 0.6227\n",
      "2022-04-07 06:46:06,786 - mmdet - INFO - Epoch [28][1950/2442]\tlr: 1.000e-05, eta: 1:42:37, time: 1.160, data_time: 0.007, memory: 17952, loss_cls: 0.2186, loss_bbox: 0.2097, loss_dfl: 0.1863, loss: 0.6146\n",
      "2022-04-07 06:47:04,791 - mmdet - INFO - Epoch [28][2000/2442]\tlr: 1.000e-05, eta: 1:41:40, time: 1.160, data_time: 0.007, memory: 17952, loss_cls: 0.2129, loss_bbox: 0.2143, loss_dfl: 0.1893, loss: 0.6164\n",
      "2022-04-07 06:48:03,011 - mmdet - INFO - Epoch [28][2050/2442]\tlr: 1.000e-05, eta: 1:40:44, time: 1.164, data_time: 0.007, memory: 17952, loss_cls: 0.2181, loss_bbox: 0.1949, loss_dfl: 0.1795, loss: 0.5926\n",
      "2022-04-07 06:49:01,200 - mmdet - INFO - Epoch [28][2100/2442]\tlr: 1.000e-05, eta: 1:39:47, time: 1.164, data_time: 0.007, memory: 17952, loss_cls: 0.2128, loss_bbox: 0.1881, loss_dfl: 0.1773, loss: 0.5781\n",
      "2022-04-07 06:49:59,265 - mmdet - INFO - Epoch [28][2150/2442]\tlr: 1.000e-05, eta: 1:38:50, time: 1.161, data_time: 0.007, memory: 17952, loss_cls: 0.2049, loss_bbox: 0.1974, loss_dfl: 0.1795, loss: 0.5817\n",
      "2022-04-07 06:50:57,578 - mmdet - INFO - Epoch [28][2200/2442]\tlr: 1.000e-05, eta: 1:37:53, time: 1.166, data_time: 0.007, memory: 17952, loss_cls: 0.2239, loss_bbox: 0.2075, loss_dfl: 0.1843, loss: 0.6157\n",
      "2022-04-07 06:51:55,663 - mmdet - INFO - Epoch [28][2250/2442]\tlr: 1.000e-05, eta: 1:36:56, time: 1.162, data_time: 0.007, memory: 17952, loss_cls: 0.2385, loss_bbox: 0.2128, loss_dfl: 0.1864, loss: 0.6377\n",
      "2022-04-07 06:52:53,660 - mmdet - INFO - Epoch [28][2300/2442]\tlr: 1.000e-05, eta: 1:35:59, time: 1.160, data_time: 0.007, memory: 17952, loss_cls: 0.2095, loss_bbox: 0.2135, loss_dfl: 0.1869, loss: 0.6099\n",
      "2022-04-07 06:53:51,675 - mmdet - INFO - Epoch [28][2350/2442]\tlr: 1.000e-05, eta: 1:35:02, time: 1.160, data_time: 0.007, memory: 17952, loss_cls: 0.2201, loss_bbox: 0.2058, loss_dfl: 0.1865, loss: 0.6124\n",
      "2022-04-07 06:54:49,604 - mmdet - INFO - Epoch [28][2400/2442]\tlr: 1.000e-05, eta: 1:34:04, time: 1.159, data_time: 0.007, memory: 17952, loss_cls: 0.2002, loss_bbox: 0.1971, loss_dfl: 0.1787, loss: 0.5760\n",
      "2022-04-07 06:55:38,425 - mmdet - INFO - Saving checkpoint at 28 epochs\n",
      "2022-04-07 06:56:45,852 - mmdet - INFO - Epoch [29][50/2442]\tlr: 1.000e-05, eta: 1:32:04, time: 1.216, data_time: 0.057, memory: 17952, loss_cls: 0.1846, loss_bbox: 0.1909, loss_dfl: 0.1789, loss: 0.5544\n",
      "2022-04-07 06:57:43,943 - mmdet - INFO - Epoch [29][100/2442]\tlr: 1.000e-05, eta: 1:31:08, time: 1.162, data_time: 0.007, memory: 17952, loss_cls: 0.1984, loss_bbox: 0.1980, loss_dfl: 0.1822, loss: 0.5786\n",
      "2022-04-07 06:58:41,978 - mmdet - INFO - Epoch [29][150/2442]\tlr: 1.000e-05, eta: 1:30:11, time: 1.161, data_time: 0.007, memory: 17952, loss_cls: 0.1851, loss_bbox: 0.1793, loss_dfl: 0.1788, loss: 0.5432\n",
      "2022-04-07 06:59:40,051 - mmdet - INFO - Epoch [29][200/2442]\tlr: 1.000e-05, eta: 1:29:14, time: 1.161, data_time: 0.007, memory: 17952, loss_cls: 0.2161, loss_bbox: 0.2079, loss_dfl: 0.1843, loss: 0.6083\n",
      "2022-04-07 07:00:38,040 - mmdet - INFO - Epoch [29][250/2442]\tlr: 1.000e-05, eta: 1:28:17, time: 1.160, data_time: 0.007, memory: 17952, loss_cls: 0.1857, loss_bbox: 0.1886, loss_dfl: 0.1764, loss: 0.5507\n",
      "2022-04-07 07:02:27,548 - mmdet - INFO - Epoch [29][300/2442]\tlr: 1.000e-05, eta: 1:27:36, time: 2.190, data_time: 0.006, memory: 17952, loss_cls: 0.1915, loss_bbox: 0.2034, loss_dfl: 0.1822, loss: 0.5770\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17033/3989587235.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_detector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistributed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/detection/baseline/mmdetection/mmdet/apis/train.py\u001b[0m in \u001b[0;36mtrain_detector\u001b[0;34m(model, dataset, cfg, distributed, validate, timestamp, meta)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m     \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkflow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/detection/lib/python3.7/site-packages/mmcv/runner/epoch_based_runner.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data_loaders, workflow, max_epochs, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_epochs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m                     \u001b[0mepoch_runner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# wait for some hooks like loggers to finish\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/detection/lib/python3.7/site-packages/mmcv/runner/epoch_based_runner.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data_loader, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'before_train_iter'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_train_iter'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/detection/lib/python3.7/site-packages/mmcv/runner/base_runner.py\u001b[0m in \u001b[0;36mcall_hook\u001b[0;34m(self, fn_name)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \"\"\"\n\u001b[1;32m    308\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m             \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_hook_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/detection/lib/python3.7/site-packages/mmcv/runner/hooks/optimizer.py\u001b[0m in \u001b[0;36mafter_train_iter\u001b[0;34m(self, runner)\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munscale_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0;31m# grad clip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/detection/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/detection/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_detector(model, dataset, cfg, distributed=False, validate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "980dec4bdc0f65d3f181e5891661df87e8769cde5e79cd54bc145a7f830b2685"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
