# boostcampAI

ğŸ¦† ë¶€ìŠ¤íŠ¸ìº í”„ AI Tech í•™ìŠµ ë‚´ìš© ì •ë¦¬ (3ê¸°, CV)

## Week 1

- [python stuff](https://github.com/star-bits/boostcampAI/blob/main/W1/%EC%A0%95%EB%A6%AC_python_stuff.ipynb): list comprehension, lambda, map, asterisk stuff(variable-length arguments, kwargs, unpacking), OOP, read(), pickle, csv, html parsing, xml, json
- [numpy and pandas](https://github.com/star-bits/boostcampAI/blob/main/W1/%EC%A0%95%EB%A6%AC_numpy_pandas.ipynb)
- GD, Probability, Inference
- ì‹¬í™” ê³¼ì œ 1 ì •ë¦¬: GD
- ì‹¬í™” ê³¼ì œ 2 ì •ë¦¬: Backprop
- ì‹¬í™” ê³¼ì œ 3 ì •ë¦¬: Maximum Liklihood Estimation

## Week 2

- [AutoGrad stuff](https://github.com/star-bits/boostcampAI/blob/main/W2/%EC%A0%95%EB%A6%AC_PyTorch_AutoGrad.ipynb): ì¼ë°˜ ë°©ì •ì‹ê³¼ cost functionì´ ë“¤ì–´ê°„ forward propagationì˜ ì°¨ì´, or lack thereof; Linear regressionì—ì„œ Jì™€ Jì˜ ë¯¸ë¶„, ê·¸ë¦¬ê³  chain rule. â­
- [PyTorch axis](https://github.com/star-bits/boostcampAI/blob/main/W2/%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5_numpy_PyTorch_axis.ipynb): on numpy and PyTorch axis. TL;DR: axis 0 is always the 'most layered' axis - t.shape: torch.Size([(axis 0), (axis 1), (axis 2)]) â­
- [ê¸°ë³¸ ê³¼ì œ 1 ì •ë¦¬](https://github.com/star-bits/boostcampAI/blob/main/W2/%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5_%E1%84%80%E1%85%B5%E1%84%87%E1%85%A9%E1%86%AB1_Custom_Model.ipynb): PyTorch Function, Module, Model
- [ê¸°ë³¸ ê³¼ì œ 2 ì •ë¦¬](https://github.com/star-bits/boostcampAI/blob/main/W2/%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5_%EA%B8%B0%EB%B3%B82_Custom_Dataset_%26_Custom_DataLoader.ipynb): PyTorch Dataset, DataLoader
- [ì‹¬í™” ê³¼ì œ 1 ì •ë¦¬](https://github.com/star-bits/boostcampAI/blob/main/W2/%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5_%E1%84%89%E1%85%B5%E1%86%B7%E1%84%92%E1%85%AA1_Transfer_Learning_%26_Hyperparameter_Tuning.ipynb): loading pretrained model, modifying the number of output features of a layer, transforming dataset - Grayscale and ToTensor, hyperparameters, train and test â­
- [iterable (object) and iterator](https://github.com/star-bits/boostcampAI/blob/main/W2/%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5_iterable_iterator.ipynb)
- [generator](https://github.com/star-bits/boostcampAI/blob/main/W2/%EC%A0%95%EB%A6%AC_generator.ipynb)

## Week 3

- [matplotlib.pyplot as plt](https://github.com/star-bits/boostcampAI/blob/main/W3/%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5_matplotlib.ipynb): fig, ax = plt.subplots(m, n); ax[i].plot(x, y); plt.show()
- [mpl: bar, line, scatter](https://github.com/star-bits/boostcampAI/blob/main/W3/%EC%A0%95%EB%A6%AC_mpl_bar_line_scatter.ipynb)
- [mpl: text, color, facet, misc.](https://github.com/star-bits/boostcampAI/blob/main/W3/%EC%A0%95%EB%A6%AC_mpl_text_color_facet_misc.ipynb)
- [seaborn as sns](https://github.com/star-bits/boostcampAI/blob/main/W3/%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5_seaborn.ipynb)
- [mpl: polar, pie](https://github.com/star-bits/boostcampAI/blob/main/W3/%EC%A0%95%EB%A6%AC_mpl_polar_pie.ipynb)
- [mpl: missingno, squarify, pywaffle, matplotlib_venn](https://github.com/star-bits/boostcampAI/blob/main/W3/%EC%A0%95%EB%A6%AC_mpl_missing_treemap_waffle_venn.ipynb): missing data, treemap (e.g. finviz), waffle chart, venn diagram
- [plotly.express as px](https://github.com/star-bits/boostcampAI/blob/main/W3/%EC%A0%95%EB%A6%AC_plotly_express.ipynb)
- [mpl: custom theme](https://github.com/star-bits/boostcampAI/blob/main/W3/%EC%A0%95%EB%A6%AC_mpl_custom_theme.ipynb)
- visualization techniques

## Week 4

- [Optimization - Adam](https://github.com/star-bits/boostcampAI/blob/main/W4/%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5_Optimization_Adam.ipynb): cross validation (k-fold validation), bootstrapping/bagging/boosting, momentum - directions with intertia, RMSprop - adaptive learning rate, Adam, parameter norm penalty (weight decay) 
- [CNN](https://github.com/star-bits/boostcampAI/blob/main/W4/%EC%A0%95%EB%A6%AC_CNN.ipynb): AlexNet - ReLU solves the vanishing gradient problem, VGGNet - smaller kernel size (3x3), GoogLeNet - 1x1 convolution the channel-wise dimension reducer, ResNet - skip connection (addition), DenseNet - skip connection (concatenation) 
- [RNN](https://github.com/star-bits/boostcampAI/blob/main/W4/%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5_RNN.ipynb): vanishing/exploding gradient in RNN caused by sigmoid and ReLU, LSTM
- Transformer, ViT
- Generative model
- [ê¸°ë³¸ ê³¼ì œ 1 ì •ë¦¬](https://github.com/star-bits/boostcampAI/blob/main/W4/%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5_%E1%84%80%E1%85%B5%E1%84%87%E1%85%A9%E1%86%AB1_MLP.ipynb): MLP â­
- [ê¸°ë³¸ ê³¼ì œ 2 ì •ë¦¬](https://github.com/star-bits/boostcampAI/blob/main/W4/%EC%A0%95%EB%A6%AC_%EA%B8%B0%EB%B3%B82_Optimization.ipynb): Optimization
- [ê¸°ë³¸ ê³¼ì œ 3 ì •ë¦¬](https://github.com/star-bits/boostcampAI/blob/main/W4/%EC%A0%95%EB%A6%AC_%EA%B8%B0%EB%B3%B83_CNN.ipynb): CNN â­
- [ê¸°ë³¸ ê³¼ì œ 4 ì •ë¦¬](https://github.com/star-bits/boostcampAI/blob/main/W4/%EC%A0%95%EB%A6%AC_%EA%B8%B0%EB%B3%B84_LSTM.ipynb): LSTM
- [ê¸°ë³¸ ê³¼ì œ 5 ì •ë¦¬](https://github.com/star-bits/boostcampAI/blob/main/W4/%EC%A0%95%EB%A6%AC_%EA%B8%B0%EB%B3%B85_SDPA.ipynb): SDPA
- [ì‹¬í™” ê³¼ì œ 1 ì •ë¦¬](https://github.com/star-bits/boostcampAI/blob/main/W4/%EC%A0%95%EB%A6%AC_%EC%8B%AC%ED%99%941_ViT.ipynb): ViT
- [ì‹¬í™” ê³¼ì œ 2 ì •ë¦¬](https://github.com/star-bits/boostcampAI/blob/main/W4/%EC%A0%95%EB%A6%AC_%EC%8B%AC%ED%99%942_AAE.ipynb): AAE

## Week 5

- [shell commands](https://github.com/star-bits/boostcampAI/blob/main/W5/%EC%A0%95%EB%A6%AC_shell_commands.ipynb)
- [venv, conda](https://github.com/star-bits/boostcampAI/blob/main/W5/%EC%A0%95%EB%A6%AC_venv_conda.ipynb)
- [os cwd](https://github.com/star-bits/boostcampAI/blob/main/W5/%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5_os_cwd.ipynb)
- [docker](https://github.com/star-bits/boostcampAI/blob/main/W5/%EC%A0%95%EB%A6%AC_docker.ipynb)
- [mlflow](https://github.com/star-bits/boostcampAI/blob/main/W5/%EC%A0%95%EB%A6%AC_mlflow.ipynb)

## Week 6-7: Image Classification

- [ë¯¸ì…˜ 2 ì •ë¦¬](https://github.com/star-bits/boostcampAI/blob/main/W6-7/%EC%A0%95%EB%A6%AC_%EB%AF%B8%EC%85%982_EDA.ipynb): EDA â­
- [ë¯¸ì…˜ 3 ì •ë¦¬](https://github.com/star-bits/boostcampAI/blob/main/W6-7/%EC%A0%95%EB%A6%AC_%EB%AF%B8%EC%85%983_Augmentation.ipynb): Augmentation â­
- [ë¯¸ì…˜ 4 ì •ë¦¬](https://github.com/star-bits/boostcampAI/blob/main/W6-7/%EC%A0%95%EB%A6%AC_%EB%AF%B8%EC%85%984_Data_Generation.ipynb): Data Generation â­
- [ë¯¸ì…˜ 5 ì •ë¦¬](https://github.com/star-bits/boostcampAI/blob/main/W6-7/%EC%A0%95%EB%A6%AC_%EB%AF%B8%EC%85%985_Model.ipynb): Model â­
- [ë¯¸ì…˜ 6 ì •ë¦¬](https://github.com/star-bits/boostcampAI/blob/main/W6-7/%EC%A0%95%EB%A6%AC_%EB%AF%B8%EC%85%986_Pretrained.ipynb): Pretrained model â­
- [ë¯¸ì…˜ 7-8 ì •ë¦¬](https://github.com/star-bits/boostcampAI/blob/main/W6-7/%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5_%E1%84%86%E1%85%B5%E1%84%89%E1%85%A7%E1%86%AB7-8_Loss_Optimizer.ipynb): Loss, Optimizer
- ë¯¸ì…˜ 9 ì •ë¦¬: Ensemble
- ë¯¸ì…˜ 10 ì •ë¦¬: tensorboard, wandb

## Week 8-9

- [ê¸°ë³¸ ê³¼ì œ 1 ì •ë¦¬](https://github.com/star-bits/boostcampAI/blob/main/W8-9/%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5_resnet34_Implementation.ipynb): resnet34 implementation from scratch: ConvBlock(nn.Sequential(\*layers[nn.Conv2d, nn.BatchNorm2d, nn.ReLU])) -> ResBlock(nn.Sequential(\*layers[ConvBlock, ConvBlock, residual])) -> ResNet â­
- [ê¸°ë³¸ ê³¼ì œ 2 ì •ë¦¬](https://github.com/star-bits/boostcampAI/blob/main/W8-9/%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5_Data_Augmentation.ipynb): Data Augmentation - transforms.Compose([RandomCrop, ToTensor, Resize, Normalize]), Channel order: {cv2: BGR, torch: RGB}, Dimension: {cv2: (height, width, channel), torch conv2d layer: (batch_size, channel, height, width)} â­
- [ê¸°ë³¸ ê³¼ì œ 3 ì •ë¦¬](https://github.com/star-bits/boostcampAI/blob/main/W8-9/%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5_vgg11_Segmentation.ipynb): vgg11 implementation from scratch, semantic segmentation using vgg11 modified as FCN by replacing fc layer with 1x1 conv layer
- [ì‹¬í™” ê³¼ì œ 1 ì •ë¦¬](https://github.com/star-bits/boostcampAI/blob/main/W8-9/%EC%A0%95%EB%A6%AC_CNN_Visualization.ipynb): visualizing conv1 filters, visualizing model activations using forward hook, visualizing saliency map (gradient_logit/gradient_image), visualizing Grad-CAM â­
- [ê¸°ë³¸ ê³¼ì œ 4 ì •ë¦¬](https://github.com/star-bits/boostcampAI/blob/main/W8-9/%EC%A0%95%EB%A6%AC_CGAN.ipynb): CGAN - G(concat(emb(z), emb(y))), D(concat(emb(x), emb(y))) â­
- [ê¸°ë³¸ ê³¼ì œ 5 ì •ë¦¬](https://github.com/star-bits/boostcampAI/blob/main/W8-9/%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5_Multi-modal.ipynb): Multi-modal
- [ì‹¬í™” ê³¼ì œ 2 ì •ë¦¬](https://github.com/star-bits/boostcampAI/blob/main/W8-9/%EC%A0%95%EB%A6%AC_Hourglass_Network.ipynb): Hourglass network, torchsummary summary
- [ì‹¬í™” ê³¼ì œ 3 ì •ë¦¬](https://github.com/star-bits/boostcampAI/blob/main/W8-9/%EC%A0%95%EB%A6%AC_Depth_map.ipynb): Depth map
- [More AutoGrad stuff](https://github.com/star-bits/boostcampAI/blob/main/W8-9/%EC%A0%95%EB%A6%AC_More_AutoGrad.ipynb)

## Week 10-12: Object Detection

- [Two-Stage Detectors](https://github.com/star-bits/boostcampAI/blob/main/W10-12/%EC%A0%95%EB%A6%AC_2_Stage_Detectors.ipynb): R-CNN, SPPNet (ROI projection: projection of selective search result onto a feature map, Spatial Pyramid Pooling: n by n grid pooling - fixed fc layer size) solves multiple CNN problem and image warping problem, Fast R-CNN (multi-task loss: classification loss + bounding box regression loss), Faster R-CNN (Region Proposal Network: apply anchor boxes on feature map cells)
- [Feature Pyramid Network](https://github.com/star-bits/boostcampAI/blob/main/W10-12/%EC%A0%95%EB%A6%AC_Feature_Pyramid_Network.ipynb): FPN (top-down pathway: mixing low level and high level feature maps), PANet (bottom-up path augmentation, adaptive feature pooling: ROI from all stages), Recursive FPN, Bi-directional FPN, NAS(Neural Architecture Search)FPN 
- [One-Stage Detectors](https://github.com/star-bits/boostcampAI/blob/main/W10-12/%EC%A0%95%EB%A6%AC_1_Stage_Detectors.ipynb): YOLO (loss: localization loss + confidence loss + classification loss), SSD(multi-scale feature maps, no fc layer, has anchor box), RetinaNet(background class imbalance - solved by focal loss)
- [More on Two-Stage Detectors](https://github.com/star-bits/boostcampAI/blob/main/W10-12/%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5_More_2_Stage_Detectors.ipynb): Faster R-CNN (image -> through ConvNet -> feature map -> through RPN -> ROI; (ROI + feature map) -> through ROI pooling -> through (classification head + regressor head) -> output) has 3 networks: (ConvNet, RPN, cls+reg head), RPN: (9 anchor boxes, 0 or 1 classification, NMS), Cascade R-CNN, Deformable convolution, Transformer (Q, K, V created by W_Q, W_K, W_V; Attention map from Q, K), Swin â­
- [More on One-Stage Detectors](https://github.com/star-bits/boostcampAI/blob/main/W10-12/%EC%A0%95%EB%A6%AC_More_1_Stage_Detectors.ipynb): Two-stage detectors: prediction doesn't happen at every pixel (of a final feature map), proposals from RPN gets projected onto a feature map, and after going through ROI pooling, output gets delivered to cls head and reg head; One-stage detectors: prediction gets made from every pixel (of a final feature map), doesn't have RPN - detector itself is an alteration of RPN, each pixel gets anchor boxes and classification and bbox regression comes right after â­
- [ê¸°ë³¸ ë¯¸ì…˜ 1 ì •ë¦¬](https://github.com/star-bits/boostcampAI/blob/main/W10-12/%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5_Metric.ipynb): bbox mAP
- ì‹¬í™” ë¯¸ì…˜ 1 ì •ë¦¬: bbox mAP (advanced)
- ê¸°ë³¸ ë¯¸ì…˜ 2 ì •ë¦¬: Faster R-CNN
- ê¸°ë³¸ ë¯¸ì…˜ 4 ì •ë¦¬: FPN
- ì‹¬í™” ë¯¸ì…˜ 4 ì •ë¦¬: Faster R-CNN FPN
- ê¸°ë³¸ ë¯¸ì…˜ 5 ì •ë¦¬: YOLO
- ì‹¬í™” ë¯¸ì…˜ 5 ì •ë¦¬: YOLO inference
- ì‹¬í™” ë¯¸ì…˜ 6 ì •ë¦¬: YOLOv3
- [ê¸°ë³¸ ë¯¸ì…˜ 7 ì •ë¦¬](https://github.com/star-bits/boostcampAI/blob/main/W10-12/%EC%A0%95%EB%A6%AC_WBF_Ensemble.ipynb): WBF(Weighted Boxes Fusion) ensemble
- Faster R-CNN with Swin-L backbone: [config.py](https://github.com/star-bits/boostcampAI/blob/main/W10-12/_swin_faster_config.py), [train.ipynb](https://github.com/star-bits/boostcampAI/blob/main/W10-12/_swin_faster_train.ipynb), [infer.ipynb](https://github.com/star-bits/boostcampAI/blob/main/W10-12/_swin_faster_infer.ipynb) â­
- UniverseNet with Swin-L backbone: [config.py](https://github.com/star-bits/boostcampAI/blob/main/W10-12/_universe_config.py), [train.ipynb](https://github.com/star-bits/boostcampAI/blob/main/W10-12/_universe_train.ipynb), [infer.ipynb](https://github.com/star-bits/boostcampAI/blob/main/W10-12/_universe_infer.ipynb)

## Week 13-14: Text Detection

- EDA.ipynb
- [download_ICDAR17.sh](https://github.com/star-bits/boostcampAI/blob/main/W13-14/download_ICDAR17.sh)
- [add_tr_va.sh](https://github.com/star-bits/boostcampAI/blob/main/W13-14/add_tr_va.sh) to rename images
- [mlt2ufo_ICDAR17raw2LKJ.py](https://github.com/star-bits/boostcampAI/blob/main/W13-14/convert_mlt_ICDAR17raw2LKJ.py)
- [mlt2ufo_ICDAR19raw2LKJ.py](https://github.com/star-bits/boostcampAI/blob/main/W13-14/convert_mlt_ICDAR19raw2LKJ.py)
- [im_mode_test.py](https://github.com/star-bits/boostcampAI/blob/main/W13-14/im_mode_test.py)
- [resize_dataset.py](https://github.com/star-bits/boostcampAI/blob/main/W13-14/resize_dataset.py): os.makedirs(), json.load(), json.dump(), cv2.imread(), cv2.resize(), cv2.imwrite()
- [cvtPoly2Rect.ipynb](https://github.com/star-bits/boostcampAI/blob/main/W13-14/cvtPoly2Rect.ipynb): cv2.contourArea(), cv2.minAreaRect(), cv2.boxPoints()
- [dataset.py](https://github.com/star-bits/boostcampAI/blob/main/W13-14/dataset_multiple.py) to check the len of dataset
- [train.py](https://github.com/star-bits/boostcampAI/blob/main/W13-14/train_multiple.py) (lr_scheduler: MultiStepLR | CosineAnnealingLR | CosineAnnealingWarmUpRestarts)

## Week 15-17: Semantic Segmentation

- [Semantic Segmentation Pipeline](https://github.com/star-bits/boostcampAI/blob/main/W15-17/%EC%A0%95%EB%A6%AC_Segmentation_Baseline.ipynb) (torchvision.models.segmentation.fcn_resnet50)
- Semantic Segmentation Models: FCN-32s, FCN-16s, FCN-8s, DeconvNet, SegNet, DeepLabV1, DialatedNet, DeepLabV2-VGG16, DeepLabV2-ResNet101, DeepLabV3-ResNet101, DeepLabV3Plus-Xception, UNet, UNet++
- [UNet3Plus.py](https://github.com/star-bits/boostcampAI/blob/main/W15-17/UNet3Plus.py): UNet3+ from scratch
- [UNet3+ Implementation](https://github.com/star-bits/boostcampAI/blob/main/W15-17/%EC%A0%95%EB%A6%AC_Segmentation_UNet3Plus.ipynb) â­

## Week 18-22: Final Project

- [ì›¹ìº ì„ í†µí•œ ê°€ìƒ ë§ˆìš°ìŠ¤](https://github.com/boostcampaitech3/final-project-level3-cv-13): ì†ê³¼ ì›¹ìº ìœ¼ë¡œ ë§ˆìš°ìŠ¤ ì»¤ì„œ ì¡°ì‘í•˜ê¸°
  - ì›¹ìº ìœ¼ë¡œ ì†ì˜ í‚¤í¬ì¸íŠ¸ë¥¼ ì°¾ê³ , ì œìŠ¤ì³ë¥¼ ì¸ì‹í•´ ë§ˆìš°ìŠ¤ ì»¤ì„œë¥¼ ì¡°ì‘í•˜ëŠ” í”„ë¡œì íŠ¸.
  - í•´ë‹¹ íƒœìŠ¤í¬ì— íŠ¹í™”ëœ ë°ì´í„°ì…‹ì„ ë§Œë“¤ê¸° ìœ„í•´ ì§ì ‘ ë‹¤ì–‘í•œ í™˜ê²½ì—ì„œ ë°ì´í„°ë¥¼ ë§Œë“¤ì–´ì£¼ëŠ” ì½”ë“œì™€, ê·¸ ë°ì´í„°ì˜ COCO í¬ë§· ì–´ë…¸í…Œì´ì…˜ íŒŒì¼ì„ ë§Œë“¤ì–´ì£¼ëŠ” ì½”ë“œë¥¼ ì‘ì„±.
  - MMPoseì—ì„œ ImageNet pretrained MobileNetV3-Largeë¥¼ ì´ìš©í•´, ëŒ€ê·œëª¨ ê³µê°œ ë°ì´í„°ì…‹(FreiHAND)ìœ¼ë¡œ í•™ìŠµí•˜ê³ , ê·¸ ëª¨ë¸ì„ ë‹¤ì‹œ pretrainedì‚¼ì•„ ì§ì ‘ ì œì‘í•œ ë°ì´í„°ì…‹ì— ì¬í•™ìŠµí•˜ëŠ” ë°©ì‹ìœ¼ë¡œ í•¸ë“œ í‚¤í¬ì¸íŠ¸ ë””í…ì…˜ ì •í™•ë„ ë° ì•ˆì •ì„± í–¥ìƒ.
