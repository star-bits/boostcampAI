{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import albumentations as A\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "import requests\n",
    "import random\n",
    "from time import time\n",
    "from enum import Enum\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=3, kernel_size=3, bias=True)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=3)\n",
    "        self.conv2 = nn.Conv2d(in_channels=3, out_channels=5, kernel_size=3, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        return F.relu(self.conv2(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "            self.layer = \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer(x)\n",
    "        return x\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (conv1): Conv2d(1, 3, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(3, 5, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### named_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight\n",
      "torch.Size([3, 1, 3, 3])\n",
      "Parameter containing:\n",
      "tensor([[[[ 0.1688, -0.0547, -0.1594],\n",
      "          [-0.0223,  0.2883,  0.0153],\n",
      "          [-0.0523,  0.1475, -0.0500]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0070, -0.1964,  0.0903],\n",
      "          [ 0.1511, -0.1235,  0.2422],\n",
      "          [-0.0602,  0.0905, -0.0266]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2699,  0.0363,  0.2206],\n",
      "          [-0.1975,  0.1651, -0.1708],\n",
      "          [-0.1452, -0.1330, -0.2261]]]], requires_grad=True)\n",
      "####################################################################################################\n",
      "conv1.bias\n",
      "torch.Size([3])\n",
      "Parameter containing:\n",
      "tensor([ 0.2864, -0.0154, -0.2926], requires_grad=True)\n",
      "####################################################################################################\n",
      "bn1.weight\n",
      "torch.Size([3])\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1.], requires_grad=True)\n",
      "####################################################################################################\n",
      "bn1.bias\n",
      "torch.Size([3])\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0.], requires_grad=True)\n",
      "####################################################################################################\n",
      "conv2.weight\n",
      "torch.Size([5, 3, 3, 3])\n",
      "Parameter containing:\n",
      "tensor([[[[-0.0713,  0.1591,  0.0971],\n",
      "          [ 0.0140, -0.1008, -0.1386],\n",
      "          [-0.1725, -0.0082, -0.1764]],\n",
      "\n",
      "         [[ 0.0711, -0.1066, -0.1408],\n",
      "          [-0.1575,  0.1829,  0.0921],\n",
      "          [-0.0869,  0.0946,  0.1534]],\n",
      "\n",
      "         [[-0.1829,  0.0619,  0.0283],\n",
      "          [ 0.0094, -0.1105, -0.0737],\n",
      "          [-0.1203,  0.0537, -0.1825]]],\n",
      "\n",
      "\n",
      "        [[[-0.1804,  0.1567,  0.1070],\n",
      "          [-0.0166,  0.1306, -0.0064],\n",
      "          [-0.1047,  0.1004,  0.0977]],\n",
      "\n",
      "         [[-0.1146,  0.0542, -0.0301],\n",
      "          [ 0.1437,  0.1748,  0.0634],\n",
      "          [-0.0612, -0.1450,  0.0582]],\n",
      "\n",
      "         [[-0.1924,  0.1793,  0.0360],\n",
      "          [ 0.0658, -0.0384,  0.1751],\n",
      "          [ 0.1542,  0.1518, -0.0187]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0536, -0.1390, -0.0722],\n",
      "          [-0.0158, -0.1440, -0.0364],\n",
      "          [ 0.0800, -0.0235,  0.1528]],\n",
      "\n",
      "         [[-0.0129, -0.0554,  0.0478],\n",
      "          [ 0.0652,  0.1551,  0.0809],\n",
      "          [ 0.0196, -0.1018, -0.1729]],\n",
      "\n",
      "         [[ 0.0579,  0.1849, -0.0171],\n",
      "          [-0.1890, -0.0750,  0.0848],\n",
      "          [ 0.1801,  0.1107,  0.0540]]],\n",
      "\n",
      "\n",
      "        [[[-0.0066, -0.1147,  0.1098],\n",
      "          [-0.1139, -0.1762,  0.0995],\n",
      "          [-0.1270, -0.1240, -0.1158]],\n",
      "\n",
      "         [[ 0.1538, -0.0851,  0.0035],\n",
      "          [-0.0589,  0.1625, -0.1198],\n",
      "          [ 0.0656,  0.0084,  0.0039]],\n",
      "\n",
      "         [[-0.1592, -0.0326, -0.0768],\n",
      "          [ 0.1375,  0.1888,  0.0877],\n",
      "          [-0.1810,  0.0439,  0.1871]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1460, -0.1380, -0.1457],\n",
      "          [ 0.1425,  0.1039, -0.0453],\n",
      "          [ 0.0718,  0.1469, -0.0516]],\n",
      "\n",
      "         [[-0.0362, -0.1826,  0.1315],\n",
      "          [-0.0025,  0.0923,  0.0338],\n",
      "          [-0.0872,  0.1088,  0.0670]],\n",
      "\n",
      "         [[ 0.0081,  0.1047, -0.1067],\n",
      "          [-0.0485,  0.0946,  0.1283],\n",
      "          [-0.0908, -0.1724, -0.0900]]]], requires_grad=True)\n",
      "####################################################################################################\n"
     ]
    }
   ],
   "source": [
    "for param, weight in model.named_parameters():\n",
    "    print(param)\n",
    "    print(weight.size())\n",
    "    print(weight)\n",
    "    print('#'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[ 0.1688, -0.0547, -0.1594],\n",
      "          [-0.0223,  0.2883,  0.0153],\n",
      "          [-0.0523,  0.1475, -0.0500]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0070, -0.1964,  0.0903],\n",
      "          [ 0.1511, -0.1235,  0.2422],\n",
      "          [-0.0602,  0.0905, -0.0266]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2699,  0.0363,  0.2206],\n",
      "          [-0.1975,  0.1651, -0.1708],\n",
      "          [-0.1452, -0.1330, -0.2261]]]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model.conv1.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder = './runs'\n",
    "save_path = os.path.join(save_folder, 'best.pth')\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "torch.save(model.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "torch.save(model.state_dict(), save_path)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model = Model()\n",
    "new_model.load_state_dict(torch.load(save_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "new_model.load_state_dict(torch.load(save_path))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight from model and new_model are matched - True\n",
      "conv1.bias from model and new_model are matched - True\n",
      "bn1.weight from model and new_model are matched - True\n",
      "bn1.bias from model and new_model are matched - True\n",
      "conv2.weight from model and new_model are matched - True\n"
     ]
    }
   ],
   "source": [
    "for (name, trained_weight), (_, saved_weight) in zip(model.named_parameters(), new_model.named_parameters()):\n",
    "    is_equal = torch.equal(trained_weight, saved_weight)\n",
    "    print(f'{name} from model and new_model are matched - {is_equal}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight\n",
      "torch.Size([3, 1, 3, 3])\n",
      "tensor([[[[ 0.1688, -0.0547, -0.1594],\n",
      "          [-0.0223,  0.2883,  0.0153],\n",
      "          [-0.0523,  0.1475, -0.0500]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0070, -0.1964,  0.0903],\n",
      "          [ 0.1511, -0.1235,  0.2422],\n",
      "          [-0.0602,  0.0905, -0.0266]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2699,  0.0363,  0.2206],\n",
      "          [-0.1975,  0.1651, -0.1708],\n",
      "          [-0.1452, -0.1330, -0.2261]]]])\n",
      "####################################################################################################\n",
      "conv1.bias\n",
      "torch.Size([3])\n",
      "tensor([ 0.2864, -0.0154, -0.2926])\n",
      "####################################################################################################\n",
      "bn1.weight\n",
      "torch.Size([3])\n",
      "tensor([1., 1., 1.])\n",
      "####################################################################################################\n",
      "bn1.bias\n",
      "torch.Size([3])\n",
      "tensor([0., 0., 0.])\n",
      "####################################################################################################\n",
      "bn1.running_mean\n",
      "torch.Size([3])\n",
      "tensor([0., 0., 0.])\n",
      "####################################################################################################\n",
      "bn1.running_var\n",
      "torch.Size([3])\n",
      "tensor([1., 1., 1.])\n",
      "####################################################################################################\n",
      "bn1.num_batches_tracked\n",
      "torch.Size([])\n",
      "tensor(0)\n",
      "####################################################################################################\n",
      "conv2.weight\n",
      "torch.Size([5, 3, 3, 3])\n",
      "tensor([[[[-0.0713,  0.1591,  0.0971],\n",
      "          [ 0.0140, -0.1008, -0.1386],\n",
      "          [-0.1725, -0.0082, -0.1764]],\n",
      "\n",
      "         [[ 0.0711, -0.1066, -0.1408],\n",
      "          [-0.1575,  0.1829,  0.0921],\n",
      "          [-0.0869,  0.0946,  0.1534]],\n",
      "\n",
      "         [[-0.1829,  0.0619,  0.0283],\n",
      "          [ 0.0094, -0.1105, -0.0737],\n",
      "          [-0.1203,  0.0537, -0.1825]]],\n",
      "\n",
      "\n",
      "        [[[-0.1804,  0.1567,  0.1070],\n",
      "          [-0.0166,  0.1306, -0.0064],\n",
      "          [-0.1047,  0.1004,  0.0977]],\n",
      "\n",
      "         [[-0.1146,  0.0542, -0.0301],\n",
      "          [ 0.1437,  0.1748,  0.0634],\n",
      "          [-0.0612, -0.1450,  0.0582]],\n",
      "\n",
      "         [[-0.1924,  0.1793,  0.0360],\n",
      "          [ 0.0658, -0.0384,  0.1751],\n",
      "          [ 0.1542,  0.1518, -0.0187]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0536, -0.1390, -0.0722],\n",
      "          [-0.0158, -0.1440, -0.0364],\n",
      "          [ 0.0800, -0.0235,  0.1528]],\n",
      "\n",
      "         [[-0.0129, -0.0554,  0.0478],\n",
      "          [ 0.0652,  0.1551,  0.0809],\n",
      "          [ 0.0196, -0.1018, -0.1729]],\n",
      "\n",
      "         [[ 0.0579,  0.1849, -0.0171],\n",
      "          [-0.1890, -0.0750,  0.0848],\n",
      "          [ 0.1801,  0.1107,  0.0540]]],\n",
      "\n",
      "\n",
      "        [[[-0.0066, -0.1147,  0.1098],\n",
      "          [-0.1139, -0.1762,  0.0995],\n",
      "          [-0.1270, -0.1240, -0.1158]],\n",
      "\n",
      "         [[ 0.1538, -0.0851,  0.0035],\n",
      "          [-0.0589,  0.1625, -0.1198],\n",
      "          [ 0.0656,  0.0084,  0.0039]],\n",
      "\n",
      "         [[-0.1592, -0.0326, -0.0768],\n",
      "          [ 0.1375,  0.1888,  0.0877],\n",
      "          [-0.1810,  0.0439,  0.1871]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1460, -0.1380, -0.1457],\n",
      "          [ 0.1425,  0.1039, -0.0453],\n",
      "          [ 0.0718,  0.1469, -0.0516]],\n",
      "\n",
      "         [[-0.0362, -0.1826,  0.1315],\n",
      "          [-0.0025,  0.0923,  0.0338],\n",
      "          [-0.0872,  0.1088,  0.0670]],\n",
      "\n",
      "         [[ 0.0081,  0.1047, -0.1067],\n",
      "          [-0.0485,  0.0946,  0.1283],\n",
      "          [-0.0908, -0.1724, -0.0900]]]])\n",
      "####################################################################################################\n"
     ]
    }
   ],
   "source": [
    "for param, weight in model.state_dict().items():\n",
    "    print(param)\n",
    "    print(weight.size())\n",
    "    print(weight)\n",
    "    print('#'*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`named_parameters()`: returns only parameters\n",
    "\n",
    "`state_dict()`: returns both parameters and buffers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['conv1.weight', 'conv1.bias', 'bn1.weight', 'bn1.bias', 'conv2.weight']\n",
      "['conv1.weight', 'conv1.bias', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'conv2.weight']\n"
     ]
    }
   ],
   "source": [
    "print([name for (name, param) in model.named_parameters()])\n",
    "print(list(model.state_dict().keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "data = torch.randn(2, 2, device=torch.device('cuda'))\n",
    "print(data.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`data = torch.randn(2,2).cuda()`는 CPU 메모리에 텐서를 만들고나서 GPU로 옯기는 것. \n",
    "\n",
    "Cost inefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "cpu\n",
      "cpu\n",
      "cpu\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# 모델의 모든 파라미터와 버퍼를 CPU 메모리로 옮기기\n",
    "model.cpu()\n",
    "\n",
    "for param in model.parameters():\n",
    "    print(param.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "model.cuda()\n",
    "\n",
    "for param in model.parameters():\n",
    "    print(param.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device_options = ['cpu', 'cuda']\n",
    "device = torch.device(device_options[1])\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "for param in model.parameters():\n",
    "    print(param.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward\n",
    "\n",
    "`nn.Module`을 상속한 객체를 직접 호출할 때 수행하는 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1, 1, 12, 12, device=device)\n",
    "model.to(device)\n",
    "output = model(input)\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
